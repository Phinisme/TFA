{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9430325a-472a-43e7-8811-8aa0b59cfeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"QT_API\"] = \"pyqt5\"\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3888028-85c0-4cd5-be18-1aba4da0426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from mne import Epochs, create_info\n",
    "from mne.io import RawArray\n",
    "from mne.time_frequency import  tfr_array_morlet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.report import Report\n",
    "import sys\n",
    "from mne.preprocessing import ICA, create_eog_epochs, create_ecg_epochs, corrmap, read_ica\n",
    "from mne.report import Report\n",
    "import math \n",
    "import pickle\n",
    "import mne\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from mne.preprocessing import ICA, create_eog_epochs, create_ecg_epochs, corrmap\n",
    "from mne.preprocessing import annotate_movement, compute_average_dev_head_t\n",
    "from mne.report import Report\n",
    "import math \n",
    "import pickle\n",
    "from mne.time_frequency import tfr_array_multitaper, tfr_array_morlet, tfr_multitaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1b8699-ab31-460f-8b10-6a422fb0402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne.channels import make_1020_channel_selections\n",
    "from mne.event import define_target_events\n",
    "\n",
    "print(__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ce073a-8550-47c2-89f3-ac79abca421a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path=\"F:/epochs_ITC\"\n",
    "\n",
    "subjects = [\"sub_m_1_02\", \"sub_m_1_06\", \"sub_m_1_10\",\"sub_m_1_14\",\"sub_m_1_18\",\"sub_m_1_22\",\"sub_m_1_26\",\"sub_m_1_30\",\"sub_m_1_34\",\"sub_m_1_38\",\"sub_m_1_42\",\"sub_m_1_46\",\n",
    "            \"sub_m_2_04\",\"sub_m_2_08\",\"sub_m_2_12\",\"sub_m_2_16\",\"sub_m_2_20\",\"sub_m_2_24\",\"sub_m_2_28\",\"sub_m_2_32\",\"sub_m_2_36\",\"sub_m_2_40\",\"sub_m_2_44\",\n",
    "            \"sub_p_1_01\",\"sub_p_1_05\",\"sub_p_1_09\",\"sub_p_1_13\",\"sub_p_1_17\",\"sub_p_1_21\",\"sub_p_1_25\",\"sub_p_1_29\",\"sub_p_1_33\",\"sub_p_1_35\",\"sub_p_1_37\",\"sub_p_1_41\",\"sub_p_1_45\",\n",
    "            \"sub_p_2_03\",\"sub_p_2_07\",\"sub_p_2_11\",\"sub_p_2_15\",\"sub_p_2_19\",\"sub_p_2_27\",\"sub_p_2_31\",\"sub_p_2_39\",\"sub_p_2_43\",\"sub_p_2_47\",]  # 被试数据\n",
    "\n",
    "for subj in subjects:\n",
    "    epochs = mne.read_epochs(\n",
    "        f\"F:/epochs_ITC/{subj}-raw-ica-reject-ERP-epo.fif\",\n",
    "        preload=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dfb0f6-6a3c-4aa5-9ded-cce07480eb94",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, ch in enumerate(epochs.ch_names):\n",
    "    print(f'\"EEG {i:03d}\": \"{ch}\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc022108-c35d-4d49-95e5-80eb9985e1b7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(epochs.ch_names[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b51756b-6a52-4601-a91b-af639a3aaf40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# General and initial exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f991347-031b-47c1-924c-45bf894b36fb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Evoked Potential\n",
    "evokeds = []\n",
    "\n",
    "for subj in subjects:\n",
    "    epochs = mne.read_epochs(\n",
    "        f\"F:/epochs_ITC/{subj}-raw-ica-reject-ERP-epo.fif\",\n",
    "        preload=False\n",
    "    )\n",
    "    evokeds.append(epochs.average())\n",
    "\n",
    "grand_evoked = mne.grand_average(evokeds)\n",
    "\n",
    "grand_evoked.plot(\n",
    "    titles=\"Grand Average Evoked (all EEG)\",\n",
    "    time_unit=\"s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dab7cee-1636-4b44-a032-c1299bbaf1af",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Global Theta Power\n",
    "freqs = np.arange(2, 30, 1)\n",
    "n_cycles = freqs / 3\n",
    "\n",
    "power = epochs.compute_tfr(\n",
    "    method=\"morlet\",\n",
    "    freqs=freqs,\n",
    "    n_cycles=n_cycles,\n",
    "    tmin=epochs.tmin,\n",
    "    tmax=1.0,\n",
    "    average=True,\n",
    "    return_itc=False,\n",
    "    decim=1,\n",
    ")\n",
    "\n",
    "power=power.apply_baseline(baseline=(-0.2,0),mode=\"logratio\")\n",
    "\n",
    "theta = power.copy().crop(fmin=4, fmax=7)\n",
    "\n",
    "theta_global = theta.data.mean(axis=(0, 1))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(theta.times, theta_global)\n",
    "plt.axvline(0, linestyle=\"--\")\n",
    "plt.title(\"Global theta power (avg all channels, 3–7 Hz)\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Power (logratio vs baseline)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb18c370-e27a-4bad-80bd-e637d3dcbe21",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#接上，64-channel heat map\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "freqs = np.arange(2, 30, 1)\n",
    "n_cycles = freqs / 3\n",
    "tmin,tmax=-0.2,1.0\n",
    "baseline=(-0.2,0)\n",
    "\n",
    "subjects = [\"sub_m_1_02\", \"sub_m_1_06\", \"sub_m_1_10\",\"sub_m_1_14\",\"sub_m_1_18\",\"sub_m_1_22\",\"sub_m_1_26\",\"sub_m_1_30\",\"sub_m_1_34\",\"sub_m_1_38\",\"sub_m_1_42\",\"sub_m_1_46\",\n",
    "            \"sub_m_2_04\",\"sub_m_2_08\",\"sub_m_2_12\",\"sub_m_2_16\",\"sub_m_2_20\",\"sub_m_2_24\",\"sub_m_2_28\",\"sub_m_2_32\",\"sub_m_2_36\",\"sub_m_2_40\",\"sub_m_2_44\",\n",
    "            \"sub_p_1_01\",\"sub_p_1_05\",\"sub_p_1_09\",\"sub_p_1_13\",\"sub_p_1_17\",\"sub_p_1_21\",\"sub_p_1_25\",\"sub_p_1_29\",\"sub_p_1_33\",\"sub_p_1_35\",\"sub_p_1_37\",\"sub_p_1_41\",\"sub_p_1_45\",\n",
    "            \"sub_p_2_03\",\"sub_p_2_07\",\"sub_p_2_11\",\"sub_p_2_15\",\"sub_p_2_19\",\"sub_p_2_27\",\"sub_p_2_31\",\"sub_p_2_39\",\"sub_p_2_43\",\"sub_p_2_47\",]  # 被试数据\n",
    "\n",
    "EPOCHS_DIR = r\"F:/epochs_ITC\"\n",
    "\n",
    "conds = [\"cue/ext/rep/sat\",\"cue/ext/swi/sat\",\"cue/int/rep/sat\",\"cue/int/swi/sat\"]\n",
    "\n",
    "bands = {\"theta\": (4, 7),\"alpha\": (8, 12)}\n",
    "    \n",
    "# storage: band_ct[band][cond] -> list of (n_channels, n_times) per subject\n",
    "band_ct = {band: {cond: [] for cond in conds} for band in bands}\n",
    "\n",
    "valid_subjects = []\n",
    "times = None\n",
    "ch_names = None\n",
    "\n",
    "#Main Loop\n",
    "for subj in subjects:\n",
    "    epo_path=os.path.join(EPOCHS_DIR,f\"{subj}-raw-ica-reject-ERP-epo.fif\")\n",
    "    epochs = mne.read_epochs(epo_path, preload=True)\n",
    "    epochs = epochs.copy().pick_types(eeg=True).crop(tmin=tmin, tmax=tmax)\n",
    "\n",
    "for cond in conds:\n",
    "    epochs_cell = epochs[cond].copy()\n",
    "    epo_path=os.path.join(EPOCHS_DIR,f\"{subj}-raw-ica-reject-ERP_epo.fif\")\n",
    "\n",
    "    power = epochs_cell.compute_tfr(\n",
    "        method=\"morlet\",\n",
    "        freqs=freqs,\n",
    "        n_cycles=n_cycles,\n",
    "        tmin=-0.2,\n",
    "        tmax=1.0,\n",
    "        average=True,\n",
    "        return_itc=False,\n",
    "        decim=3,\n",
    "    )\n",
    "    power.apply_baseline(baseline=(-0.2, 0), mode=\"logratio\")\n",
    "\n",
    "    for band_name, (fmin, fmax) in bands.items():\n",
    "        p_band = power.copy().crop(fmin=fmin, fmax=fmax)\n",
    "        band_ct[band_name][cond] = p_band.data.mean(axis=1)\n",
    "\n",
    "\n",
    "times = power.times\n",
    "ch_names = power.ch_names\n",
    "yticks = np.arange(0, len(ch_names), 2)\n",
    "\n",
    "#Theta\n",
    "theta_ct = band_ct[\"theta\"]\n",
    "all_vals = np.concatenate([theta_ct[c].ravel() for c in conds])\n",
    "vmax = np.percentile(np.abs(all_vals), 98)\n",
    "vmin = -vmax\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10), sharex=True, sharey=True, constrained_layout=True)\n",
    "\n",
    "for ax, cond in zip(axes.ravel(), conds):\n",
    "    im = ax.imshow(\n",
    "        theta_ct[cond],\n",
    "        aspect=\"auto\",\n",
    "        origin=\"lower\",\n",
    "        extent=[times[0], times[-1], 0, len(ch_names)],\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "    ax.axvline(0, linestyle=\"--\")\n",
    "    ax.set_title(cond.replace(\"cue/\", \"\"))\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"Channel\")\n",
    "\n",
    "axes[0, 0].set_yticks(yticks)\n",
    "axes[0, 0].set_yticklabels([ch_names[i] for i in yticks], fontsize=7)\n",
    "\n",
    "fig.colorbar(im, ax=axes.ravel().tolist(), label=\"Theta power (logratio)\")\n",
    "plt.show()\n",
    "\n",
    "# theta difference\n",
    "diff_ext = theta_ct[\"cue/ext/rep/sat\"] - theta_ct[\"cue/ext/swi/sat\"]\n",
    "diff_int = theta_ct[\"cue/int/rep/sat\"] - theta_ct[\"cue/int/swi/sat\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharex=True, sharey=True, constrained_layout=True)\n",
    "\n",
    "for ax, diff, title in zip(\n",
    "    axes,\n",
    "    [diff_ext, diff_int],\n",
    "    [\"ext: rep − swi (theta)\", \"int: rep − swi (theta)\"]\n",
    "):\n",
    "    im = ax.imshow(\n",
    "        diff,\n",
    "        aspect=\"auto\",\n",
    "        origin=\"lower\",\n",
    "        extent=[times[0], times[-1], 0, len(ch_names)],\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        cmap=\"RdBu_r\",\n",
    "    )\n",
    "    ax.axvline(0, linestyle=\"--\", color=\"k\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"Channel\")\n",
    "\n",
    "axes[0].set_yticks(yticks)\n",
    "axes[0].set_yticklabels([ch_names[i] for i in yticks], fontsize=7)\n",
    "\n",
    "fig.colorbar(im, ax=axes.ravel().tolist(), label=\"Theta power difference (logratio)\")\n",
    "plt.show()\n",
    "\n",
    "#alpha difference\n",
    "alpha_ct = band_ct[\"alpha\"]\n",
    "\n",
    "diff_ext_alpha = (alpha_ct[\"cue/ext/rep/sat\"] -alpha_ct[\"cue/ext/swi/sat\"])\n",
    "diff_int_alpha = (alpha_ct[\"cue/int/rep/sat\"] -alpha_ct[\"cue/int/swi/sat\"])\n",
    "\n",
    "all_diff_vals_alpha = np.concatenate([diff_ext_alpha.ravel(),diff_int_alpha.ravel()])\n",
    "vmax_diff_alpha = np.percentile(np.abs(all_diff_vals_alpha), 98)\n",
    "vmin_diff_alpha = -vmax_diff_alpha\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    1, 2, figsize=(14, 6),\n",
    "    sharex=True, sharey=True,\n",
    "    constrained_layout=True\n",
    ")\n",
    "\n",
    "for ax, diff, title in zip(\n",
    "    axes,\n",
    "    [diff_ext_alpha, diff_int_alpha],\n",
    "    [\"ext: rep − swi (alpha)\", \"int: rep − swi (alpha)\"]\n",
    "):\n",
    "    im = ax.imshow(\n",
    "        diff,\n",
    "        aspect=\"auto\",\n",
    "        origin=\"lower\",\n",
    "        extent=[times[0], times[-1], 0, len(ch_names)],\n",
    "        vmin=vmin_diff_alpha,\n",
    "        vmax=vmax_diff_alpha,\n",
    "        cmap=\"RdBu_r\",\n",
    "    )\n",
    "    ax.axvline(0, linestyle=\"--\", color=\"k\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"Channel\")\n",
    "\n",
    "axes[0].set_yticks(yticks)\n",
    "axes[0].set_yticklabels([ch_names[i] for i in yticks], fontsize=7)\n",
    "\n",
    "fig.colorbar(\n",
    "    im,\n",
    "    ax=axes.ravel().tolist(),\n",
    "    label=\"Alpha power difference (logratio)\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# alpha\n",
    "alpha_ct = band_ct[\"alpha\"]\n",
    "all_vals_alpha = np.concatenate([alpha_ct[c].ravel() for c in conds])\n",
    "vmax_alpha = np.percentile(np.abs(all_vals_alpha), 98)\n",
    "vmin_alpha = -vmax_alpha\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10), sharex=True, sharey=True, constrained_layout=True)\n",
    "\n",
    "for ax, cond in zip(axes.ravel(), conds):\n",
    "    im = ax.imshow(\n",
    "        alpha_ct[cond],\n",
    "        aspect=\"auto\",\n",
    "        origin=\"lower\",\n",
    "        extent=[times[0], times[-1], 0, len(ch_names)],\n",
    "        vmin=vmin_alpha,\n",
    "        vmax=vmax_alpha,\n",
    "    )\n",
    "    ax.axvline(0, linestyle=\"--\")\n",
    "    ax.set_title(cond.replace(\"cue/\", \"\"))\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"Channel\")\n",
    "\n",
    "axes[0, 0].set_yticks(yticks)\n",
    "axes[0, 0].set_yticklabels([ch_names[i] for i in yticks], fontsize=7)\n",
    "\n",
    "fig.colorbar(im, ax=axes.ravel().tolist(), label=\"Alpha power (logratio)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b574a8-84fe-44e5-928b-d2fbcfdd4e97",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Frequency analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import mne\n",
    "from mne.datasets import somato\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afcc1be-b608-41ad-b154-905d6fdc5a58",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subjects = [\"sub_m_1_02\", \"sub_m_1_06\", \"sub_m_1_10\",\"sub_m_1_14\",\"sub_m_1_18\",\"sub_m_1_22\",\"sub_m_1_26\",\"sub_m_1_30\",\"sub_m_1_34\",\"sub_m_1_38\",\"sub_m_1_42\",\"sub_m_1_46\",\n",
    "            \"sub_m_2_04\",\"sub_m_2_08\",\"sub_m_2_12\",\"sub_m_2_16\",\"sub_m_2_20\",\"sub_m_2_24\",\"sub_m_2_28\",\"sub_m_2_32\",\"sub_m_2_36\",\"sub_m_2_40\",\"sub_m_2_44\",\n",
    "            \"sub_p_1_01\",\"sub_p_1_05\",\"sub_p_1_09\",\"sub_p_1_13\",\"sub_p_1_17\",\"sub_p_1_21\",\"sub_p_1_25\",\"sub_p_1_29\",\"sub_p_1_33\",\"sub_p_1_35\",\"sub_p_1_37\",\"sub_p_1_41\",\"sub_p_1_45\",\n",
    "            \"sub_p_2_03\",\"sub_p_2_07\",\"sub_p_2_11\",\"sub_p_2_15\",\"sub_p_2_19\",\"sub_p_2_27\",\"sub_p_2_31\",\"sub_p_2_39\",\"sub_p_2_43\",\"sub_p_2_47\",]  # 被试数据\n",
    "\n",
    "EPOCHS_DIR = r\"F:/epochs_ITC\"\n",
    "\n",
    "target_sfreq = 100  #200对应最高分析100Hz，100对应一秒100个时间点，最高分析到50Hz\n",
    "tmin, tmax = -0.2,1.0         \n",
    "baseline = (-0.2, 0.0)           \n",
    "\n",
    "pick_kwargs = dict(eeg=True, eog=False, meg=False, stim=False)\n",
    "\n",
    "epochs_all = {}\n",
    "\n",
    "for subj in subjects:\n",
    "    epo_path = os.path.join(EPOCHS_DIR, f\"{subj}-raw-ica-reject-ERP-epo.fif\")\n",
    "    epochs = mne.read_epochs(epo_path, preload=True)\n",
    "\n",
    "  \n",
    "    if target_sfreq is not None and epochs.info[\"sfreq\"] != target_sfreq:\n",
    "        epochs = epochs.copy().resample(target_sfreq)\n",
    "\n",
    "    epochs = epochs.copy().crop(tmin=tmin, tmax=tmax)\n",
    "    epochs = epochs.copy().apply_baseline(baseline)\n",
    "    epochs = epochs.copy().pick_types(**pick_kwargs)\n",
    "    epochs_all[subj] = epochs\n",
    "\n",
    "print(f\"Loaded {len(epochs_all)} subjects' epochs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d121afae-8260-4071-8547-ed6845c34792",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#PSD in general\n",
    "psd = epochs.compute_psd(fmin=2.0, fmax=40.0)\n",
    "psd.plot(average=True, amplitude=False)\n",
    "psd.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3efc3-9500-4e53-8290-a8f7795ecf23",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs.compute_psd().plot_topomap(ch_type=\"eeg\", normalize=False, contours=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edbf8e4-e4d7-4fca-a3d1-30bd4d5ac553",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#PSD Power spectual density\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "spectrum = epochs.compute_psd(\n",
    "    fmin=2.0,\n",
    "    fmax=40.0,\n",
    "    tmax=3.0,\n",
    "    n_jobs=None,\n",
    "    picks=\"eeg\",          \n",
    ")\n",
    "\n",
    "mean_spectrum = spectrum.average()  # average across epochs\n",
    "psds, freqs = mean_spectrum.get_data(return_freqs=True)  # psds: (n_channels, n_freqs)\n",
    "\n",
    "psds_db = 10 * np.log10(psds)\n",
    "psds_mean = psds_db.mean(axis=0)    # mean across channels\n",
    "psds_std  = psds_db.std(axis=0)     # std across channels\n",
    "\n",
    "ax.plot(freqs, psds_mean, color=\"k\")\n",
    "ax.fill_between(freqs, psds_mean - psds_std, psds_mean + psds_std,\n",
    "                color=\"k\", alpha=0.5, edgecolor=\"none\")\n",
    "\n",
    "ax.set(\n",
    "    title=\"Multitaper PSD (EEG, mean ± SD across channels)\",\n",
    "    xlabel=\"Frequency (Hz)\",\n",
    "    ylabel=\"Power Spectral Density (dB)\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccd0638-fea5-4705-92a9-e45d26769a8a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#visualizing Specturum Objects\n",
    "%matplotlib qt\n",
    "\n",
    "epochs_eeg = epochs.copy().pick_types(eeg=True, eog=False, meg=False)\n",
    "epochs_spectrum = epochs_eeg.compute_psd(\n",
    "    method=\"welch\",       \n",
    "    fmin=2, fmax=40,\n",
    "    picks=\"eeg\",\n",
    "    n_jobs=None\n",
    ")\n",
    "evk_spectrum = epochs_spectrum.average()\n",
    "evk_spectrum.plot(picks=\"data\", exclude=\"bads\")\n",
    "evk_spectrum.plot(dB=True) \n",
    "evk_spectrum.plot_topo(color=\"k\", fig_facecolor=\"w\", axis_facecolor=\"w\",show=True)\n",
    "evk_spectrum.plot_topomap(ch_type=\"eeg\", agg_fun=np.median,show=True)\n",
    "\n",
    "bands = {\n",
    "    \"delta\": (0.5, 4),\n",
    "    \"theta\": (4, 8),\n",
    "    \"alpha\": (8, 12),\n",
    "    \"beta\": (12, 30),\n",
    "    \"gamma\": (30, 40),\n",
    "}\n",
    "\n",
    "evk_spectrum.plot_topomap(\n",
    "    bands=bands,\n",
    "    ch_type=\"eeg\",\n",
    "    agg_fun=np.median,   \n",
    "    normalize=False,\n",
    "    contours=0,\n",
    "    show=True\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9228228-4562-49d5-aec8-119deb9e90e9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#visualizing Specturum Objects- 4 conditions seperately\n",
    "\n",
    "conds = [\"cue/sat/int/rep\",\"cue/sat/int/swi\",\"cue/sat/ext/rep\",\"cue/sat/ext/swi\"]\n",
    "\n",
    "for cond in conds:\n",
    "    ep = epochs.copy().pick_types(eeg=True, eog=False, meg=False)[cond]\n",
    "\n",
    "    psd = ep.compute_psd(method=\"welch\", fmin=2, fmax=40, picks=\"eeg\")\n",
    "    spec = psd.average()  \n",
    "    \n",
    "    fig = spec.plot(dB=True, show=True)\n",
    "    fig.suptitle(f\"EEG – {cond}\", fontsize=14)\n",
    "    fig.savefig(f\"psd_{cond.replace('/','_')}.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c083499-e3a8-480e-9b06-f5b9bce5aa23",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# By using average power to first explore the power and ITC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c6b162-6b0d-4617-9ea8-d5e2ca64f566",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Power changes Across time - Under 4 conditions\n",
    "\n",
    "conds = [\"cue/sat/int/rep\",\"cue/sat/int/swi\",\"cue/sat/ext/rep\",\"cue/sat/ext/swi\"]\n",
    "\n",
    "freqs=np.arange()\n",
    "power_by_cond = {}\n",
    "itc_by_cond = {}\n",
    "\n",
    "epochs_eeg = epochs.copy().pick_types(eeg=True, eog=False, meg=False)\n",
    "\n",
    "for cond in conds:\n",
    "    ep = epochs_eeg[cond]\n",
    "    power, itc = ep.compute_tfr(\n",
    "        method=\"morlet\",\n",
    "        freqs=freqs,\n",
    "        n_cycles=n_cycles,\n",
    "        picks=\"eeg\",\n",
    "        average=True,     \n",
    "        return_itc=True,\n",
    "        decim=3,\n",
    "    )\n",
    "\n",
    "    power_by_cond[cond] = power\n",
    "    itc_by_cond[cond] = itc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d29823-c97e-4ee6-a3e6-9c01114a2310",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Original code without seperating into 4 conditions\n",
    "power.plot_joint(\n",
    "    baseline=(-0.2, 0), mode=\"logratio\", tmin=-0.2, tmax=1, timefreqs=[(0, 4),(0.2, 4), (0.4, 4),(0.6, 4),(0.8, 4)]\n",
    ")\n",
    "power.plot_joint(\n",
    "    baseline=(-0.2, 0), mode=\"logratio\", tmin=-0.2, tmax=1, timefreqs=[(0, 8),(0.2, 8), (0.4, 8),(0.6, 8),(0.8,8)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50787b7d-002c-4b7a-a91d-88e6e1f6b75c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Power plot under 4 conditions\n",
    "\n",
    "timefreqs_4 = [(0.0, 4), (0.2, 4), (0.4, 4), (0.6, 4), (0.8, 4)]\n",
    "timefreqs_8 = [(0.0, 8), (0.2, 8), (0.4, 8), (0.6, 8), (0.8, 8)]\n",
    "\n",
    "conds = [\"cue/sat/int/rep\",\"cue/sat/int/swi\",\"cue/sat/ext/rep\",\"cue/sat/ext/swi\"]\n",
    "\n",
    "for cond in conds:\n",
    "    pw = power_by_cond[cond]\n",
    "\n",
    "    figs_4 = pw.plot_joint(\n",
    "        baseline=(-0.2, 0),\n",
    "        mode=\"logratio\",\n",
    "        tmin=-0.2, tmax=1.0,\n",
    "        timefreqs=timefreqs_4,\n",
    "        show=True\n",
    "    )\n",
    "    \n",
    "    if not isinstance(figs_4, (list, tuple)):\n",
    "        figs_4 = [figs_4]\n",
    "    for k, fig in enumerate(figs_4):\n",
    "        fig.suptitle(f\"EEG – {cond} | joint @4Hz\", fontsize=14)\n",
    "        fig.savefig(f\"ThetaPower_{cond.replace('/','_')}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        \n",
    "    figs_8 = pw.plot_joint(\n",
    "        baseline=(-0.2, 0),\n",
    "        mode=\"logratio\",\n",
    "        tmin=-0.2, tmax=1.0,\n",
    "        timefreqs=timefreqs_8,\n",
    "        show=True\n",
    "    )\n",
    "    if not isinstance(figs_8, (list, tuple)):\n",
    "        figs_8 = [figs_8]\n",
    "    for k, fig in enumerate(figs_8):\n",
    "        fig.suptitle(f\"EEG – {cond} | joint @8Hz\", fontsize=14)\n",
    "        fig.savefig(f\"AlphaPower_{cond.replace('/','_')}.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a032df-94ed-428f-a5a7-163bbab02d1d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#ITC\n",
    "itc.plot_topo(title=\"Inter-Trial coherence\", vmin=0.0, vmax=1.0, cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2060e4-9d9b-4d29-bade-fd01952e2723",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ITC under 4 conditions\n",
    "\n",
    "conds = [\"cue/sat/int/rep\", \"cue/sat/int/swi\", \"cue/sat/ext/rep\", \"cue/sat/ext/swi\"]\n",
    "\n",
    "\n",
    "for cond in conds:\n",
    "    itc = itc_by_cond[cond]\n",
    "\n",
    "    fig = itc.plot_topo(title=f\"Inter-Trial Coherence (ITC) – {cond}\",vmin=0.0, vmax=1.0,cmap=\"Reds\")\n",
    "    fig.savefig(f\"ITC_topo_{cond.replace('/','_')}.png\",dpi=300,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710b9aa5-e439-42f2-b8d7-ee18ebdca8ff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Time-frequency of power under ROI channels\n",
    "frontal_chs=[\"Fz\", \"F1\", \"F2\", \"FCz\", \"FC1\", \"FC2\", \"Cz\"]\n",
    "occipital_chs = [\"Oz\", \"O1\", \"O2\",\"POz\", \"PO3\", \"PO4\"]\n",
    "\n",
    "bands={\"theta\":(4,8),\"alpha\":(8,12)}\n",
    "\n",
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "def extract_roi_band_timecourse(power, roi_channels, fmin, fmax):\n",
    "    missing = [ch for ch in roi_channels if ch not in power.ch_names]\n",
    "    if len(missing) > 0:\n",
    "        raise ValueError(f\"Missing channels in {roi_name}: {missing}\")\n",
    "\n",
    "    roi_idx = [power.ch_names.index(ch) for ch in roi_channels]\n",
    "    freq_mask = (power.freqs >= fmin) & (power.freqs <= fmax)\n",
    "    roi_data = power.data[roi_idx][:, freq_mask, :] #channel x freqs x times\n",
    "    roi_tc = roi_data.mean(axis=(0, 1))\n",
    "\n",
    "    return roi_tc\n",
    "    \n",
    "frontal_theta = extract_roi_band_timecourse(power,frontal_chs,*bands[\"theta\"])\n",
    "frontal_alpha = extract_roi_band_timecourse(power,frontal_chs,*bands[\"alpha\"])\n",
    "occipital_theta=extract_roi_band_timecourse(power,occipital_chs,*bands[\"theta\"])\n",
    "occipital_alpha=extract_roi_band_timecourse(power,occipital_chs,*bands[\"alpha\"])\n",
    "\n",
    "times = power.times\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(times, frontal_theta, label=\"Frontal Theta\")\n",
    "plt.plot(times, frontal_alpha, label=\"Frontal Alpha\")\n",
    "plt.plot(times, occipital_theta, label=\"Occipital Theta\")\n",
    "plt.plot(times, occipital_alpha, label=\"Occipital Alpha\")\n",
    "plt.axvline(0, color=\"k\", linestyle=\"--\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.legend()\n",
    "plt.title(\"ROI × Band Time Courses\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a403e405-98da-478a-b573-39339704cf05",
   "metadata": {},
   "source": [
    "# Cluster permutation with ROI, to invetigate the time x frequency. Data is TFR (Cycle = 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5652386-7a4a-4426-899b-0eca73262a96",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Compute TFR\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "\n",
    "subjects = [\"sub_m_1_02\", \"sub_m_1_06\", \"sub_m_1_10\",\"sub_m_1_14\",\"sub_m_1_18\",\"sub_m_1_22\",\"sub_m_1_26\",\"sub_m_1_30\",\"sub_m_1_34\",\"sub_m_1_38\",\"sub_m_1_42\",\"sub_m_1_46\",\n",
    "            \"sub_m_2_04\",\"sub_m_2_08\",\"sub_m_2_12\",\"sub_m_2_16\",\"sub_m_2_20\",\"sub_m_2_24\",\"sub_m_2_28\",\"sub_m_2_32\",\"sub_m_2_36\",\"sub_m_2_40\",\"sub_m_2_44\",\n",
    "            \"sub_p_1_01\",\"sub_p_1_05\",\"sub_p_1_09\",\"sub_p_1_13\",\"sub_p_1_17\",\"sub_p_1_21\",\"sub_p_1_25\",\"sub_p_1_29\",\"sub_p_1_33\",\"sub_p_1_35\",\"sub_p_1_37\",\"sub_p_1_41\",\"sub_p_1_45\",\n",
    "            \"sub_p_2_03\",\"sub_p_2_07\",\"sub_p_2_11\",\"sub_p_2_15\",\"sub_p_2_19\",\"sub_p_2_27\",\"sub_p_2_31\",\"sub_p_2_39\",\"sub_p_2_43\",\"sub_p_2_47\",]  # 被试数据\n",
    "\n",
    "EPOCHS_DIR = r\"F:/epochs_ITC\"\n",
    "OUT_DIR = r\"F:/tfr_single_trial\"\n",
    "\n",
    "freqs = np.arange(2, 30, 1)\n",
    "n_cycles = freqs / 3\n",
    "tmin,tmax=(-0.2,1)\n",
    "\n",
    "out_data = os.path.join(OUT_DIR, f\"{subj}_power.npy\")\n",
    "out_meta = os.path.join(OUT_DIR, f\"{subj}_meta.npz\")\n",
    "\n",
    "epochs = mne.read_epochs(epo_path, preload=True).crop(tmin=tmin, tmax=tmax)\n",
    "print(\"[epochs] len:\", len(epochs))\n",
    "\n",
    "for subj in subjects:\n",
    "    epo_path = os.path.join(EPOCHS_DIR, f\"{subj}-raw-ica-reject-ERP-epo.fif\")\n",
    "    epochs = mne.read_epochs(epo_path, preload=True).crop(tmin=tmin, tmax=tmax)\n",
    "    \n",
    "    power = epochs.compute_tfr(\n",
    "    method=\"morlet\",\n",
    "    freqs=freqs,\n",
    "    n_cycles=n_cycles,\n",
    "    tmin=epochs.tmin,\n",
    "    tmax=1.0,\n",
    "    average=False,\n",
    "    return_itc=False,\n",
    "    decim=1)\n",
    "    power=power.apply_baseline(baseline=(-0.2,0),mode=\"logratio\")\n",
    "    print(\"[tfr] type:\", type(power))\n",
    "    print(\"[tfr] shape:\", power.data.shape)  # (n_trials, n_ch, n_freq, n_time) expected\n",
    "    assert power.data.ndim == 4\n",
    "    assert power.data.shape[0] == len(epochs)\n",
    "\n",
    "    out_data = os.path.join(OUT_DIR, f\"{subj}_power.npy\")\n",
    "    out_meta = os.path.join(OUT_DIR, f\"{subj}_meta.npz\")\n",
    "\n",
    "    np.save(out_data, power.data.astype(np.float32))\n",
    "    np.savez(\n",
    "        out_meta,\n",
    "        ch_names=np.array(power.ch_names, dtype=object),\n",
    "        freqs=power.freqs.astype(np.float32),\n",
    "        times=power.times.astype(np.float32),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9275d823-d503-46ec-b243-898e41a8b73e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#import matplotlib\n",
    "import os\n",
    "os.environ[\"QT_API\"] = \"pyqt5\"\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc7597-4e7c-4c21-a2a3-fa25c654aa6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Power changes across time under 4 conditions,selected ROI\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "subjects = [\"sub_m_1_02\", \"sub_m_1_06\", \"sub_m_1_10\",\"sub_m_1_14\",\"sub_m_1_18\",\"sub_m_1_22\",\"sub_m_1_26\",\"sub_m_1_30\",\"sub_m_1_34\",\"sub_m_1_38\",\"sub_m_1_42\",\"sub_m_1_46\",\n",
    "            \"sub_m_2_04\",\"sub_m_2_08\",\"sub_m_2_12\",\"sub_m_2_16\",\"sub_m_2_20\",\"sub_m_2_24\",\"sub_m_2_28\",\"sub_m_2_32\",\"sub_m_2_36\",\"sub_m_2_40\",\"sub_m_2_44\",\n",
    "            \"sub_p_1_01\",\"sub_p_1_05\",\"sub_p_1_09\",\"sub_p_1_13\",\"sub_p_1_17\",\"sub_p_1_21\",\"sub_p_1_25\",\"sub_p_1_29\",\"sub_p_1_33\",\"sub_p_1_35\",\"sub_p_1_37\",\"sub_p_1_41\",\"sub_p_1_45\",\n",
    "            \"sub_p_2_03\",\"sub_p_2_07\",\"sub_p_2_11\",\"sub_p_2_15\",\"sub_p_2_19\",\"sub_p_2_27\",\"sub_p_2_31\",\"sub_p_2_39\",\"sub_p_2_43\",\"sub_p_2_47\",]  # 被试数据\n",
    "\n",
    "OUT_DIR = r\"F:/tfr_single_trial\"\n",
    "EPOCHS_DIR = r\"F:/epochs_ITC\"\n",
    "\n",
    "conds = [\"cue/sat/int/rep\",\"cue/sat/int/swi\",\"cue/sat/ext/rep\",\"cue/sat/ext/swi\"]\n",
    "roi = [\"Fz\", \"F1\", \"F2\", \"FCz\", \"FC1\", \"FC2\", \"Cz\"]\n",
    "\n",
    "group_tf = {cond: [] for cond in conds}\n",
    "\n",
    "freqs_ref = None\n",
    "times_ref = None\n",
    "\n",
    "for subj in subjects:\n",
    "    power_path = os.path.join(OUT_DIR, f\"{subj}_power.npy\")\n",
    "    meta_path  = os.path.join(OUT_DIR, f\"{subj}_meta.npz\")\n",
    "    epo_path   = os.path.join(EPOCHS_DIR, f\"{subj}-raw-ica-reject-ERP-epo.fif\")\n",
    "\n",
    "    X = np.load(power_path, mmap_mode=\"r\")  # (n_trials, n_ch, n_freq, n_time)\n",
    "    meta = np.load(meta_path, allow_pickle=True)\n",
    "    ch_names = meta[\"ch_names\"].tolist()\n",
    "    freqs = meta[\"freqs\"]\n",
    "    times = meta[\"times\"]\n",
    "\n",
    "    if freqs_ref is None:\n",
    "        freqs_ref = freqs.copy()\n",
    "        times_ref = times.copy()\n",
    "    else:\n",
    "        if (len(freqs) != len(freqs_ref) or len(times) != len(times_ref)\n",
    "            or not np.allclose(freqs, freqs_ref) or not np.allclose(times, times_ref)):\n",
    "            print(\"SKIP axis mismatch:\", subj)\n",
    "            continue\n",
    "    try:\n",
    "        roi_idx = [ch_names.index(ch) for ch in roi]\n",
    "    except ValueError:\n",
    "        print(\"SKIP missing ROI chan:\", subj)\n",
    "        continue\n",
    "    # epochs only for selected condition (must match trial count)\n",
    "    epochs = mne.read_epochs(epo_path, preload=True).crop(tmin=times[0], tmax=times[-1])\n",
    "\n",
    "    for cond in conds:\n",
    "        cond_sel = epochs[cond].selection\n",
    "        idx = np.flatnonzero(np.isin(epochs.selection, cond_sel))\n",
    "        if len(idx) == 0:\n",
    "            continue\n",
    "\n",
    "        tf = X[idx][:, roi_idx].mean(axis=(0, 1))\n",
    "        group_tf[cond].append(tf.astype(np.float32))\n",
    "\n",
    "group_mean = {}\n",
    "for cond in conds:\n",
    "    if len(group_tf[cond]) == 0:\n",
    "        group_mean[cond] = None\n",
    "        print(\"No subjects for cond:\", cond)\n",
    "    else:\n",
    "        group_mean[cond] = np.mean(np.stack(group_tf[cond], axis=0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305a67f6-56d3-4401-95c1-2de94615cca3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#plot above\n",
    "available = [group_mean[c] for c in conds if group_mean[c] is not None]\n",
    "stack = np.stack(available, axis=0)\n",
    "vmin, vmax = np.percentile(stack, [5, 95])\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8),\n",
    "                        gridspec_kw={\"width_ratios\": [1, 1], \"wspace\": 0.25, \"hspace\": 0.25})\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, cond in zip(axes, conds):\n",
    "    tf = group_mean[cond]\n",
    "    im = ax.imshow(\n",
    "        tf,\n",
    "        aspect=\"auto\",\n",
    "        origin=\"lower\",\n",
    "        extent=[times_ref[0], times_ref[-1], freqs_ref[0], freqs_ref[-1]],\n",
    "        vmin=vmin, vmax=vmax\n",
    "    )\n",
    "    ax.set_title(f\"{cond} (group mean)\")\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"Frequency (Hz)\")\n",
    "    \n",
    "cbar = fig.colorbar(\n",
    "    im,\n",
    "    ax=axes,\n",
    "    location=\"right\",\n",
    "    fraction=0.025,\n",
    "    pad=0.04)\n",
    "cbar.set_label(\"Log power (baseline corrected)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fc3847-f9a3-4ef6-9a92-255258442255",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Again Double CHECK if it is the right data structure\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "\n",
    "subj = \"sub_m_1_02\"\n",
    "OUT_DIR = r\"F:/tfr_single_trial\"\n",
    "EPOCHS_DIR = r\"F:/epochs_ITC\"\n",
    "\n",
    "X = np.load(os.path.join(OUT_DIR, f\"{subj}_power.npy\"))\n",
    "meta = np.load(os.path.join(OUT_DIR, f\"{subj}_meta.npz\"), allow_pickle=True)\n",
    "\n",
    "ch_names = meta[\"ch_names\"].tolist()\n",
    "freqs = meta[\"freqs\"]\n",
    "times = meta[\"times\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7512a0-2f65-4526-9e07-549e365a81ac",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#CHECK\n",
    "print(\"X.ndim =\", X.ndim)\n",
    "print(\"X.shape =\", X.shape)\n",
    "assert X.ndim == 4, \"power.npy 不是 4D\"\n",
    "\n",
    "n_trials, n_ch, n_freq, n_time = X.shape\n",
    "\n",
    "print(\"channels in data:\", n_ch)\n",
    "print(\"channels in meta:\", len(ch_names))\n",
    "print(\"freq bins:\", n_freq, \"meta:\", len(freqs))\n",
    "print(\"time points:\", n_time, \"meta:\", len(times))\n",
    "assert n_ch == len(ch_names), \"channel 维度不一致\"\n",
    "assert n_freq == len(freqs), \"freq 维度不一致\"\n",
    "assert n_time == len(times), \"time 维度不一致\"\n",
    "\n",
    "epo_path = os.path.join(EPOCHS_DIR, f\"{subj}-raw-ica-reject-ERP-epo.fif\")\n",
    "epochs = mne.read_epochs(epo_path, preload=True).crop(tmin=times[0], tmax=times[-1])\n",
    "\n",
    "print(\"n_trials in X:\", n_trials)\n",
    "print(\"n_epochs:\", len(epochs))\n",
    "\n",
    "assert n_trials == len(epochs), \"trial 数和 epochs 不一致\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bdab0c-179e-4fb6-8e8d-a4b0bfd0577a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#check input\n",
    "conds = {\"int_rep\": \"cue/sat/int/rep\", \"int_swi\": \"cue/sat/int/swi\", \"ext_rep\": \"cue/sat/ext/rep\",\n",
    "    \"ext_swi\": \"cue/sat/ext/swi\"}\n",
    "\n",
    "#Average trial-level -> Subject-level\n",
    "def cond_mean(X, epochs, cond):\n",
    "    cond_sel = epochs[cond].selection\n",
    "    idx = np.flatnonzero(np.isin(epochs.selection, cond_sel))\n",
    "    assert len(idx) > 0, f\"No trials for {cond}\"\n",
    "    return X[idx].mean(axis=0) \n",
    "\n",
    "M = {}\n",
    "for k, c in conds.items():\n",
    "    M[k] = cond_mean(X, epochs, c) #(channel, freqs, time)\n",
    "    assert M[k].ndim == 3  #self-check\n",
    "\n",
    "def roi_theta(Mk, roi_idx, fidx): #MK: 来自上一步;fidx: theta \n",
    "    return Mk[roi_idx][:, fidx, :].mean(axis=(0,1)) \n",
    "\n",
    "#Effect\n",
    "INT = 0.5 * (M[\"int_rep\"] + M[\"int_swi\"])\n",
    "EXT = 0.5 * (M[\"ext_rep\"] + M[\"ext_swi\"])\n",
    "D_int_ext = INT - EXT\n",
    "SWI = 0.5 * (M[\"int_swi\"] + M[\"ext_swi\"])\n",
    "REP = 0.5 * (M[\"int_rep\"] + M[\"ext_rep\"])\n",
    "D_swi_rep = SWI - REP\n",
    "D_interaction = (M[\"int_swi\"] - M[\"int_rep\"]) - (M[\"ext_swi\"] - M[\"ext_rep\"])\n",
    "\n",
    "def check_stack(D_list):\n",
    "    shapes = [d.shape for d in D_list]\n",
    "    assert len(set(shapes)) == 1, f\"Shape mismatch: {set(shapes)}\"\n",
    "    X = np.stack(D_list, axis=0)\n",
    "    assert X.ndim in (3, 4), \"Expect subjects×freq×time or ×ch×freq×time\"\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0cf214-190a-4c6f-93e8-5323086e93fe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"M[int_rep].shape =\", M[\"int_rep\"].shape)\n",
    "print(\"D_int_ext.shape =\", D_int_ext.shape)\n",
    "print(\"D_swi_rep.shape =\", D_swi_rep.shape)\n",
    "print(\"D_interaction.shape =\", D_interaction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adfd864-828f-46c4-a40d-ed92f28568ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cluster permutation\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.stats import permutation_cluster_1samp_test\n",
    "os.environ[\"QT_API\"] = \"pyqt5\"\n",
    "%matplotlib qt\n",
    "\n",
    "OUT_DIR = r\"F:/tfr_single_trial\"\n",
    "EPOCHS_DIR = r\"F:/epochs_ITC\"\n",
    "\n",
    "subjects = [\"sub_m_1_02\", \"sub_m_1_06\", \"sub_m_1_10\",\"sub_m_1_14\",\"sub_m_1_18\",\"sub_m_1_22\",\"sub_m_1_26\",\"sub_m_1_30\",\"sub_m_1_34\",\"sub_m_1_38\",\"sub_m_1_42\",\"sub_m_1_46\",\n",
    "            \"sub_m_2_04\",\"sub_m_2_08\",\"sub_m_2_12\",\"sub_m_2_16\",\"sub_m_2_20\",\"sub_m_2_24\",\"sub_m_2_28\",\"sub_m_2_32\",\"sub_m_2_36\",\"sub_m_2_40\",\"sub_m_2_44\",\n",
    "            \"sub_p_1_01\",\"sub_p_1_05\",\"sub_p_1_09\",\"sub_p_1_13\",\"sub_p_1_17\",\"sub_p_1_21\",\"sub_p_1_25\",\"sub_p_1_29\",\"sub_p_1_33\",\"sub_p_1_35\",\"sub_p_1_37\",\"sub_p_1_41\",\"sub_p_1_45\",\n",
    "            \"sub_p_2_03\",\"sub_p_2_07\",\"sub_p_2_11\",\"sub_p_2_15\",\"sub_p_2_19\",\"sub_p_2_27\",\"sub_p_2_31\",\"sub_p_2_39\",\"sub_p_2_43\",\"sub_p_2_47\"]\n",
    "\n",
    "conds = {\"int_rep\": \"cue/sat/int/rep\", \"int_swi\": \"cue/sat/int/swi\", \"ext_rep\": \"cue/sat/ext/rep\",\n",
    "    \"ext_swi\": \"cue/sat/ext/swi\"}\n",
    "\n",
    "roi = [\"Oz\", \"O1\", \"O2\",\"POz\", \"PO3\", \"PO4\"]\n",
    "theta_lo, theta_hi = 4.0, 8.0\n",
    "EFFECTS_TO_TEST = [\"int_ext\", \"swi_rep\", \"interaction\"]\n",
    "\n",
    "#cluster setting\n",
    "N_PERM=5000\n",
    "ALPHA=0.05\n",
    "TAIL=0\n",
    "\n",
    "#Construct subject-level(same as above\n",
    "def cond_mean(X, epochs, cond):\n",
    "    cond_sel = epochs[cond].selection\n",
    "    idx = np.flatnonzero(np.isin(epochs.selection, cond_sel))\n",
    "    assert len(idx) > 0, f\"No trials for {cond}\"\n",
    "    return X[idx].mean(axis=0) \n",
    "\n",
    "def roi_theta(Mk, roi_idx, fidx): #MK: 来自上一步;fidx: theta \n",
    "    return Mk[roi_idx][:, fidx, :].mean(axis=(0,1))\n",
    "\n",
    "#Load one subject, compute ROI×theta timecourses for effects\n",
    "def build_subject_effects(subj):\n",
    "    def roi_theta_time(Mk, roi_idx, fidx):\n",
    "        return Mk[roi_idx][:, fidx, :].mean(axis=(0, 1)) \n",
    "        \n",
    "    power_path = os.path.join(OUT_DIR, f\"{subj}_power.npy\")\n",
    "    meta_path  = os.path.join(OUT_DIR, f\"{subj}_meta.npz\")\n",
    "    epo_path   = os.path.join(EPOCHS_DIR, f\"{subj}-raw-ica-reject-ERP-epo.fif\")\n",
    "\n",
    "    if not (os.path.exists(power_path) and os.path.exists(meta_path) and os.path.exists(epo_path)):\n",
    "        return None, None, f\"missing file(s)\"\n",
    "\n",
    "    X = np.load(power_path, mmap_mode=\"r\")  # (n_trials, n_ch, n_freq, n_time)\n",
    "    meta = np.load(meta_path, allow_pickle=True)\n",
    "    ch_names = meta[\"ch_names\"].tolist()\n",
    "    freqs = meta[\"freqs\"].astype(float)\n",
    "    times = meta[\"times\"].astype(float)\n",
    "\n",
    "    # ROI index\n",
    "    try:\n",
    "        roi_idx = [ch_names.index(ch) for ch in roi]\n",
    "    except ValueError:\n",
    "        return None, None, \"missing ROI channels\"\n",
    "\n",
    "    # theta index\n",
    "    fmask = (freqs >= theta_lo) & (freqs <= theta_hi)\n",
    "    if not np.any(fmask):\n",
    "        return None, None, \"no theta bins\"\n",
    "    fidx = np.where(fmask)[0]\n",
    "\n",
    "    # load epochs just for selection mapping\n",
    "    epochs = mne.read_epochs(epo_path, preload=True).crop(tmin=times[0], tmax=times[-1])\n",
    "\n",
    "    # Alignment Check\n",
    "    if X.shape[0] != len(epochs):\n",
    "        return None, None, f\"trial mismatch: X={X.shape[0]} epochs={len(epochs)}\"\n",
    "\n",
    "    # condition means (subject-level)\n",
    "    M = {k: cond_mean(X, epochs, c) for k, c in conds.items()}\n",
    "\n",
    "    # effects (ch,freq,time)\n",
    "    INT = 0.5 * (M[\"int_rep\"] + M[\"int_swi\"])\n",
    "    EXT = 0.5 * (M[\"ext_rep\"] + M[\"ext_swi\"])\n",
    "    D_int_ext = INT - EXT\n",
    "\n",
    "    SWI = 0.5 * (M[\"int_swi\"] + M[\"ext_swi\"])\n",
    "    REP = 0.5 * (M[\"int_rep\"] + M[\"ext_rep\"])\n",
    "    D_swi_rep = SWI - REP\n",
    "\n",
    "    D_interaction = (M[\"int_swi\"] - M[\"int_rep\"]) - (M[\"ext_swi\"] - M[\"ext_rep\"])\n",
    "\n",
    "    # ROI×theta -> timecourses\n",
    "    out = {\n",
    "        \"int_ext\": roi_theta_time(D_int_ext, roi_idx, fidx),\n",
    "        \"swi_rep\": roi_theta_time(D_swi_rep, roi_idx, fidx),\n",
    "        \"interaction\": roi_theta_time(D_interaction, roi_idx, fidx),\n",
    "    }\n",
    "    return out, times, None\n",
    "\n",
    "def run_cluster_1samp(X_subj_time, times, title):\n",
    "    X_subj_time = np.asarray(X_subj_time, dtype=float)\n",
    "    assert X_subj_time.ndim == 2, \"expect (subjects, time)\"\n",
    "    assert X_subj_time.shape[1] == len(times), \"time length mismatch\"\n",
    "\n",
    "    T_obs, clusters, pvals, H0 = permutation_cluster_1samp_test(\n",
    "        X_subj_time,\n",
    "        n_permutations=N_PERM,\n",
    "        tail=TAIL,\n",
    "        threshold=None,     # MNE picks a default threshold\n",
    "        out_type=\"mask\",\n",
    "        n_jobs=1,\n",
    "        seed=0,\n",
    "    )\n",
    "\n",
    "    # report significant clusters\n",
    "    sig = np.where(pvals < ALPHA)[0]\n",
    "    print(f\"\\n[{title}] n_subjects={X_subj_time.shape[0]}  n_sig_clusters={len(sig)}\")\n",
    "    for i in sig:\n",
    "        mask = clusters[i] \n",
    "        t0, t1 = times[mask][0], times[mask][-1]\n",
    "        print(f\"  cluster {i}: p={pvals[i]:.4f}, time=[{t0:.3f},{t1:.3f}]s, mass={T_obs[mask].sum():.3f}\")\n",
    "\n",
    "    # quick plot: mean ± SEM + mark significant clusters\n",
    "    mean = X_subj_time.mean(axis=0)\n",
    "    sem = X_subj_time.std(axis=0, ddof=1) / np.sqrt(X_subj_time.shape[0])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    ax.plot(times, mean)\n",
    "    ax.fill_between(times, mean - sem, mean + sem, alpha=0.2)\n",
    "    ax.axhline(0, color=\"k\", ls=\"--\", lw=1)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"ROI×theta contrast (logratio power)\")\n",
    "\n",
    "    # shade significant clusters\n",
    "    for i in sig:\n",
    "        mask = clusters[i]\n",
    "        ax.axvspan(times[mask][0], times[mask][-1], alpha=0.15)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return T_obs, clusters, pvals, H0\n",
    "\n",
    "# main: build subject matrices \n",
    "effects_all = {eff: [] for eff in EFFECTS_TO_TEST}\n",
    "times_ref = None\n",
    "kept = 0\n",
    "\n",
    "for subj in subjects:\n",
    "    out, times, err = build_subject_effects(subj)\n",
    "    if err is not None:\n",
    "        print(\"SKIP\", subj, \"->\", err)\n",
    "        continue\n",
    "\n",
    "    if times_ref is None:\n",
    "        times_ref = times.copy()\n",
    "    else:\n",
    "        if len(times) != len(times_ref) or not np.allclose(times, times_ref):\n",
    "            print(\"SKIP\", subj, \"-> times mismatch\")\n",
    "            continue\n",
    "\n",
    "    for eff in EFFECTS_TO_TEST:\n",
    "        effects_all[eff].append(out[eff].astype(np.float32))\n",
    "\n",
    "    kept += 1\n",
    "\n",
    "print(\"\\nKept subjects:\", kept)\n",
    "\n",
    "#  run cluster permutation per effect \n",
    "for eff in EFFECTS_TO_TEST:\n",
    "    X_eff = np.stack(effects_all[eff], axis=0)  # (subjects, time)\n",
    "    title = f\"Cluster permutation (time) — {eff} | ROI={roi} | theta={theta_lo}-{theta_hi} Hz\"\n",
    "    run_cluster_1samp(X_eff, times_ref, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80736e3c-c711-4df5-b36e-63f8eebe50ee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cluster permutation alpha\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.stats import permutation_cluster_1samp_test\n",
    "os.environ[\"QT_API\"] = \"pyqt5\"\n",
    "%matplotlib qt\n",
    "\n",
    "OUT_DIR = r\"F:/tfr_single_trial\"\n",
    "EPOCHS_DIR = r\"F:/epochs_ITC\"\n",
    "\n",
    "subjects = [\"sub_m_1_02\", \"sub_m_1_06\", \"sub_m_1_10\",\"sub_m_1_14\",\"sub_m_1_18\",\"sub_m_1_22\",\"sub_m_1_26\",\"sub_m_1_30\",\"sub_m_1_34\",\"sub_m_1_38\",\"sub_m_1_42\",\"sub_m_1_46\",\n",
    "            \"sub_m_2_04\",\"sub_m_2_08\",\"sub_m_2_12\",\"sub_m_2_16\",\"sub_m_2_20\",\"sub_m_2_24\",\"sub_m_2_28\",\"sub_m_2_32\",\"sub_m_2_36\",\"sub_m_2_40\",\"sub_m_2_44\",\n",
    "            \"sub_p_1_01\",\"sub_p_1_05\",\"sub_p_1_09\",\"sub_p_1_13\",\"sub_p_1_17\",\"sub_p_1_21\",\"sub_p_1_25\",\"sub_p_1_29\",\"sub_p_1_33\",\"sub_p_1_35\",\"sub_p_1_37\",\"sub_p_1_41\",\"sub_p_1_45\",\n",
    "            \"sub_p_2_03\",\"sub_p_2_07\",\"sub_p_2_11\",\"sub_p_2_15\",\"sub_p_2_19\",\"sub_p_2_27\",\"sub_p_2_31\",\"sub_p_2_39\",\"sub_p_2_43\",\"sub_p_2_47\"]\n",
    "\n",
    "conds = {\"int_rep\": \"cue/sat/int/rep\", \"int_swi\": \"cue/sat/int/swi\", \"ext_rep\": \"cue/sat/ext/rep\",\n",
    "    \"ext_swi\": \"cue/sat/ext/swi\"}\n",
    "\n",
    "roi = [\"Oz\", \"O1\", \"O2\",\"POz\", \"PO3\", \"PO4\"]\n",
    "alpha_lo, alpha_hi = 8.0, 15.0\n",
    "EFFECTS_TO_TEST = [\"int_ext\", \"swi_rep\", \"interaction\"]\n",
    "\n",
    "#cluster setting\n",
    "N_PERM=5000\n",
    "ALPHA=0.05\n",
    "TAIL=0\n",
    "\n",
    "#Construct subject-level(same as above\n",
    "def cond_mean(X, epochs, cond):\n",
    "    cond_sel = epochs[cond].selection\n",
    "    idx = np.flatnonzero(np.isin(epochs.selection, cond_sel))\n",
    "    assert len(idx) > 0, f\"No trials for {cond}\"\n",
    "    return X[idx].mean(axis=0) \n",
    "\n",
    "def roi_alpha(Mk, roi_idx, fidx): #MK: 来自上一步;fidx: theta \n",
    "    return Mk[roi_idx][:, fidx, :].mean(axis=(0,1))\n",
    "\n",
    "#Load one subject, compute ROI×theta timecourses for effects\n",
    "def build_subject_effects(subj):\n",
    "    def roi_alpha_time(Mk, roi_idx, fidx):\n",
    "        return Mk[roi_idx][:, fidx, :].mean(axis=(0, 1)) \n",
    "        \n",
    "    power_path = os.path.join(OUT_DIR, f\"{subj}_power.npy\")\n",
    "    meta_path  = os.path.join(OUT_DIR, f\"{subj}_meta.npz\")\n",
    "    epo_path   = os.path.join(EPOCHS_DIR, f\"{subj}-raw-ica-reject-ERP-epo.fif\")\n",
    "\n",
    "    if not (os.path.exists(power_path) and os.path.exists(meta_path) and os.path.exists(epo_path)):\n",
    "        return None, None, f\"missing file(s)\"\n",
    "\n",
    "    X = np.load(power_path, mmap_mode=\"r\")  # (n_trials, n_ch, n_freq, n_time)\n",
    "    meta = np.load(meta_path, allow_pickle=True)\n",
    "    ch_names = meta[\"ch_names\"].tolist()\n",
    "    freqs = meta[\"freqs\"].astype(float)\n",
    "    times = meta[\"times\"].astype(float)\n",
    "\n",
    "    # ROI index\n",
    "    try:\n",
    "        roi_idx = [ch_names.index(ch) for ch in roi]\n",
    "    except ValueError:\n",
    "        return None, None, \"missing ROI channels\"\n",
    "\n",
    "    # theta index\n",
    "    fmask = (freqs >= theta_lo) & (freqs <= theta_hi)\n",
    "    if not np.any(fmask):\n",
    "        return None, None, \"no theta bins\"\n",
    "    fidx = np.where(fmask)[0]\n",
    "\n",
    "    # load epochs just for selection mapping\n",
    "    epochs = mne.read_epochs(epo_path, preload=True).crop(tmin=times[0], tmax=times[-1])\n",
    "\n",
    "    # Alignment Check\n",
    "    if X.shape[0] != len(epochs):\n",
    "        return None, None, f\"trial mismatch: X={X.shape[0]} epochs={len(epochs)}\"\n",
    "\n",
    "    # condition means (subject-level)\n",
    "    M = {k: cond_mean(X, epochs, c) for k, c in conds.items()}\n",
    "\n",
    "    # effects (ch,freq,time)\n",
    "    INT = 0.5 * (M[\"int_rep\"] + M[\"int_swi\"])\n",
    "    EXT = 0.5 * (M[\"ext_rep\"] + M[\"ext_swi\"])\n",
    "    D_int_ext = INT - EXT\n",
    "\n",
    "    SWI = 0.5 * (M[\"int_swi\"] + M[\"ext_swi\"])\n",
    "    REP = 0.5 * (M[\"int_rep\"] + M[\"ext_rep\"])\n",
    "    D_swi_rep = SWI - REP\n",
    "\n",
    "    D_interaction = (M[\"int_swi\"] - M[\"int_rep\"]) - (M[\"ext_swi\"] - M[\"ext_rep\"])\n",
    "\n",
    "    # ROI×theta -> timecourses\n",
    "    out = {\n",
    "        \"int_ext\": roi_alpha_time(D_int_ext, roi_idx, fidx),\n",
    "        \"swi_rep\": roi_alpha_time(D_swi_rep, roi_idx, fidx),\n",
    "        \"interaction\": roi_alpha_time(D_interaction, roi_idx, fidx),\n",
    "    }\n",
    "    return out, times, None\n",
    "\n",
    "def run_cluster_1samp(X_subj_time, times, title):\n",
    "    X_subj_time = np.asarray(X_subj_time, dtype=float)\n",
    "    assert X_subj_time.ndim == 2, \"expect (subjects, time)\"\n",
    "    assert X_subj_time.shape[1] == len(times), \"time length mismatch\"\n",
    "\n",
    "    T_obs, clusters, pvals, H0 = permutation_cluster_1samp_test(\n",
    "        X_subj_time,\n",
    "        n_permutations=N_PERM,\n",
    "        tail=TAIL,\n",
    "        threshold=None,     # MNE picks a default threshold\n",
    "        out_type=\"mask\",\n",
    "        n_jobs=1,\n",
    "        seed=0,\n",
    "    )\n",
    "\n",
    "    # report significant clusters\n",
    "    sig = np.where(pvals < ALPHA)[0]\n",
    "    print(f\"\\n[{title}] n_subjects={X_subj_time.shape[0]}  n_sig_clusters={len(sig)}\")\n",
    "    for i in sig:\n",
    "        mask = clusters[i] \n",
    "        t0, t1 = times[mask][0], times[mask][-1]\n",
    "        print(f\"  cluster {i}: p={pvals[i]:.4f}, time=[{t0:.3f},{t1:.3f}]s, mass={T_obs[mask].sum():.3f}\")\n",
    "\n",
    "    # quick plot: mean ± SEM + mark significant clusters\n",
    "    mean = X_subj_time.mean(axis=0)\n",
    "    sem = X_subj_time.std(axis=0, ddof=1) / np.sqrt(X_subj_time.shape[0])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    ax.plot(times, mean)\n",
    "    ax.fill_between(times, mean - sem, mean + sem, alpha=0.2)\n",
    "    ax.axhline(0, color=\"k\", ls=\"--\", lw=1)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"ROI×theta contrast (logratio power)\")\n",
    "\n",
    "    # shade significant clusters\n",
    "    for i in sig:\n",
    "        mask = clusters[i]\n",
    "        ax.axvspan(times[mask][0], times[mask][-1], alpha=0.15)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return T_obs, clusters, pvals, H0\n",
    "\n",
    "# main: build subject matrices \n",
    "effects_all = {eff: [] for eff in EFFECTS_TO_TEST}\n",
    "times_ref = None\n",
    "kept = 0\n",
    "\n",
    "for subj in subjects:\n",
    "    out, times, err = build_subject_effects(subj)\n",
    "    if err is not None:\n",
    "        print(\"SKIP\", subj, \"->\", err)\n",
    "        continue\n",
    "\n",
    "    if times_ref is None:\n",
    "        times_ref = times.copy()\n",
    "    else:\n",
    "        if len(times) != len(times_ref) or not np.allclose(times, times_ref):\n",
    "            print(\"SKIP\", subj, \"-> times mismatch\")\n",
    "            continue\n",
    "\n",
    "    for eff in EFFECTS_TO_TEST:\n",
    "        effects_all[eff].append(out[eff].astype(np.float32))\n",
    "\n",
    "    kept += 1\n",
    "\n",
    "print(\"\\nKept subjects:\", kept)\n",
    "\n",
    "#  run cluster permutation per effect \n",
    "for eff in EFFECTS_TO_TEST:\n",
    "    X_eff = np.stack(effects_all[eff], axis=0)  # (subjects, time)\n",
    "    title = f\"Cluster permutation (time) — {eff} | ROI={roi} | alpha={alpha_lo}-{alpha_hi} Hz\"\n",
    "    run_cluster_1samp(X_eff, times_ref, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9408fb-aa9e-4a15-b146-e7cf021826d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Checking Baseline\n",
    "import numpy as np\n",
    "\n",
    "tmin_b, tmax_b = -0.2, 0\n",
    "bmask = (power.times >= tmin_b) & (power.times <= tmax_b)\n",
    "\n",
    "# baseline average power(channel x frequency)\n",
    "base = power.data[:, :, bmask].mean(axis=2)\n",
    "print(\"baseline min/max:\", np.nanmin(base), np.nanmax(base))\n",
    "\n",
    "# power across time\n",
    "full = power.data\n",
    "print(\"full min/max:\", np.nanmin(full), np.nanmax(full))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcd7b70-af21-444d-bed3-079c3899c372",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Sensor study and ERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89cd562-5547-493f-be86-1ef2f2ed19ef",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Compute power and phase lock in label of the sensor space,\n",
    "#But we don't have MRI, so it'll be sensor-space\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import mne\n",
    "from mne import io\n",
    "from mne.datasets import sample\n",
    "from mne.minimum_norm import read_inverse_operator, source_induced_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a82a407-37f6-4a3f-9d88-5730931b68ba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Computer power across 46subjs X epochs across all conditions\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "subjects = [\"sub_m_1_02\", \"sub_m_1_06\", \"sub_m_1_10\",\"sub_m_1_14\",\"sub_m_1_18\",\"sub_m_1_22\",\"sub_m_1_26\",\"sub_m_1_30\",\"sub_m_1_34\",\"sub_m_1_38\",\"sub_m_1_42\",\"sub_m_1_46\",\n",
    "            \"sub_m_2_04\",\"sub_m_2_08\",\"sub_m_2_12\",\"sub_m_2_16\",\"sub_m_2_20\",\"sub_m_2_24\",\"sub_m_2_28\",\"sub_m_2_32\",\"sub_m_2_36\",\"sub_m_2_40\",\"sub_m_2_44\",\n",
    "            \"sub_p_1_01\",\"sub_p_1_05\",\"sub_p_1_09\",\"sub_p_1_13\",\"sub_p_1_17\",\"sub_p_1_21\",\"sub_p_1_25\",\"sub_p_1_29\",\"sub_p_1_33\",\"sub_p_1_35\",\"sub_p_1_37\",\"sub_p_1_41\",\"sub_p_1_45\",\n",
    "            \"sub_p_2_03\",\"sub_p_2_07\",\"sub_p_2_11\",\"sub_p_2_15\",\"sub_p_2_19\",\"sub_p_2_27\",\"sub_p_2_31\",\"sub_p_2_39\",\"sub_p_2_43\",\"sub_p_2_47\",]  # 被试数据\n",
    "\n",
    "EPOCHS_DIR = r\"F:/epochs_ITC\"\n",
    "\n",
    "frontal_roi = [\"Fz\", \"F1\", \"F2\", \"FCz\", \"FC1\", \"FC2\", \"Cz\"]\n",
    "occipital_roi = [\"O1\", \"O2\", \"PO3\", \"POz\",\"Oz\"]\n",
    "\n",
    "freqs=np.arange(4,30,2)\n",
    "n_cycles=freqs/3.0\n",
    "pick_kwargs = dict(eeg=True, eog=False, meg=False, stim=False)\n",
    "baseline=(-0.2,0)\n",
    "tmin,tmax=-0.2,1.0\n",
    "decim=3\n",
    "epochs_all = {}\n",
    "\n",
    "def roi_band_timecourse(tfr, roi_chs, fmin, fmax, min_chs=1):\n",
    "    present_chs = [ch for ch in roi_chs if ch in tfr.ch_names]\n",
    "    missing = list(set(roi_chs) - set(present_chs))\n",
    "    if missing:\n",
    "        warnings.warn(f\"ROI missing channels (ignored): {missing}\")\n",
    "    if len(present_chs) < min_chs:\n",
    "        return None\n",
    "\n",
    "    picks = [tfr.ch_names.index(ch) for ch in present_chs]\n",
    "    fmask = (tfr.freqs >= fmin) & (tfr.freqs <= fmax)\n",
    "\n",
    "    # tfr.data shape: (n_channels, n_freqs, n_times)\n",
    "    roi_tc = tfr.data[picks][:, fmask, :].mean(axis=(0, 1))\n",
    "    return roi_tc\n",
    "\n",
    "# store subject-level ROI timecourses for group averaging\n",
    "subj_tc = {\"frontal_theta_total\": [],\"frontal_theta_induced\": [],\"occip_alpha_total\": [],\n",
    "    \"occip_alpha_induced\": []}\n",
    "\n",
    "for subj in subjects:\n",
    "    epo_path = os.path.join(EPOCHS_DIR, f\"{subj}-raw-ica-reject-ERP-epo.fif\")\n",
    "    epochs = mne.read_epochs(epo_path, preload=True)\n",
    "    epochs = epochs.copy().crop(tmin=tmin, tmax=tmax)\n",
    "    epochs = epochs.copy().apply_baseline(baseline)\n",
    "    epochs = epochs.copy().pick_types(**pick_kwargs)\n",
    "    epochs_all[subj] = epochs\n",
    "\n",
    "# total (evoked + induced) \n",
    "    power_total, itc_total = epochs.compute_tfr(\n",
    "        method=\"morlet\",\n",
    "        freqs=freqs,\n",
    "        n_cycles=n_cycles,\n",
    "        average=True,\n",
    "        return_itc=True,\n",
    "        decim=decim,\n",
    "    )\n",
    "    # baseline for power\n",
    "    power_total.apply_baseline(baseline=baseline, mode=\"logratio\")\n",
    "    #induced-only (remove phase-locked ERP first)\n",
    "    epochs_induced=epochs.copy().subtract_evoked()\n",
    "\n",
    "    epochs_induced = epochs.copy().subtract_evoked()\n",
    "    power_ind, itc_ind = epochs_induced.compute_tfr(\n",
    "        method=\"morlet\",\n",
    "        freqs=freqs,\n",
    "        n_cycles=n_cycles,\n",
    "        average=True,\n",
    "        return_itc=True,\n",
    "        decim=decim,\n",
    "    )\n",
    "    power_ind.apply_baseline(baseline=baseline, mode=\"logratio\")\n",
    "\n",
    "    # ROI timecourses (theta / alpha)\n",
    "    tc = roi_band_timecourse(power_total, frontal_roi, 4, 8)\n",
    "    if tc is not None:\n",
    "        subj_tc[\"frontal_theta_total\"].append(tc)\n",
    "\n",
    "    tc = roi_band_timecourse(power_ind, frontal_roi, 4, 8)\n",
    "    if tc is not None:\n",
    "        subj_tc[\"frontal_theta_induced\"].append(tc)\n",
    "\n",
    "    tc = roi_band_timecourse(power_total, occipital_roi, 8, 12)\n",
    "    if tc is not None:\n",
    "        subj_tc[\"occip_alpha_total\"].append(tc)\n",
    "\n",
    "    tc = roi_band_timecourse(power_ind, occipital_roi, 8, 12)\n",
    "    if tc is not None:\n",
    "        subj_tc[\"occip_alpha_induced\"].append(tc)\n",
    "\n",
    "\n",
    "# -------- group average --------\n",
    "times = power_total.times  # same across subjects if preprocessing consistent\n",
    "\n",
    "def mean_sem(arr_list):\n",
    "    if len(arr_list) == 0:\n",
    "        return None, None\n",
    "    x = np.stack(arr_list, axis=0)\n",
    "    mean = x.mean(axis=0)\n",
    "    sem = x.std(axis=0, ddof=1) / np.sqrt(x.shape[0])\n",
    "    return mean, sem\n",
    "\n",
    "\n",
    "ft_tot_m, ft_tot_sem = mean_sem(subj_tc[\"frontal_theta_total\"])\n",
    "ft_ind_m, ft_ind_sem = mean_sem(subj_tc[\"frontal_theta_induced\"])\n",
    "oa_tot_m, oa_tot_sem = mean_sem(subj_tc[\"occip_alpha_total\"])\n",
    "oa_ind_m, oa_ind_sem = mean_sem(subj_tc[\"occip_alpha_induced\"])\n",
    "\n",
    "\n",
    "#view TF plots\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "ax.plot(times, ft_tot_m, label=\"Frontal θ total (4–8)\")\n",
    "ax.plot(times, ft_ind_m, label=\"Frontal θ induced-only (4–8)\")\n",
    "ax.plot(times, oa_tot_m, label=\"Occip α total (8–12)\")\n",
    "ax.plot(times, oa_ind_m, label=\"Occip α induced-only (8–12)\")\n",
    "\n",
    "ax.axvline(0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Power change (mean)\")\n",
    "ax.set_title(\"Group ROI band power (sensor space)\")\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(\n",
    "    \"Group_ROI_band_power.png\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\"\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ee7c01-a6d0-4865-ba2a-5ef00729de97",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Group ROI under 4 conditions\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "subjects = [\n",
    "    \"sub_m_1_02\", \"sub_m_1_06\", \"sub_m_1_10\",\"sub_m_1_14\",\"sub_m_1_18\",\"sub_m_1_22\",\"sub_m_1_26\",\"sub_m_1_30\",\"sub_m_1_34\",\"sub_m_1_38\",\"sub_m_1_42\",\"sub_m_1_46\",\n",
    "    \"sub_m_2_04\",\"sub_m_2_08\",\"sub_m_2_12\",\"sub_m_2_16\",\"sub_m_2_20\",\"sub_m_2_24\",\"sub_m_2_28\",\"sub_m_2_32\",\"sub_m_2_36\",\"sub_m_2_40\",\"sub_m_2_44\",\n",
    "    \"sub_p_1_01\",\"sub_p_1_05\",\"sub_p_1_09\",\"sub_p_1_13\",\"sub_p_1_17\",\"sub_p_1_21\",\"sub_p_1_25\",\"sub_p_1_29\",\"sub_p_1_33\",\"sub_p_1_35\",\"sub_p_1_37\",\"sub_p_1_41\",\"sub_p_1_45\",\n",
    "    \"sub_p_2_03\",\"sub_p_2_07\",\"sub_p_2_11\",\"sub_p_2_15\",\"sub_p_2_19\",\"sub_p_2_27\",\"sub_p_2_31\",\"sub_p_2_39\",\"sub_p_2_43\",\"sub_p_2_47\",\n",
    "]\n",
    "\n",
    "EPOCHS_DIR = r\"F:/epochs_ITC\"\n",
    "\n",
    "conds = [\"cue/ext/rep/sat\",\"cue/ext/swi/sat\",\"cue/int/rep/sat\",\"cue/int/swi/sat\"]\n",
    "\n",
    "frontal_roi = [\"Fz\", \"F1\", \"F2\", \"FCz\", \"FC1\", \"FC2\", \"Cz\"]\n",
    "occipital_roi = [\"O1\", \"O2\", \"PO3\", \"POz\", \"Oz\"]\n",
    "\n",
    "freqs = np.arange(4, 30, 2)\n",
    "n_cycles = freqs / 3.0\n",
    "\n",
    "baseline = (-0.2, 0.0)\n",
    "tmin, tmax = -0.2, 1.0\n",
    "decim = 3\n",
    "pick_kwargs = dict(eeg=True, eog=False, meg=False, stim=False)\n",
    "\n",
    "def roi_band_timecourse(tfr, roi_chs, fmin, fmax, min_chs=1):\n",
    "    present_chs = [ch for ch in roi_chs if ch in tfr.ch_names]\n",
    "    if len(present_chs) < min_chs:\n",
    "        return None\n",
    "\n",
    "    picks = [tfr.ch_names.index(ch) for ch in present_chs]\n",
    "    fmask = (tfr.freqs >= fmin) & (tfr.freqs <= fmax)\n",
    "\n",
    "    # tfr.data: (n_channels, n_freqs, n_times)\n",
    "    return tfr.data[picks][:, fmask, :].mean(axis=(0, 1))\n",
    "\n",
    "def mean_sem(arr_list):\n",
    "    if len(arr_list) == 0:\n",
    "        return None, None, 0\n",
    "    x = np.stack(arr_list, axis=0)  # (n_subj, n_times)\n",
    "    m = x.mean(axis=0)\n",
    "    sem = x.std(axis=0, ddof=1) / np.sqrt(x.shape[0]) if x.shape[0] > 1 else np.zeros_like(m)\n",
    "    return m, sem, x.shape[0]\n",
    "\n",
    "\n",
    "metrics = [\"ft_total\", \"ft_induced\", \"fa_total\",\"fa_induced\",\"ot_total\",\"ot_induced\",\"oa_total\", \"oa_induced\"]\n",
    "subj_tc = {cond: {m: [] for m in metrics} for cond in conds}\n",
    "\n",
    "times_ref = None\n",
    "\n",
    "#  main loop \n",
    "for subj in subjects:\n",
    "    epo_path = os.path.join(EPOCHS_DIR, f\"{subj}-raw-ica-reject-ERP-epo.fif\")\n",
    "    if not os.path.exists(epo_path):\n",
    "        warnings.warn(f\"Missing file: {epo_path}\")\n",
    "        continue\n",
    "\n",
    "    epochs = mne.read_epochs(epo_path, preload=True)\n",
    "    epochs = epochs.copy().crop(tmin=tmin, tmax=tmax)\n",
    "    epochs = epochs.copy().apply_baseline(baseline)\n",
    "    epochs = epochs.copy().pick_types(**pick_kwargs)\n",
    "\n",
    "    # loop conditions\n",
    "    for cond in conds:\n",
    "        if cond not in epochs.event_id:\n",
    "            continue\n",
    "\n",
    "        ep = epochs[cond]\n",
    "        if len(ep) == 0:\n",
    "            continue\n",
    "\n",
    "        # total \n",
    "        power_total, _itc_total = ep.compute_tfr(\n",
    "            method=\"morlet\",\n",
    "            freqs=freqs,\n",
    "            n_cycles=n_cycles,\n",
    "            average=True,\n",
    "            return_itc=True,\n",
    "            decim=decim,\n",
    "        )\n",
    "        power_total.apply_baseline(baseline=baseline, mode=\"logratio\")\n",
    "\n",
    "        # induced-only\n",
    "        ep_ind = ep.copy().subtract_evoked()\n",
    "        power_ind, _itc_ind = ep_ind.compute_tfr(\n",
    "            method=\"morlet\",\n",
    "            freqs=freqs,\n",
    "            n_cycles=n_cycles,\n",
    "            average=True,\n",
    "            return_itc=True,\n",
    "            decim=decim,\n",
    "        )\n",
    "        power_ind.apply_baseline(baseline=baseline, mode=\"logratio\")\n",
    "\n",
    "        # times reference check\n",
    "        if times_ref is None:\n",
    "            times_ref = power_total.times\n",
    "        else:\n",
    "            if len(power_total.times) != len(times_ref) or not np.allclose(power_total.times, times_ref):\n",
    "                warnings.warn(f\"Times mismatch in {subj} {cond}; skipping this entry.\")\n",
    "                continue\n",
    "\n",
    "        # ROI timecourses\n",
    "        tc = roi_band_timecourse(power_total, frontal_roi, 4, 8)\n",
    "        if tc is not None:\n",
    "            subj_tc[cond][\"ft_total\"].append(tc)\n",
    "\n",
    "        tc = roi_band_timecourse(power_ind, frontal_roi, 4, 8)\n",
    "        if tc is not None:\n",
    "            subj_tc[cond][\"ft_induced\"].append(tc)\n",
    "\n",
    "        tc = roi_band_timecourse(power_total, frontal_roi,8, 15)\n",
    "        if tc is not None:\n",
    "            subj_tc[cond][\"fa_total\"].append(tc)\n",
    "\n",
    "        tc = roi_band_timecourse(power_ind, frontal_roi, 8, 15)\n",
    "        if tc is not None:\n",
    "            subj_tc[cond][\"fa_induced\"].append(tc)\n",
    "\n",
    "        tc = roi_band_timecourse(power_total, occipital_roi, 4, 8)\n",
    "        if tc is not None:\n",
    "            subj_tc[cond][\"ot_total\"].append(tc)\n",
    "\n",
    "        tc = roi_band_timecourse(power_ind, occipital_roi, 4, 8)\n",
    "        if tc is not None:\n",
    "            subj_tc[cond][\"ot_induced\"].append(tc)\n",
    "\n",
    "        tc = roi_band_timecourse(power_total, occipital_roi, 8, 15)\n",
    "        if tc is not None:\n",
    "            subj_tc[cond][\"oa_total\"].append(tc)\n",
    "\n",
    "        tc = roi_band_timecourse(power_ind, occipital_roi, 8, 15)\n",
    "        if tc is not None:\n",
    "            subj_tc[cond][\"oa_induced\"].append(tc)\n",
    "\n",
    "#  group plots: 2x2 (one subplot per condition) \n",
    "if times_ref is None:\n",
    "    raise RuntimeError(\"No valid TFR computed. Check condition names in epochs.event_id and file paths.\")\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    2, 2, figsize=(14, 10),\n",
    "    sharex=True, sharey=True,\n",
    "    constrained_layout=True\n",
    ")\n",
    "\n",
    "for ax, cond in zip(axes.ravel(), conds):\n",
    "    ft_tot_m, ft_tot_sem, n_ft_tot = mean_sem(subj_tc[cond][\"ft_total\"])\n",
    "    ft_ind_m, ft_ind_sem, n_ft_ind = mean_sem(subj_tc[cond][\"ft_induced\"])\n",
    "    fa_tot_m, fa_tot_sem, n_fa_tot = mean_sem(subj_tc[cond][\"fa_total\"])\n",
    "    fa_ind_m, fa_ind_sem, n_fa_ind = mean_sem(subj_tc[cond][\"fa_induced\"])\n",
    "\n",
    "    ot_tot_m, ot_tot_sem, n_ot_tot = mean_sem(subj_tc[cond][\"ot_total\"])\n",
    "    ot_ind_m, ot_ind_sem, n_ot_ind = mean_sem(subj_tc[cond][\"ot_induced\"])\n",
    "    oa_tot_m, oa_tot_sem, n_oa_tot = mean_sem(subj_tc[cond][\"oa_total\"])\n",
    "    oa_ind_m, oa_ind_sem, n_oa_ind = mean_sem(subj_tc[cond][\"oa_induced\"])\n",
    "\n",
    "    if ft_tot_m is not None:\n",
    "        ax.plot(times_ref, ft_tot_m, label=f\"Frontal θ total (N={n_ft_tot})\")\n",
    "        ax.fill_between(times_ref, ft_tot_m - ft_tot_sem, ft_tot_m + ft_tot_sem, alpha=0.2)\n",
    "\n",
    "    if ft_ind_m is not None:\n",
    "        ax.plot(times_ref, ft_ind_m, label=f\"Frontal θ induced (N={n_ft_ind})\")\n",
    "        ax.fill_between(times_ref, ft_ind_m - ft_ind_sem, ft_ind_m + ft_ind_sem, alpha=0.2)\n",
    "\n",
    "    if fa_tot_m is not None:\n",
    "        ax.plot(times_ref, fa_tot_m, label=f\"Frontal α total (N={n_fa_tot})\")\n",
    "        ax.fill_between(times_ref, fa_tot_m - fa_tot_sem, fa_tot_m + fa_tot_sem, alpha=0.2)\n",
    "\n",
    "    if fa_ind_m is not None:\n",
    "        ax.plot(times_ref, fa_ind_m, label=f\"Frontal α induced (N={n_fa_ind})\")\n",
    "        ax.fill_between(times_ref, fa_ind_m - fa_ind_sem, fa_ind_m + fa_ind_sem, alpha=0.2)\n",
    "\n",
    "    if ot_tot_m is not None:\n",
    "        ax.plot(times_ref, ot_tot_m, label=f\"Occip θ total (N={n_ot_tot})\")\n",
    "        ax.fill_between(times_ref, ot_tot_m - ot_tot_sem, ot_tot_m + ot_tot_sem, alpha=0.2)\n",
    "\n",
    "    if ot_ind_m is not None:\n",
    "        ax.plot(times_ref, ot_ind_m, label=f\"Occip θ induced (N={n_ot_ind})\")\n",
    "        ax.fill_between(times_ref, ot_ind_m - ot_ind_sem, ot_ind_m + ot_ind_sem, alpha=0.2)\n",
    "\n",
    "    if oa_tot_m is not None:\n",
    "        ax.plot(times_ref, oa_tot_m, label=f\"Occip α total (N={n_oa_tot})\")\n",
    "        ax.fill_between(times_ref, oa_tot_m - oa_tot_sem, oa_tot_m + oa_tot_sem, alpha=0.2)\n",
    "\n",
    "    if oa_ind_m is not None:\n",
    "        ax.plot(times_ref, oa_ind_m, label=f\"Occip α induced (N={n_oa_ind})\")\n",
    "        ax.fill_between(times_ref, oa_ind_m - oa_ind_sem, oa_ind_m + oa_ind_sem, alpha=0.2)\n",
    "\n",
    "\n",
    "    ax.axvline(0, color=\"k\", linestyle=\"--\", linewidth=1)\n",
    "    ax.set_title(f\"Group ROI band power - {cond}\")\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"Power (logratio)\")\n",
    "    ax.set_title(f\"Group ROI band power-{cond}\")\n",
    "\n",
    "handles, labels = axes.ravel()[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"center right\", frameon=True)\n",
    "\n",
    "fig.subplots_adjust(right=0.80)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027426df-ded0-47d9-a14d-ebdc039117d6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Explore event-related dynamics for specific frequency bands（跑不跑再说）\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import mne\n",
    "from mne.baseline import rescale\n",
    "from mne.datasets import somato\n",
    "from mne.stats import bootstrap_confidence_interval\n",
    "import os\n",
    "\n",
    "subjects = [\"sub_m_1_02\", \"sub_m_1_06\", \"sub_m_1_10\",\"sub_m_1_14\",\"sub_m_1_18\",\"sub_m_1_22\",\"sub_m_1_26\",\"sub_m_1_30\",\"sub_m_1_34\",\"sub_m_1_38\",\"sub_m_1_42\",\"sub_m_1_46\",\n",
    "            \"sub_m_2_04\",\"sub_m_2_08\",\"sub_m_2_12\",\"sub_m_2_16\",\"sub_m_2_20\",\"sub_m_2_24\",\"sub_m_2_28\",\"sub_m_2_32\",\"sub_m_2_36\",\"sub_m_2_40\",\"sub_m_2_44\",\n",
    "            \"sub_p_1_01\",\"sub_p_1_05\",\"sub_p_1_09\",\"sub_p_1_13\",\"sub_p_1_17\",\"sub_p_1_21\",\"sub_p_1_25\",\"sub_p_1_29\",\"sub_p_1_33\",\"sub_p_1_35\",\"sub_p_1_37\",\"sub_p_1_41\",\"sub_p_1_45\",\n",
    "            \"sub_p_2_03\",\"sub_p_2_07\",\"sub_p_2_11\",\"sub_p_2_15\",\"sub_p_2_19\",\"sub_p_2_27\",\"sub_p_2_31\",\"sub_p_2_39\",\"sub_p_2_43\",\"sub_p_2_47\",]  # 被试数据\n",
    "\n",
    "frontal_roi = [\"Fz\", \"F1\", \"F2\", \"FCz\", \"FC1\", \"FC2\", \"Cz\"]\n",
    "\n",
    "EPOCHS_DIR = r\"F:/epochs_ITC\"\n",
    "epochs_all = {}\n",
    "\n",
    "frequency_map = {subj: {} for subj in subjects}\n",
    "for subj in subjects:\n",
    "    epo_path = os.path.join(EPOCHS_DIR, f\"{subj}-raw-ica-reject-ERP-epo.fif\")\n",
    "    epochs = mne.read_epochs(epo_path, preload=True)\n",
    "    epochs_roi = epochs.copy().pick(frontal_roi)\n",
    "\n",
    "iter_freqs = [(\"Theta\", 4, 7), (\"Alpha\", 8, 12)]\n",
    "\n",
    "# set epoching parameters\n",
    "tmin, tmax = -0.2, 1.0\n",
    "baseline = None\n",
    "\n",
    "\n",
    "## Store subject-level timecourses per band\n",
    "band_tc = {band: [] for band, _, _ in iter_freqs}\n",
    "times_ref = None\n",
    "\n",
    "for subj in subjects:\n",
    "    epo_path = os.path.join(EPOCHS_DIR, f\"{subj}-raw-ica-reject-ERP-epo.fif\")\n",
    "    if not os.path.exists(epo_path):\n",
    "        print(f\"Skipping {subj}: file missing\")\n",
    "        continue\n",
    "\n",
    "    epochs = mne.read_epochs(epo_path, preload=True)\n",
    "    epochs_roi = epochs.copy().pick(frontal_roi).crop(tmin=tmin, tmax=tmax)\n",
    "\n",
    "    for band, fmin, fmax in iter_freqs:\n",
    "        e = epochs_roi.copy()\n",
    "        e.filter(l_freq=fmin, h_freq=fmax, n_jobs=None,\n",
    "                 l_trans_bandwidth=1, h_trans_bandwidth=1)\n",
    "        e.subtract_evoked()\n",
    "        e.apply_hilbert(envelope=True)\n",
    "        evk = e.average()\n",
    "        evk_data = rescale(evk.data, times=evk.times, baseline=baseline, mode=\"percent\", copy=True)\n",
    "        evk = mne.EvokedArray(evk_data, evk.info, tmin=evk.times[0], nave=evk.nave)\n",
    "        frequency_map[subj][band] = evk\n",
    "        del e\n",
    "\n",
    "    valid_subjects.append(subj)\n",
    "    del epochs, epochs_roi\n",
    "\n",
    "print(f\"Valid subjects: {len(valid_subjects)} / {len(subjects)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f6fd6d-8143-4fd4-8054-1796763a0ea8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Figure(属于跑不跑再说的哪个figure)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.stats import bootstrap_confidence_interval\n",
    "from mne.baseline import rescale\n",
    "\n",
    "iter_freqs = [(\"Theta\", 4, 7), (\"Alpha\", 8, 12)]\n",
    "\n",
    "def stat_mean_tc(x):\n",
    "    # x: (n_subj, n_ch, n_times) or (n_boot, n_ch, n_times) depending on internal call\n",
    "    return x.mean(axis=(0, 1))  # -> (n_times,)\n",
    "\n",
    "fig, axes = plt.subplots(len(iter_freqs), 1, figsize=(10, 8), sharex=True)\n",
    "if len(iter_freqs) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "colors = plt.colormaps[\"winter_r\"](np.linspace(0, 1, len(iter_freqs)))\n",
    "\n",
    "for ax, (band, fmin, fmax), color in zip(axes, iter_freqs, colors):\n",
    "\n",
    "    subj_data = []\n",
    "    for subj in subjects:\n",
    "        if band not in frequency_map.get(subj, {}):\n",
    "            continue\n",
    "        evk = frequency_map[subj][band]         # (n_roi_ch, n_times)\n",
    "        subj_data.append(evk.data)\n",
    "\n",
    "    subj_data = np.array(subj_data)            # (n_subj, n_ch, n_times)\n",
    "    times = evk.times * 1e3                    # ms\n",
    "\n",
    "    mean_tc = subj_data.mean(axis=(0, 1))      # (n_times,)\n",
    "    mean_tc = rescale(mean_tc, times, baseline=(None, 0), mode=\"mean\", copy=True)\n",
    "\n",
    "    ci_low, ci_up = bootstrap_confidence_interval(\n",
    "        subj_data,\n",
    "        random_state=0,\n",
    "        stat_fun=stat_mean_tc\n",
    "    )\n",
    "    ci_low = rescale(ci_low, times, baseline=(None, 0), mode=\"mean\", copy=True)\n",
    "    ci_up  = rescale(ci_up,  times, baseline=(None, 0), mode=\"mean\", copy=True)\n",
    "\n",
    "    ax.plot(times, mean_tc, color=color, linewidth=2.5)\n",
    "    ax.fill_between(times, mean_tc - ci_low, mean_tc + ci_up, color=color, alpha=0.3)\n",
    "\n",
    "    ax.axhline(0, linestyle=\"--\", color=\"grey\")\n",
    "    ax.set_ylabel(\"ROI envelope\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    ax.annotate(f\"{band} ({fmin}-{fmax} Hz)\",\n",
    "                xy=(0.02, 0.85), xycoords=\"axes fraction\",\n",
    "                fontsize=11, fontweight=\"bold\")\n",
    "\n",
    "axes[-1].set_xlabel(\"Time (ms)\")\n",
    "fig.suptitle(\"Frontal ROI induced band envelopes (group mean ± bootstrap CI)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c5b31-d1c9-459a-808c-f53a2baf36af",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Explore event-related dynamics for specific frequency bands under 4 conditions\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "\n",
    "from mne.baseline import rescale\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "subjects = [\n",
    "    \"sub_m_1_02\", \"sub_m_1_06\", \"sub_m_1_10\",\"sub_m_1_14\",\"sub_m_1_18\",\"sub_m_1_22\",\"sub_m_1_26\",\"sub_m_1_30\",\"sub_m_1_34\",\"sub_m_1_38\",\"sub_m_1_42\",\"sub_m_1_46\",\n",
    "    \"sub_m_2_04\",\"sub_m_2_08\",\"sub_m_2_12\",\"sub_m_2_16\",\"sub_m_2_20\",\"sub_m_2_24\",\"sub_m_2_28\",\"sub_m_2_32\",\"sub_m_2_36\",\"sub_m_2_40\",\"sub_m_2_44\",\n",
    "    \"sub_p_1_01\",\"sub_p_1_05\",\"sub_p_1_09\",\"sub_p_1_13\",\"sub_p_1_17\",\"sub_p_1_21\",\"sub_p_1_25\",\"sub_p_1_29\",\"sub_p_1_33\",\"sub_p_1_35\",\"sub_p_1_37\",\"sub_p_1_41\",\"sub_p_1_45\",\n",
    "    \"sub_p_2_03\",\"sub_p_2_07\",\"sub_p_2_11\",\"sub_p_2_15\",\"sub_p_2_19\",\"sub_p_2_27\",\"sub_p_2_31\",\"sub_p_2_39\",\"sub_p_2_43\",\"sub_p_2_47\",\n",
    "]\n",
    "EPOCHS_DIR = r\"F:/epochs_ITC\"\n",
    "\n",
    "conds = [\"cue/ext/rep/sat\",\"cue/ext/swi/sat\",\"cue/int/rep/sat\",\"cue/int/swi/sat\"]\n",
    "\n",
    "iter_freqs = [(\"Theta\", 4, 7), (\"Alpha\", 8, 12)]\n",
    "\n",
    "frontal_roi   = [\"Fz\", \"F1\", \"F2\", \"FCz\", \"FC1\", \"FC2\", \"Cz\"]\n",
    "occipital_roi = [\"O1\", \"O2\", \"PO3\", \"POz\", \"Oz\"]\n",
    "\n",
    "tmin, tmax = -0.2, 1.0\n",
    "baseline = None\n",
    "baseline_win = (-0.2, 0.0) \n",
    "\n",
    "def _existing(ch_names, roi):\n",
    "    roi_set=set(roi)\n",
    "    return[ch for ch in ch_names if ch in roi_set]\n",
    "\n",
    "def _roi_mean_evoked(evoked,roi_chs,new_name):\n",
    "    evk = evoked.copy().pick_channels(roi_chs)\n",
    "    data = evk.data.mean(axis=0, keepdims=True)\n",
    "    info = mne.create_info([new_name], sfreq=evk.info[\"sfreq\"], ch_types=\"misc\")\n",
    "    out = mne.EvokedArray(data, info, tmin=evk.times[0], nave=evk.nave)\n",
    "    return out\n",
    "\n",
    "results={}\n",
    "\n",
    "#Main loop\n",
    "for subj in subjects:\n",
    "    results[subj] = {c: {} for c in conds}\n",
    "\n",
    "    epo_path = os.path.join(EPOCHS_DIR, f\"{subj}-raw-ica-reject-ERP-epo.fif\")\n",
    "    epochs = mne.read_epochs(epo_path, preload=True)\n",
    "\n",
    "    epochs = epochs.copy().pick(\"eeg\").crop(tmin=tmin, tmax=tmax)\n",
    "\n",
    "    missing = [c for c in conds if c not in epochs.event_id]\n",
    "    if missing:\n",
    "        raise RuntimeError(\n",
    "            f\"{subj}: cond not in epochs.event_id: {missing}\\n\"\n",
    "            f\"existing keys (head): {list(epochs.event_id.keys())[:30]}\"\n",
    "        )\n",
    "\n",
    "    frontal_chs = _existing(epochs.ch_names, frontal_roi)\n",
    "    occipital_chs = _existing(epochs.ch_names, occipital_roi)\n",
    "    if (len(frontal_chs) == 0) or (len(occipital_chs) == 0):\n",
    "        raise RuntimeError(\n",
    "            f\"{subj}: ROI channels missing.\\n\"\n",
    "            f\"frontal_found={frontal_chs}, occipital_found={occipital_chs}\\n\"\n",
    "            f\"example ch_names: {epochs.ch_names[:20]}\"\n",
    "        )\n",
    "\n",
    "    for band, fmin, fmax in iter_freqs:\n",
    "        ep_band = epochs.copy().filter(\n",
    "            fmin, fmax,\n",
    "            method=\"iir\",\n",
    "            iir_params=dict(order=4,ftype=\"butter\")\n",
    "        )\n",
    "\n",
    "        for cond in conds:\n",
    "            ep = ep_band[cond].copy()\n",
    "            ep.subtract_evoked()\n",
    "            ep.apply_hilbert(envelope=True)\n",
    "            evoked_env = ep.average()\n",
    "            evoked_ers = evoked_env.copy()\n",
    "            rescale(evoked_ers.data, evoked_ers.times, baseline=baseline_win, mode=\"percent\", copy=False)\n",
    "\n",
    "            frontal_ers = _roi_mean_evoked(evoked_ers, frontal_chs, f\"{subj}|{cond}|{band}|frontal_ERS%\")\n",
    "            occipital_ers = _roi_mean_evoked(evoked_ers, occipital_chs, f\"{subj}|{cond}|{band}|occipital_ERS%\")\n",
    "\n",
    "            results[subj][cond][band] = {\"frontal\": frontal_ers, \"occipital\": occipital_ers}\n",
    "\n",
    "        del ep_band\n",
    "\n",
    "    del epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7136fe-ed67-4d8a-a660-410273de71d8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#figure for the above step\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.stats import bootstrap_confidence_interval\n",
    "from mne.stats import bootstrap_confidence_interval\n",
    "from mne.baseline import rescale\n",
    "%matplotlib qt\n",
    "\n",
    "def stat_fun_mean(x):\n",
    "    \"\"\"Bootstrap statistic: mean across subjects.\"\"\"\n",
    "    return np.mean(x, axis=0)\n",
    "\n",
    "def get_subject_matrix(results, subjects, cond, band, roi):\n",
    "    \"\"\"Stack subject-wise ROI timecourses into (n_subj, n_times).\"\"\"\n",
    "    series = []\n",
    "    for s in subjects:\n",
    "        evk = results[s][cond][band][roi]  # EvokedArray, shape (1, n_times)\n",
    "        series.append(evk.data[0])\n",
    "    X = np.stack(series, axis=0)\n",
    "    times = results[subjects[0]][cond][band][roi].times * 1e3  # ms\n",
    "    return X, times\n",
    "\n",
    "\n",
    "#plot\n",
    "def plot_roi_ers_by_band(results, subjects, conds, iter_freqs, roi=\"frontal\"):\n",
    "    fig, axes = plt.subplots(len(iter_freqs), 1, figsize=(10, 6), sharex=True, sharey=True)\n",
    "    if len(iter_freqs) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    cond_colors = plt.colormaps[\"tab10\"](np.linspace(0, 1, len(conds)))\n",
    "\n",
    "    for ax, (freq_name, fmin, fmax) in zip(axes, iter_freqs):\n",
    "        for cond, color in zip(conds, cond_colors):\n",
    "            X, times = get_subject_matrix(results, subjects, cond, freq_name, roi)\n",
    "            mean = X.mean(axis=0)\n",
    "            ci_low, ci_up = bootstrap_confidence_interval(\n",
    "                X, random_state=0, stat_fun=stat_fun_mean\n",
    "            )\n",
    "\n",
    "            ax.plot(times, mean, color=color, linewidth=2, label=cond)\n",
    "            ax.fill_between(times, mean - ci_low, mean + ci_up, color=color, alpha=0.18)\n",
    "\n",
    "        ax.axhline(0, linestyle=\"--\", color=\"grey\", linewidth=1.2)\n",
    "        ax.grid(True)\n",
    "        ax.set_ylabel(\"ERS (%)\")\n",
    "        ax.set_title(f\"{roi} | {freq_name} ({fmin}-{fmax} Hz)\")\n",
    "\n",
    "    axes[-1].set_xlabel(\"Time (ms)\")\n",
    "    axes[0].legend(fontsize=8, loc=\"upper right\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "fig_f = plot_roi_ers_by_band(\n",
    "    results, subjects, conds, iter_freqs, roi=\"frontal\"\n",
    ")\n",
    "\n",
    "fig_o = plot_roi_ers_by_band(\n",
    "    results, subjects, conds, iter_freqs, roi=\"occipital\"\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03890c3-8496-4f26-806e-5b8e9aac8856",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Cluster permutation across channels, with TFR (cycle = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9099e56a-262c-49ef-827c-c1c6a0dcdec4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#compute TFR- cycle 7\n",
    "\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "\n",
    "subjects = [\"sub_m_1_02\", \"sub_m_1_06\", \"sub_m_1_10\",\"sub_m_1_14\",\"sub_m_1_18\",\"sub_m_1_22\",\"sub_m_1_26\",\"sub_m_1_30\",\"sub_m_1_34\",\"sub_m_1_38\",\"sub_m_1_42\",\"sub_m_1_46\",\n",
    "            \"sub_m_2_04\",\"sub_m_2_08\",\"sub_m_2_12\",\"sub_m_2_16\",\"sub_m_2_20\",\"sub_m_2_24\",\"sub_m_2_28\",\"sub_m_2_32\",\"sub_m_2_36\",\"sub_m_2_40\",\"sub_m_2_44\",\n",
    "            \"sub_p_1_01\",\"sub_p_1_05\",\"sub_p_1_09\",\"sub_p_1_13\",\"sub_p_1_17\",\"sub_p_1_21\",\"sub_p_1_25\",\"sub_p_1_29\",\"sub_p_1_33\",\"sub_p_1_35\",\"sub_p_1_37\",\"sub_p_1_41\",\"sub_p_1_45\",\n",
    "            \"sub_p_2_03\",\"sub_p_2_07\",\"sub_p_2_11\",\"sub_p_2_15\",\"sub_p_2_19\",\"sub_p_2_27\",\"sub_p_2_31\",\"sub_p_2_39\",\"sub_p_2_43\",\"sub_p_2_47\",]  # 被试数据\n",
    "\n",
    "EPOCHS_DIR = r\"F:/epochs_ITC\"\n",
    "OUT_DIR = r\"F:/tfr_single_trial_cycle_8\"\n",
    "\n",
    "freqs = np.arange(2, 30, 1)\n",
    "n_cycles = freqs / 7\n",
    "tmin,tmax=(-0.2,1)\n",
    "\n",
    "out_data = os.path.join(OUT_DIR, f\"{subj}_power.npy\")\n",
    "out_meta = os.path.join(OUT_DIR, f\"{subj}_meta.npz\")\n",
    "\n",
    "for subj in subjects:\n",
    "    epo_path = os.path.join(EPOCHS_DIR, f\"{subj}-raw-ica-reject-ERP-epo.fif\")\n",
    "    epochs = mne.read_epochs(epo_path, preload=True).crop(tmin=tmin, tmax=tmax)\n",
    "    epochs = mne.read_epochs(epo_path, preload=True).crop(tmin=tmin, tmax=tmax)\n",
    "    print(\"[epochs] len:\", len(epochs))\n",
    "    \n",
    "    power = epochs.compute_tfr(\n",
    "    method=\"morlet\",\n",
    "    freqs=freqs,\n",
    "    n_cycles=n_cycles,\n",
    "    tmin=epochs.tmin,\n",
    "    tmax=1.0,\n",
    "    average=False,\n",
    "    return_itc=False,\n",
    "    decim=1)\n",
    "    power=power.apply_baseline(baseline=(-0.2,0),mode=\"logratio\")\n",
    "    print(\"[tfr] type:\", type(power))\n",
    "    print(\"[tfr] shape:\", power.data.shape)  # (n_trials, n_ch, n_freq, n_time) expected\n",
    "    assert power.data.ndim == 4\n",
    "    assert power.data.shape[0] == len(epochs)\n",
    "\n",
    "    out_data = os.path.join(OUT_DIR, f\"{subj}_power.npy\")\n",
    "    out_meta = os.path.join(OUT_DIR, f\"{subj}_meta.npz\")\n",
    "\n",
    "    np.save(out_data, power.data.astype(np.float32))\n",
    "    np.savez(\n",
    "        out_meta,\n",
    "        ch_names=np.array(power.ch_names, dtype=object),\n",
    "        freqs=power.freqs.astype(np.float32),\n",
    "        times=power.times.astype(np.float32),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc665eb-2819-4bcb-a3b6-e0857578857c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cluster permutation\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"QT_API\"] = \"pyqt5\"\n",
    "%matplotlib qt\n",
    "\n",
    "subjects = [\"sub_m_1_02\", \"sub_m_1_06\", \"sub_m_1_10\",\"sub_m_1_14\",\"sub_m_1_18\",\"sub_m_1_22\",\"sub_m_1_26\",\"sub_m_1_30\",\"sub_m_1_34\",\"sub_m_1_38\",\"sub_m_1_42\",\"sub_m_1_46\",\n",
    "            \"sub_m_2_04\",\"sub_m_2_08\",\"sub_m_2_12\",\"sub_m_2_16\",\"sub_m_2_20\",\"sub_m_2_24\",\"sub_m_2_28\",\"sub_m_2_32\",\"sub_m_2_36\",\"sub_m_2_40\",\"sub_m_2_44\",\n",
    "            \"sub_p_1_01\",\"sub_p_1_05\",\"sub_p_1_09\",\"sub_p_1_13\",\"sub_p_1_17\",\"sub_p_1_21\",\"sub_p_1_25\",\"sub_p_1_29\",\"sub_p_1_33\",\"sub_p_1_35\",\"sub_p_1_37\",\"sub_p_1_41\",\"sub_p_1_45\",\n",
    "            \"sub_p_2_03\",\"sub_p_2_07\",\"sub_p_2_11\",\"sub_p_2_15\",\"sub_p_2_19\",\"sub_p_2_27\",\"sub_p_2_31\",\"sub_p_2_39\",\"sub_p_2_43\",\"sub_p_2_47\"]\n",
    "\n",
    "OUT_DIR = r\"F:/tfr_single_trial_cycle_8\"\n",
    "EPOCHS_DIR = r\"F:/epochs_ITC\"\n",
    "\n",
    "conds = {\"int_rep\": \"cue/sat/int/rep\", \"int_swi\": \"cue/sat/int/swi\", \"ext_rep\": \"cue/sat/ext/rep\",\n",
    "    \"ext_swi\": \"cue/sat/ext/swi\"}\n",
    "\n",
    "roi = [\"Fz\", \"F1\", \"F2\", \"FCz\", \"FC1\", \"FC2\", \"Cz\"]\n",
    "\n",
    "bands = {\"theta\": (4.0, 7.0),\"alpha\": (8.0, 14.0)}\n",
    "\n",
    "BIN = 0.25\n",
    "N_PERM = 2000\n",
    "ALPHA = 0.05\n",
    "TAIL = 0\n",
    "SEED = 42\n",
    "\n",
    "def safe_cond_indices(epochs, cond):\n",
    "    cond_sel = epochs[cond].selection\n",
    "    idx = np.flatnonzero(np.isin(epochs.selection, cond_sel))\n",
    "    return idx\n",
    "\n",
    "def cond_mean(X, epochs, cond):\n",
    "    idx = safe_cond_indices(epochs, cond)\n",
    "    if len(idx) == 0:\n",
    "        raise RuntimeError(f\"No trials for {cond}\")\n",
    "    return X[idx].mean(axis=0)  # (ch, freq, time)\n",
    "\n",
    "def band_average(M, freqs, f_lo, f_hi):\n",
    "    fmask = (freqs >= f_lo) & (freqs <= f_hi)\n",
    "    if not np.any(fmask):\n",
    "        raise RuntimeError(f\"No freq bins in [{f_lo}, {f_hi}]\")\n",
    "    return M[:, fmask, :].mean(axis=1)  # (ch, time)\n",
    "\n",
    "def build_subject_effects(subj, freqs_ref=None, times_ref=None, ch_ref=None):\n",
    "    power_path = os.path.join(OUT_DIR, f\"{subj}_power.npy\")\n",
    "    meta_path  = os.path.join(OUT_DIR, f\"{subj}_meta.npz\")\n",
    "    epo_path   = os.path.join(EPOCHS_DIR, f\"{subj}-raw-ica-reject-ERP-epo.fif\")\n",
    "\n",
    "    if not (os.path.exists(power_path) and os.path.exists(meta_path) and os.path.exists(epo_path)):\n",
    "        return None, None, None, f\"missing file(s)\"\n",
    "\n",
    "    X = np.load(power_path, mmap_mode=\"r\")  # (trial, ch, freq, time)\n",
    "    meta = np.load(meta_path, allow_pickle=True)\n",
    "    ch_names = meta[\"ch_names\"].tolist()\n",
    "    freqs = meta[\"freqs\"]\n",
    "    times = meta[\"times\"]\n",
    "\n",
    "    # axis consistency check\n",
    "    if freqs_ref is not None:\n",
    "        if len(freqs) != len(freqs_ref) or not np.allclose(freqs, freqs_ref):\n",
    "            return None, None, None, \"freq mismatch\"\n",
    "    if times_ref is not None:\n",
    "        if len(times) != len(times_ref) or not np.allclose(times, times_ref):\n",
    "            return None, None, None, \"time mismatch\"\n",
    "    if ch_ref is not None:\n",
    "        if ch_names != ch_ref:\n",
    "            return None, None, None, \"channel order mismatch\"\n",
    "\n",
    "    # epochs: only used for condition trial indexing\n",
    "    epochs = mne.read_epochs(epo_path, preload=True).crop(tmin=times[0], tmax=times[-1])\n",
    "\n",
    "    if X.shape[0] != len(epochs):\n",
    "        return None, None, None, f\"trial count mismatch: X={X.shape[0]} vs epochs={len(epochs)}\"\n",
    "\n",
    "    # condition means: (ch,freq,time)\n",
    "    M = {k: cond_mean(X, epochs, c) for k, c in conds.items()}\n",
    "\n",
    "    # effects in full TF (ch,freq,time)\n",
    "    INT = 0.5 * (M[\"int_rep\"] + M[\"int_swi\"])\n",
    "    EXT = 0.5 * (M[\"ext_rep\"] + M[\"ext_swi\"])\n",
    "    D_int_ext = INT - EXT\n",
    "\n",
    "    SWI = 0.5 * (M[\"int_swi\"] + M[\"ext_swi\"])\n",
    "    REP = 0.5 * (M[\"int_rep\"] + M[\"ext_rep\"])\n",
    "    D_swi_rep = SWI - REP\n",
    "\n",
    "    D_inter = (M[\"int_swi\"] - M[\"int_rep\"]) - (M[\"ext_swi\"] - M[\"ext_rep\"])\n",
    "\n",
    "    out = {\n",
    "        \"rule_switch_int_ext\": D_int_ext,\n",
    "        \"att_switch_swi_rep\": D_swi_rep,\n",
    "        \"interaction\": D_inter,\n",
    "    }\n",
    "    return out, freqs, times, None\n",
    "\n",
    "def make_time_bins(times, bin_s=0.25):\n",
    "    t0, t1 = float(times[0]), float(times[-1])\n",
    "    edges = np.arange(t0, t1 + 1e-9, bin_s)\n",
    "    if edges[-1] < t1:\n",
    "        edges = np.append(edges, t1)\n",
    "    bins = []\n",
    "    for a, b in zip(edges[:-1], edges[1:]):\n",
    "        mask = (times >= a) & (times < b) if b < t1 else (times >= a) & (times <= b)\n",
    "        if mask.any():\n",
    "            bins.append((a, b, mask))\n",
    "    return bins\n",
    "\n",
    "def run_cluster_time_ch(X_subj_ch_time, info, adjacency, alpha=0.05, n_perm=2000, tail=0, seed=42):\n",
    "    # MNE expects (n_samples, n_times, n_space) for spatio-temporal with adjacency over space\n",
    "    X_st = np.transpose(X_subj_ch_time, (0, 2, 1))  # -> (subj, time, ch)\n",
    "\n",
    "    T_obs, clusters, pvals, H0 = mne.stats.spatio_temporal_cluster_1samp_test(\n",
    "        X_st,\n",
    "        adjacency=adjacency,\n",
    "        n_permutations=n_perm,\n",
    "        threshold=None,   # uses t-threshold internally (like your logs showed ~2.01)\n",
    "        tail=tail,\n",
    "        out_type=\"mask\",\n",
    "        seed=seed,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # Build sig mask over (time,ch)\n",
    "    sig = np.zeros(T_obs.shape, dtype=bool)  # (time,ch)\n",
    "    for cl, p in zip(clusters, pvals):\n",
    "        if p < alpha:\n",
    "            sig |= cl  # cl is boolean mask if out_type=\"mask\"\n",
    "\n",
    "    # convert to (ch,time) for topomap usage\n",
    "    sig_ch_time = sig.T  # (ch,time)\n",
    "    return T_obs, clusters, pvals, sig_ch_time\n",
    "\n",
    "# 1) Load one subject to anchor info/adjacency + axes\n",
    "anchor = subjects[0]\n",
    "epo_anchor = os.path.join(EPOCHS_DIR, f\"{anchor}-raw-ica-reject-ERP-epo.fif\")\n",
    "epochs_anchor = mne.read_epochs(epo_anchor, preload=True)\n",
    "info = epochs_anchor.copy().pick_types(eeg=True).info\n",
    "\n",
    "adjacency, ch_names_adj = mne.channels.find_ch_adjacency(info, ch_type=\"eeg\")\n",
    "print(\"[adjacency] shape:\", adjacency.shape)\n",
    "\n",
    "# 2) Build subject stacks for each effect+band\n",
    "effects = [\"att_switch_swi_rep\", \"rule_switch_int_ext\", \"interaction\"]\n",
    "\n",
    "# store: band -> effect -> list of (ch,time)\n",
    "stack = {band: {eff: [] for eff in effects} for band in bands.keys()}\n",
    "\n",
    "freqs_ref = None\n",
    "times_ref = None\n",
    "ch_ref = None\n",
    "kept = 0\n",
    "\n",
    "for subj in subjects:\n",
    "    out, freqs, times, err = build_subject_effects(subj, freqs_ref, times_ref, ch_ref)\n",
    "    if err is not None:\n",
    "        print(\"SKIP\", subj, \"->\", err)\n",
    "        continue\n",
    "\n",
    "    # lock references on first kept subject\n",
    "    if freqs_ref is None:\n",
    "        freqs_ref = freqs.copy()\n",
    "        times_ref = times.copy()\n",
    "        # channel names from your meta (must match X channel order)\n",
    "        meta0 = np.load(os.path.join(OUT_DIR, f\"{subj}_meta.npz\"), allow_pickle=True)\n",
    "        ch_ref = meta0[\"ch_names\"].tolist()\n",
    "\n",
    "    # band-average and collect\n",
    "    for band_name, (f_lo, f_hi) in bands.items():\n",
    "        for eff in effects:\n",
    "            D_ch_f_t = out[eff]  # (ch,freq,time)\n",
    "            D_ch_t = band_average(D_ch_f_t, freqs_ref, f_lo, f_hi)  # (ch,time)\n",
    "            stack[band_name][eff].append(D_ch_t.astype(np.float32))\n",
    "\n",
    "    kept += 1\n",
    "\n",
    "print(\"Kept subjects:\", kept)\n",
    "\n",
    "# 3) Cluster + plot: many topomaps per time-bin with black dots\n",
    "time_bins = make_time_bins(times_ref, BIN)\n",
    "print(\"n_time_bins:\", len(time_bins), \"bin_s:\", BIN)\n",
    "\n",
    "for band_name, (f_lo, f_hi) in bands.items():\n",
    "    # compute shared color limits per band across all effects/bins\n",
    "    all_maps = []\n",
    "    for eff in effects:\n",
    "        X_eff = np.stack(stack[band_name][eff], axis=0)  # (subj,ch,time)\n",
    "        all_maps.append(X_eff.mean(axis=0))              # (ch,time)\n",
    "    all_maps = np.concatenate(all_maps, axis=1)          # (ch, time*effects)\n",
    "    vmin, vmax = np.percentile(all_maps, [5, 95])\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "    fig.suptitle(f\"{band_name.upper()} ({f_lo:.0f}-{f_hi:.0f} Hz) — Cluster permutation topomaps\", y=0.98)\n",
    "\n",
    "    # layout: rows = effects, cols = time bins\n",
    "    n_rows = len(effects)\n",
    "    n_cols = len(time_bins)\n",
    "\n",
    "    # for each effect, run cluster once (over channels×time)\n",
    "    for r, eff in enumerate(effects):\n",
    "        X_eff = np.stack(stack[band_name][eff], axis=0)  # (subj,ch,time)\n",
    "\n",
    "        print(f\"\\n[{band_name} | {eff}] X shape:\", X_eff.shape)\n",
    "        T_obs, clusters, pvals, sig_ch_time = run_cluster_time_ch(\n",
    "            X_eff, info, adjacency, alpha=ALPHA, n_perm=N_PERM, tail=TAIL, seed=SEED\n",
    "        )\n",
    "\n",
    "        n_sig = int(np.sum(pvals < ALPHA))\n",
    "        print(f\"[{band_name} | {eff}] n_clusters={len(clusters)}  n_sig_clusters={n_sig}\")\n",
    "\n",
    "        # mean effect for plotting\n",
    "        mean_ch_t = X_eff.mean(axis=0)  # (ch,time)\n",
    "\n",
    "        # plot each time bin topomap\n",
    "        for c, (ta, tb, tmask) in enumerate(time_bins):\n",
    "            ax = fig.add_subplot(n_rows, n_cols, r * n_cols + c + 1)\n",
    "\n",
    "            # data for this bin: mean over time window -> (ch,)\n",
    "            dat = mean_ch_t[:, tmask].mean(axis=1)\n",
    "\n",
    "            # significant channels in this bin (any timepoint within bin significant)\n",
    "            sig_ch = sig_ch_time[:, tmask].any(axis=1)\n",
    "\n",
    "            mne.viz.plot_topomap(dat, info, axes=ax, show=False, vlim=(vmin, vmax), contours=0, sensors=False, mask=sig_ch, mask_params=dict(markersize=6,\n",
    "                                                                                                                                             markerfacecolor=\"k\",\n",
    "                                                                                                                                             markeredgecolor=\"k\"))\n",
    "\n",
    "            ax.set_title(f\"{ta:+.2f}–{tb:+.2f}s\", fontsize=8)\n",
    "            if c == 0:\n",
    "                ax.set_ylabel(eff, fontsize=10)\n",
    "\n",
    "    # add one shared colorbar\n",
    "    # fake mappable for colorbar\n",
    "    import matplotlib as mpl\n",
    "    norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    sm = mpl.cm.ScalarMappable(norm=norm, cmap=plt.get_cmap(\"RdBu_r\"))\n",
    "    sm.set_array([])\n",
    "\n",
    "    cbar = fig.colorbar(sm, ax=fig.axes, fraction=0.02, pad=0.01)\n",
    "    cbar.set_label(\"Power (baseline-corrected logratio / dB-like)\", rotation=90)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de16dc-b3e5-4963-9716-a86051ab62b2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#replot the figure\n",
    "\n",
    "%matplotlib qt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "\n",
    "time_bins = make_time_bins(times_ref, BIN)\n",
    "print(\"n_time_bins:\", len(time_bins), \"bin_s:\", BIN)\n",
    "\n",
    "for band_name, (f_lo, f_hi) in bands.items():\n",
    "    all_maps = []\n",
    "    for eff in effects:\n",
    "        X_eff = np.stack(stack[band_name][eff], axis=0)  \n",
    "        all_maps.append(X_eff.mean(axis=0))           \n",
    "    all_maps = np.concatenate(all_maps, axis=1)\n",
    "    vmin, vmax = np.percentile(all_maps, [5, 95])\n",
    "\n",
    "    n_rows = len(effects)\n",
    "    n_cols = len(time_bins)\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "    fig.suptitle(\n",
    "        f\"{band_name.upper()} ({f_lo:.0f}-{f_hi:.0f} Hz) — Cluster permutation topomaps\",\n",
    "        y=0.98\n",
    "    )\n",
    "\n",
    "    # +1 column reserved for colorbar\n",
    "    gs = gridspec.GridSpec(\n",
    "        n_rows,\n",
    "        n_cols + 1,\n",
    "        width_ratios=[1] * n_cols + [0.05],\n",
    "        wspace=0.25,\n",
    "        hspace=0.3\n",
    "    )\n",
    "\n",
    "    #plot\n",
    "    for r, eff in enumerate(effects):\n",
    "        X_eff = np.stack(stack[band_name][eff], axis=0)  # (subj,ch,time)\n",
    "\n",
    "        T_obs, clusters, pvals, sig_ch_time = run_cluster_time_ch(\n",
    "            X_eff, info, adjacency,\n",
    "            alpha=ALPHA, n_perm=N_PERM, tail=TAIL, seed=SEED\n",
    "        )\n",
    "\n",
    "        mean_ch_t = X_eff.mean(axis=0)  # (ch,time)\n",
    "\n",
    "        for c, (ta, tb, tmask) in enumerate(time_bins):\n",
    "            ax = fig.add_subplot(gs[r, c])\n",
    "\n",
    "            dat = mean_ch_t[:, tmask].mean(axis=1)\n",
    "            sig_ch = sig_ch_time[:, tmask].any(axis=1)\n",
    "\n",
    "            mne.viz.plot_topomap(\n",
    "                dat,\n",
    "                info,\n",
    "                axes=ax,\n",
    "                show=False,\n",
    "                vlim=(vmin, vmax),\n",
    "                contours=0,\n",
    "                sensors=False,\n",
    "                mask=sig_ch,\n",
    "                mask_params=dict(\n",
    "                    markersize=6,\n",
    "                    markerfacecolor=\"k\",\n",
    "                    markeredgecolor=\"k\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "            ax.set_title(f\"{ta:+.2f}–{tb:+.2f}s\", fontsize=8)\n",
    "            if c == 0:\n",
    "                ax.set_ylabel(eff, fontsize=10)\n",
    "\n",
    "    #  colorbar (single, dedicated axis) \n",
    "    cax = fig.add_subplot(gs[:, -1])\n",
    "    norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    sm = mpl.cm.ScalarMappable(norm=norm, cmap=\"RdBu_r\")\n",
    "    sm.set_array([])\n",
    "\n",
    "    cbar = fig.colorbar(sm, cax=cax)\n",
    "    cbar.set_label(\"Power (baseline-corrected logratio)\", rotation=90)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d990e298-12ff-463d-bfb4-4f3433e228fb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#central alpha - exploration\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.stats import permutation_cluster_1samp_test\n",
    "os.environ[\"QT_API\"] = \"pyqt5\"\n",
    "%matplotlib qt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.stats import permutation_cluster_1samp_test\n",
    "os.environ[\"QT_API\"] = \"pyqt5\"\n",
    "%matplotlib qt\n",
    "\n",
    "OUT_DIR = r\"F:/tfr_single_trial_cycle_8\"\n",
    "EPOCHS_DIR = r\"F:/epochs_ITC\"\n",
    "\n",
    "subjects = [\"sub_m_1_02\", \"sub_m_1_06\", \"sub_m_1_10\",\"sub_m_1_14\",\"sub_m_1_18\",\"sub_m_1_22\",\"sub_m_1_26\",\"sub_m_1_30\",\"sub_m_1_34\",\"sub_m_1_38\",\"sub_m_1_42\",\"sub_m_1_46\",\n",
    "            \"sub_m_2_04\",\"sub_m_2_08\",\"sub_m_2_12\",\"sub_m_2_16\",\"sub_m_2_20\",\"sub_m_2_24\",\"sub_m_2_28\",\"sub_m_2_32\",\"sub_m_2_36\",\"sub_m_2_40\",\"sub_m_2_44\",\n",
    "            \"sub_p_1_01\",\"sub_p_1_05\",\"sub_p_1_09\",\"sub_p_1_13\",\"sub_p_1_17\",\"sub_p_1_21\",\"sub_p_1_25\",\"sub_p_1_29\",\"sub_p_1_33\",\"sub_p_1_35\",\"sub_p_1_37\",\"sub_p_1_41\",\"sub_p_1_45\",\n",
    "            \"sub_p_2_03\",\"sub_p_2_07\",\"sub_p_2_11\",\"sub_p_2_15\",\"sub_p_2_19\",\"sub_p_2_27\",\"sub_p_2_31\",\"sub_p_2_39\",\"sub_p_2_43\",\"sub_p_2_47\"]\n",
    "\n",
    "conds = {\"int_rep\": \"cue/sat/int/rep\", \"int_swi\": \"cue/sat/int/swi\", \"ext_rep\": \"cue/sat/ext/rep\",\n",
    "    \"ext_swi\": \"cue/sat/ext/swi\"}\n",
    "\n",
    "roi = [\"O1\", \"O2\", \"Oz\", \"PO3\", \"PO4\", \"POz\", \"P1\", \"P2\", \"Pz\",\"P3\", \"P4\",\"CP1\", \"CP2\", \"CPz\"]\n",
    "alpha_lo, alpha_hi = 8.0, 15.0\n",
    "EFFECTS_TO_TEST = [\"int_ext\", \"swi_rep\", \"interaction\"]\n",
    "\n",
    "#cluster setting\n",
    "N_PERM=5000\n",
    "ALPHA=0.05\n",
    "TAIL= -1\n",
    "\n",
    "#Construct subject-level(same as above\n",
    "def cond_mean(X, epochs, cond):\n",
    "    cond_sel = epochs[cond].selection\n",
    "    idx = np.flatnonzero(np.isin(epochs.selection, cond_sel))\n",
    "    assert len(idx) > 0, f\"No trials for {cond}\"\n",
    "    return X[idx].mean(axis=0) \n",
    "\n",
    "def roi_alpha(Mk, roi_idx, fidx): #MK: 来自上一步;fidx: theta \n",
    "    return Mk[roi_idx][:, fidx, :].mean(axis=(0,1))\n",
    "\n",
    "#Load one subject, compute ROI×theta timecourses for effects\n",
    "def build_subject_effects(subj):\n",
    "    def roi_alpha_time(Mk, roi_idx, fidx):\n",
    "        return Mk[roi_idx][:, fidx, :].mean(axis=(0, 1)) \n",
    "        \n",
    "    power_path = os.path.join(OUT_DIR, f\"{subj}_power.npy\")\n",
    "    meta_path  = os.path.join(OUT_DIR, f\"{subj}_meta.npz\")\n",
    "    epo_path   = os.path.join(EPOCHS_DIR, f\"{subj}-raw-ica-reject-ERP-epo.fif\")\n",
    "\n",
    "    if not (os.path.exists(power_path) and os.path.exists(meta_path) and os.path.exists(epo_path)):\n",
    "        return None, None, f\"missing file(s)\"\n",
    "\n",
    "    X = np.load(power_path, mmap_mode=\"r\")  # (n_trials, n_ch, n_freq, n_time)\n",
    "    meta = np.load(meta_path, allow_pickle=True)\n",
    "    ch_names = meta[\"ch_names\"].tolist()\n",
    "    freqs = meta[\"freqs\"].astype(float)\n",
    "    times = meta[\"times\"].astype(float)\n",
    "\n",
    "    # ROI index\n",
    "    try:\n",
    "        roi_idx = [ch_names.index(ch) for ch in roi]\n",
    "    except ValueError:\n",
    "        return None, None, \"missing ROI channels\"\n",
    "\n",
    "    # theta index\n",
    "    fmask = (freqs >= alpha_lo) & (freqs <= alpha_hi)\n",
    "    if not np.any(fmask):\n",
    "        return None, None, \"no alpha bins\"\n",
    "    fidx = np.where(fmask)[0]\n",
    "\n",
    "    # load epochs just for selection mapping\n",
    "    epochs = mne.read_epochs(epo_path, preload=True).crop(tmin=times[0], tmax=times[-1])\n",
    "\n",
    "    # Alignment Check\n",
    "    if X.shape[0] != len(epochs):\n",
    "        return None, None, f\"trial mismatch: X={X.shape[0]} epochs={len(epochs)}\"\n",
    "\n",
    "    # condition means (subject-level)\n",
    "    M = {k: cond_mean(X, epochs, c) for k, c in conds.items()}\n",
    "\n",
    "    # effects (ch,freq,time)\n",
    "    INT = 0.5 * (M[\"int_rep\"] + M[\"int_swi\"])\n",
    "    EXT = 0.5 * (M[\"ext_rep\"] + M[\"ext_swi\"])\n",
    "    D_int_ext = INT - EXT\n",
    "\n",
    "    SWI = 0.5 * (M[\"int_swi\"] + M[\"ext_swi\"])\n",
    "    REP = 0.5 * (M[\"int_rep\"] + M[\"ext_rep\"])\n",
    "    D_swi_rep = SWI - REP\n",
    "\n",
    "    D_interaction = (M[\"int_swi\"] - M[\"int_rep\"]) - (M[\"ext_swi\"] - M[\"ext_rep\"])\n",
    "\n",
    "    # ROI×theta -> timecourses\n",
    "    out = {\n",
    "        \"int_ext\": roi_alpha_time(D_int_ext, roi_idx, fidx),\n",
    "        \"swi_rep\": roi_alpha_time(D_swi_rep, roi_idx, fidx),\n",
    "        \"interaction\": roi_alpha_time(D_interaction, roi_idx, fidx),\n",
    "    }\n",
    "    return out, times, None\n",
    "\n",
    "def run_cluster_1samp(X_subj_time, times, title):\n",
    "    X_subj_time = np.asarray(X_subj_time, dtype=float)\n",
    "    assert X_subj_time.ndim == 2, \"expect (subjects, time)\"\n",
    "    assert X_subj_time.shape[1] == len(times), \"time length mismatch\"\n",
    "\n",
    "    T_obs, clusters, pvals, H0 = permutation_cluster_1samp_test(\n",
    "        X_subj_time,\n",
    "        n_permutations=N_PERM,\n",
    "        tail=TAIL,\n",
    "        threshold=None,     # MNE picks a default threshold\n",
    "        out_type=\"mask\",\n",
    "        n_jobs=1,\n",
    "        seed=0,\n",
    "    )\n",
    "\n",
    "    # report significant clusters\n",
    "    sig = np.where(pvals < ALPHA)[0]\n",
    "    print(f\"\\n[{title}] n_subjects={X_subj_time.shape[0]}  n_sig_clusters={len(sig)}\")\n",
    "    for i in sig:\n",
    "        mask = clusters[i] \n",
    "        t0, t1 = times[mask][0], times[mask][-1]\n",
    "        print(f\"  cluster {i}: p={pvals[i]:.4f}, time=[{t0:.3f},{t1:.3f}]s, mass={T_obs[mask].sum():.3f}\")\n",
    "\n",
    "    # quick plot: mean ± SEM + mark significant clusters\n",
    "    mean = X_subj_time.mean(axis=0)\n",
    "    sem = X_subj_time.std(axis=0, ddof=1) / np.sqrt(X_subj_time.shape[0])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    ax.plot(times, mean)\n",
    "    ax.fill_between(times, mean - sem, mean + sem, alpha=0.2)\n",
    "    ax.axhline(0, color=\"k\", ls=\"--\", lw=1)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"ROI×alpha contrast (logratio power)\")\n",
    "\n",
    "    # shade significant clusters\n",
    "    for i in sig:\n",
    "        mask = clusters[i]\n",
    "        ax.axvspan(times[mask][0], times[mask][-1], alpha=0.15)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return T_obs, clusters, pvals, H0\n",
    "\n",
    "# main: build subject matrices \n",
    "effects_all = {eff: [] for eff in EFFECTS_TO_TEST}\n",
    "times_ref = None\n",
    "kept = 0\n",
    "\n",
    "for subj in subjects:\n",
    "    out, times, err = build_subject_effects(subj)\n",
    "    if err is not None:\n",
    "        print(\"SKIP\", subj, \"->\", err)\n",
    "        continue\n",
    "\n",
    "    if times_ref is None:\n",
    "        times_ref = times.copy()\n",
    "    else:\n",
    "        if len(times) != len(times_ref) or not np.allclose(times, times_ref):\n",
    "            print(\"SKIP\", subj, \"-> times mismatch\")\n",
    "            continue\n",
    "\n",
    "    for eff in EFFECTS_TO_TEST:\n",
    "        effects_all[eff].append(out[eff].astype(np.float32))\n",
    "\n",
    "    kept += 1\n",
    "\n",
    "print(\"\\nKept subjects:\", kept)\n",
    "\n",
    "#  run cluster permutation per effect \n",
    "for eff in EFFECTS_TO_TEST:\n",
    "    X_eff = np.stack(effects_all[eff], axis=0)  # (subjects, time)\n",
    "    title = f\"Cluster permutation (time) — {eff} | ROI={roi} | alpha={alpha_lo}-{alpha_hi} Hz\"\n",
    "    run_cluster_1samp(X_eff, times_ref, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9c5d55-bb03-4136-8e3f-c0e045933d74",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Frontalparietal Theta (selected ROI\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.stats import permutation_cluster_1samp_test\n",
    "os.environ[\"QT_API\"] = \"pyqt5\"\n",
    "%matplotlib qt\n",
    "\n",
    "OUT_DIR = r\"F:/tfr_single_trial\"\n",
    "EPOCHS_DIR = r\"F:/epochs_ITC\"\n",
    "\n",
    "subjects = [\"sub_m_1_02\", \"sub_m_1_06\", \"sub_m_1_10\",\"sub_m_1_14\",\"sub_m_1_18\",\"sub_m_1_22\",\"sub_m_1_26\",\"sub_m_1_30\",\"sub_m_1_34\",\"sub_m_1_38\",\"sub_m_1_42\",\"sub_m_1_46\",\n",
    "            \"sub_m_2_04\",\"sub_m_2_08\",\"sub_m_2_12\",\"sub_m_2_16\",\"sub_m_2_20\",\"sub_m_2_24\",\"sub_m_2_28\",\"sub_m_2_32\",\"sub_m_2_36\",\"sub_m_2_40\",\"sub_m_2_44\",\n",
    "            \"sub_p_1_01\",\"sub_p_1_05\",\"sub_p_1_09\",\"sub_p_1_13\",\"sub_p_1_17\",\"sub_p_1_21\",\"sub_p_1_25\",\"sub_p_1_29\",\"sub_p_1_33\",\"sub_p_1_35\",\"sub_p_1_37\",\"sub_p_1_41\",\"sub_p_1_45\",\n",
    "            \"sub_p_2_03\",\"sub_p_2_07\",\"sub_p_2_11\",\"sub_p_2_15\",\"sub_p_2_19\",\"sub_p_2_27\",\"sub_p_2_31\",\"sub_p_2_39\",\"sub_p_2_43\",\"sub_p_2_47\"]\n",
    "\n",
    "conds = {\"int_rep\": \"cue/sat/int/rep\", \"int_swi\": \"cue/sat/int/swi\", \"ext_rep\": \"cue/sat/ext/rep\",\n",
    "    \"ext_swi\": \"cue/sat/ext/swi\"}\n",
    "\n",
    "roi = [\"Pz\", \"P3\", \"P4\",  \"Fz\", \"F3\", \"F4\"]\n",
    "theta_lo, theta_hi = 4.0, 8.0\n",
    "EFFECTS_TO_TEST = [\"int_ext\", \"swi_rep\", \"interaction\"]\n",
    "\n",
    "#cluster setting\n",
    "N_PERM=5000\n",
    "ALPHA=0.05\n",
    "TAIL= +1\n",
    "\n",
    "#Construct subject-level(same as above\n",
    "def cond_mean(X, epochs, cond):\n",
    "    cond_sel = epochs[cond].selection\n",
    "    idx = np.flatnonzero(np.isin(epochs.selection, cond_sel))\n",
    "    assert len(idx) > 0, f\"No trials for {cond}\"\n",
    "    return X[idx].mean(axis=0) \n",
    "\n",
    "def roi_theta(Mk, roi_idx, fidx): #MK: 来自上一步;fidx: theta \n",
    "    return Mk[roi_idx][:, fidx, :].mean(axis=(0,1))\n",
    "\n",
    "#Load one subject, compute ROI×theta timecourses for effects\n",
    "def build_subject_effects(subj):\n",
    "    def roi_theta_time(Mk, roi_idx, fidx):\n",
    "        return Mk[roi_idx][:, fidx, :].mean(axis=(0, 1)) \n",
    "        \n",
    "    power_path = os.path.join(OUT_DIR, f\"{subj}_power.npy\")\n",
    "    meta_path  = os.path.join(OUT_DIR, f\"{subj}_meta.npz\")\n",
    "    epo_path   = os.path.join(EPOCHS_DIR, f\"{subj}-raw-ica-reject-ERP-epo.fif\")\n",
    "\n",
    "    if not (os.path.exists(power_path) and os.path.exists(meta_path) and os.path.exists(epo_path)):\n",
    "        return None, None, f\"missing file(s)\"\n",
    "\n",
    "    X = np.load(power_path, mmap_mode=\"r\")  # (n_trials, n_ch, n_freq, n_time)\n",
    "    meta = np.load(meta_path, allow_pickle=True)\n",
    "    ch_names = meta[\"ch_names\"].tolist()\n",
    "    freqs = meta[\"freqs\"].astype(float)\n",
    "    times = meta[\"times\"].astype(float)\n",
    "\n",
    "    # ROI index\n",
    "    try:\n",
    "        roi_idx = [ch_names.index(ch) for ch in roi]\n",
    "    except ValueError:\n",
    "        return None, None, \"missing ROI channels\"\n",
    "\n",
    "    # theta index\n",
    "    fmask = (freqs >= theta_lo) & (freqs <= theta_hi)\n",
    "    if not np.any(fmask):\n",
    "        return None, None, \"no theta bins\"\n",
    "    fidx = np.where(fmask)[0]\n",
    "\n",
    "    # load epochs just for selection mapping\n",
    "    epochs = mne.read_epochs(epo_path, preload=True).crop(tmin=times[0], tmax=times[-1])\n",
    "\n",
    "    # Alignment Check\n",
    "    if X.shape[0] != len(epochs):\n",
    "        return None, None, f\"trial mismatch: X={X.shape[0]} epochs={len(epochs)}\"\n",
    "\n",
    "    # condition means (subject-level)\n",
    "    M = {k: cond_mean(X, epochs, c) for k, c in conds.items()}\n",
    "\n",
    "    # effects (ch,freq,time)\n",
    "    INT = 0.5 * (M[\"int_rep\"] + M[\"int_swi\"])\n",
    "    EXT = 0.5 * (M[\"ext_rep\"] + M[\"ext_swi\"])\n",
    "    D_int_ext = INT - EXT\n",
    "\n",
    "    SWI = 0.5 * (M[\"int_swi\"] + M[\"ext_swi\"])\n",
    "    REP = 0.5 * (M[\"int_rep\"] + M[\"ext_rep\"])\n",
    "    D_swi_rep = SWI - REP\n",
    "\n",
    "    D_interaction = (M[\"int_swi\"] - M[\"int_rep\"]) - (M[\"ext_swi\"] - M[\"ext_rep\"])\n",
    "\n",
    "    # ROI×theta -> timecourses\n",
    "    out = {\n",
    "        \"int_ext\": roi_theta_time(D_int_ext, roi_idx, fidx),\n",
    "        \"swi_rep\": roi_theta_time(D_swi_rep, roi_idx, fidx),\n",
    "        \"interaction\": roi_theta_time(D_interaction, roi_idx, fidx),\n",
    "    }\n",
    "    return out, times, None\n",
    "\n",
    "def run_cluster_1samp(X_subj_time, times, title):\n",
    "    X_subj_time = np.asarray(X_subj_time, dtype=float)\n",
    "    assert X_subj_time.ndim == 2, \"expect (subjects, time)\"\n",
    "    assert X_subj_time.shape[1] == len(times), \"time length mismatch\"\n",
    "\n",
    "    T_obs, clusters, pvals, H0 = permutation_cluster_1samp_test(\n",
    "        X_subj_time,\n",
    "        n_permutations=N_PERM,\n",
    "        tail=TAIL,\n",
    "        threshold=None,     # MNE picks a default threshold\n",
    "        out_type=\"mask\",\n",
    "        n_jobs=1,\n",
    "        seed=0,\n",
    "    )\n",
    "\n",
    "    # report significant clusters\n",
    "    sig = np.where(pvals < ALPHA)[0]\n",
    "    print(f\"\\n[{title}] n_subjects={X_subj_time.shape[0]}  n_sig_clusters={len(sig)}\")\n",
    "    for i in sig:\n",
    "        mask = clusters[i] \n",
    "        t0, t1 = times[mask][0], times[mask][-1]\n",
    "        print(f\"  cluster {i}: p={pvals[i]:.4f}, time=[{t0:.3f},{t1:.3f}]s, mass={T_obs[mask].sum():.3f}\")\n",
    "\n",
    "    # quick plot: mean ± SEM + mark significant clusters\n",
    "    mean = X_subj_time.mean(axis=0)\n",
    "    sem = X_subj_time.std(axis=0, ddof=1) / np.sqrt(X_subj_time.shape[0])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    ax.plot(times, mean)\n",
    "    ax.fill_between(times, mean - sem, mean + sem, alpha=0.2)\n",
    "    ax.axhline(0, color=\"k\", ls=\"--\", lw=1)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"ROI×theta contrast (logratio power)\")\n",
    "\n",
    "    # shade significant clusters\n",
    "    for i in sig:\n",
    "        mask = clusters[i]\n",
    "        ax.axvspan(times[mask][0], times[mask][-1], alpha=0.15)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return T_obs, clusters, pvals, H0\n",
    "\n",
    "# main: build subject matrices \n",
    "effects_all = {eff: [] for eff in EFFECTS_TO_TEST}\n",
    "times_ref = None\n",
    "kept = 0\n",
    "\n",
    "for subj in subjects:\n",
    "    out, times, err = build_subject_effects(subj)\n",
    "    if err is not None:\n",
    "        print(\"SKIP\", subj, \"->\", err)\n",
    "        continue\n",
    "\n",
    "    if times_ref is None:\n",
    "        times_ref = times.copy()\n",
    "    else:\n",
    "        if len(times) != len(times_ref) or not np.allclose(times, times_ref):\n",
    "            print(\"SKIP\", subj, \"-> times mismatch\")\n",
    "            continue\n",
    "\n",
    "    for eff in EFFECTS_TO_TEST:\n",
    "        effects_all[eff].append(out[eff].astype(np.float32))\n",
    "\n",
    "    kept += 1\n",
    "\n",
    "print(\"\\nKept subjects:\", kept)\n",
    "\n",
    "#  run cluster permutation per effect \n",
    "for eff in EFFECTS_TO_TEST:\n",
    "    X_eff = np.stack(effects_all[eff], axis=0)  # (subjects, time)\n",
    "    title = f\"Cluster permutation (time) — {eff} | ROI={roi} | theta={theta_lo}-{theta_hi} Hz\"\n",
    "    run_cluster_1samp(X_eff, times_ref, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd45b18-9264-4c4b-adca-28c0cae94718",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Expoloration and statistical test for Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bd9c5c-a927-4754-9010-c801c8777f3c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Compute AverageTFR\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.time_frequency import AverageTFR\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "os.environ[\"QT_API\"] = \"pyqt5\"\n",
    "%matplotlib qt\n",
    "\n",
    "subjects = [\"sub_m_1_02\", \"sub_m_1_06\", \"sub_m_1_10\",\"sub_m_1_14\",\"sub_m_1_18\",\"sub_m_1_22\",\"sub_m_1_26\",\"sub_m_1_30\",\"sub_m_1_34\",\"sub_m_1_38\",\"sub_m_1_42\",\"sub_m_1_46\",\n",
    "            \"sub_m_2_04\",\"sub_m_2_08\",\"sub_m_2_12\",\"sub_m_2_16\",\"sub_m_2_20\",\"sub_m_2_24\",\"sub_m_2_28\",\"sub_m_2_32\",\"sub_m_2_36\",\"sub_m_2_40\",\"sub_m_2_44\",\n",
    "            \"sub_p_1_01\",\"sub_p_1_05\",\"sub_p_1_09\",\"sub_p_1_13\",\"sub_p_1_17\",\"sub_p_1_21\",\"sub_p_1_25\",\"sub_p_1_29\",\"sub_p_1_33\",\"sub_p_1_35\",\"sub_p_1_37\",\"sub_p_1_41\",\"sub_p_1_45\",\n",
    "            \"sub_p_2_03\",\"sub_p_2_07\",\"sub_p_2_11\",\"sub_p_2_15\",\"sub_p_2_19\",\"sub_p_2_27\",\"sub_p_2_31\",\"sub_p_2_39\",\"sub_p_2_43\",\"sub_p_2_47\",]  # 被试数据\n",
    "\n",
    "conds = [\"cue/sat/int/rep\",\"cue/sat/int/swi\",\"cue/sat/ext/rep\",\"cue/sat/ext/swi\"]\n",
    "\n",
    "OUT_DIR = r\"F:/tfr_single_trial_cycle_8\" \n",
    "EPOCHS_DIR = r\"F:/epochs_ITC\" \n",
    "\n",
    "epo_path = os.path.join(EPOCHS_DIR, f\"{subj}-raw-ica-reject-ERP-epo.fif\")\n",
    "epochs = mne.read_epochs(epo_path, preload=True).crop(tmin=tmin, tmax=tmax)\n",
    "epochs = epochs.pick_types(eeg=True, eog=False, meg=False)\n",
    "\n",
    "conds = [\"cue/sat/int/rep\",\"cue/sat/int/swi\",\"cue/sat/ext/rep\",\"cue/sat/ext/swi\"]\n",
    "\n",
    "freqs = np.arange(2, 30, 1) \n",
    "n_cycles = freqs / 6\n",
    "decim = 3\n",
    "baseline = (-0.2, 0.0)\n",
    "mode = \"logratio\"\n",
    "tmin, tmax = -0.2, 1.0\n",
    "\n",
    "power_by_cond = {}\n",
    "\n",
    "for cond in conds:\n",
    "    ep = epochs[cond]\n",
    "    pw = ep.compute_tfr(\n",
    "        method=\"morlet\",\n",
    "        freqs=freqs,\n",
    "        n_cycles=n_cycles,\n",
    "        picks=\"eeg\",\n",
    "        average=True,         \n",
    "        return_itc=False,\n",
    "        decim=decim,\n",
    "    ).apply_baseline(baseline=baseline, mode=mode)\n",
    "\n",
    "    power_by_cond[cond] = pw\n",
    "\n",
    "#joint plot\n",
    "timefreqs_18 = [(0.0, 18), (0.2, 18), (0.4, 18), (0.6, 18), (0.8, 18)]\n",
    "timefreqs_25 = [(0.0, 25), (0.2, 25), (0.4, 25), (0.6, 25), (0.8, 25)]\n",
    "\n",
    "\n",
    "for cond in conds:\n",
    "    pw = power_by_cond[cond]\n",
    "\n",
    "    figs_18 = pw.plot_joint(\n",
    "        tmin=-0.2, tmax=1.0,\n",
    "        timefreqs=timefreqs_18,\n",
    "        show=True\n",
    "    )\n",
    "    \n",
    "    if not isinstance(figs_18, (list, tuple)):\n",
    "        figs_18 = [figs_18]\n",
    "    for k, fig in enumerate(figs_18):\n",
    "        fig.suptitle(f\"EEG – {cond} | joint @18Hz\", fontsize=14)\n",
    "        fig.savefig(f\"MidBetaPower_{cond.replace('/','_')}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        \n",
    "    figs_25 = pw.plot_joint(\n",
    "        tmin=-0.2, tmax=1.0,\n",
    "        timefreqs=timefreqs_25,\n",
    "        show=True\n",
    "    )\n",
    "    if not isinstance(figs_25, (list, tuple)):\n",
    "        figs_25 = [figs_25]\n",
    "    for k, fig in enumerate(figs_25):\n",
    "        fig.suptitle(f\"EEG – {cond} | joint @25Hz\", fontsize=14)\n",
    "        fig.savefig(f\"HighBetaPower_{cond.replace('/','_')}.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe152946-e45b-4ac4-b466-e56de87ce5ba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cluster-based permutation across 64 channel with topo plot\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "os.environ[\"QT_API\"] = \"pyqt5\"\n",
    "%matplotlib qt\n",
    "\n",
    "subjects = [\"sub_m_1_02\", \"sub_m_1_06\", \"sub_m_1_10\",\"sub_m_1_14\",\"sub_m_1_18\",\"sub_m_1_22\",\"sub_m_1_26\",\"sub_m_1_30\",\"sub_m_1_34\",\"sub_m_1_38\",\"sub_m_1_42\",\"sub_m_1_46\",\n",
    "            \"sub_m_2_04\",\"sub_m_2_08\",\"sub_m_2_12\",\"sub_m_2_16\",\"sub_m_2_20\",\"sub_m_2_24\",\"sub_m_2_28\",\"sub_m_2_32\",\"sub_m_2_36\",\"sub_m_2_40\",\"sub_m_2_44\",\n",
    "            \"sub_p_1_01\",\"sub_p_1_05\",\"sub_p_1_09\",\"sub_p_1_13\",\"sub_p_1_17\",\"sub_p_1_21\",\"sub_p_1_25\",\"sub_p_1_29\",\"sub_p_1_33\",\"sub_p_1_35\",\"sub_p_1_37\",\"sub_p_1_41\",\"sub_p_1_45\",\n",
    "            \"sub_p_2_03\",\"sub_p_2_07\",\"sub_p_2_11\",\"sub_p_2_15\",\"sub_p_2_19\",\"sub_p_2_27\",\"sub_p_2_31\",\"sub_p_2_39\",\"sub_p_2_43\",\"sub_p_2_47\"]\n",
    "\n",
    "OUT_DIR = r\"F:/tfr_single_trial_cycle_8\"\n",
    "EPOCHS_DIR = r\"F:/epochs_ITC\"\n",
    "\n",
    "conds = {\"int_rep\": \"cue/sat/int/rep\", \"int_swi\": \"cue/sat/int/swi\", \"ext_rep\": \"cue/sat/ext/rep\",\"ext_swi\": \"cue/sat/ext/swi\"}\n",
    "\n",
    "bands = {\"Low Beta\": (13, 16),\"Beta\": (16, 28)}\n",
    "\n",
    "BIN = 0.25\n",
    "N_PERM = 2000\n",
    "ALPHA = 0.05\n",
    "TAIL = 0\n",
    "SEED = 42\n",
    "\n",
    "def safe_cond_indices(epochs, cond):\n",
    "    cond_sel = epochs[cond].selection\n",
    "    idx = np.flatnonzero(np.isin(epochs.selection, cond_sel))\n",
    "    return idx\n",
    "\n",
    "def cond_mean(X, epochs, cond):\n",
    "    idx = safe_cond_indices(epochs, cond)\n",
    "    if len(idx) == 0:\n",
    "        raise RuntimeError(f\"No trials for {cond}\")\n",
    "    return X[idx].mean(axis=0)  # (ch, freq, time)\n",
    "\n",
    "def band_average(M, freqs, f_lo, f_hi):\n",
    "    fmask = (freqs >= f_lo) & (freqs <= f_hi)\n",
    "    if not np.any(fmask):\n",
    "        raise RuntimeError(f\"No freq bins in [{f_lo}, {f_hi}]\")\n",
    "    return M[:, fmask, :].mean(axis=1)  # (ch, time)\n",
    "\n",
    "def build_subject_effects(subj, freqs_ref=None, times_ref=None, ch_ref=None):\n",
    "    power_path = os.path.join(OUT_DIR, f\"{subj}_power.npy\")\n",
    "    meta_path  = os.path.join(OUT_DIR, f\"{subj}_meta.npz\")\n",
    "    epo_path   = os.path.join(EPOCHS_DIR, f\"{subj}-raw-ica-reject-ERP-epo.fif\")\n",
    "\n",
    "    if not (os.path.exists(power_path) and os.path.exists(meta_path) and os.path.exists(epo_path)):\n",
    "        return None, None, None, f\"missing file(s)\"\n",
    "\n",
    "    X = np.load(power_path, mmap_mode=\"r\")  # (trial, ch, freq, time)\n",
    "    meta = np.load(meta_path, allow_pickle=True)\n",
    "    ch_names = meta[\"ch_names\"].tolist()\n",
    "    freqs = meta[\"freqs\"]\n",
    "    times = meta[\"times\"]\n",
    "\n",
    "    # axis consistency check\n",
    "    if freqs_ref is not None:\n",
    "        if len(freqs) != len(freqs_ref) or not np.allclose(freqs, freqs_ref):\n",
    "            return None, None, None, \"freq mismatch\"\n",
    "    if times_ref is not None:\n",
    "        if len(times) != len(times_ref) or not np.allclose(times, times_ref):\n",
    "            return None, None, None, \"time mismatch\"\n",
    "    if ch_ref is not None:\n",
    "        if ch_names != ch_ref:\n",
    "            return None, None, None, \"channel order mismatch\"\n",
    "\n",
    "    # epochs: only used for condition trial indexing\n",
    "    epochs = mne.read_epochs(epo_path, preload=True).crop(tmin=times[0], tmax=times[-1])\n",
    "\n",
    "    if X.shape[0] != len(epochs):\n",
    "        return None, None, None, f\"trial count mismatch: X={X.shape[0]} vs epochs={len(epochs)}\"\n",
    "\n",
    "    # condition means: (ch,freq,time)\n",
    "    M = {k: cond_mean(X, epochs, c) for k, c in conds.items()}\n",
    "\n",
    "    # effects in full TF (ch,freq,time)\n",
    "    INT = 0.5 * (M[\"int_rep\"] + M[\"int_swi\"])\n",
    "    EXT = 0.5 * (M[\"ext_rep\"] + M[\"ext_swi\"])\n",
    "    D_int_ext = INT - EXT\n",
    "\n",
    "    SWI = 0.5 * (M[\"int_swi\"] + M[\"ext_swi\"])\n",
    "    REP = 0.5 * (M[\"int_rep\"] + M[\"ext_rep\"])\n",
    "    D_swi_rep = SWI - REP\n",
    "\n",
    "    D_inter = (M[\"int_swi\"] - M[\"int_rep\"]) - (M[\"ext_swi\"] - M[\"ext_rep\"])\n",
    "\n",
    "    out = {\n",
    "        \"rule_switch_int_ext\": D_int_ext,\n",
    "        \"att_switch_swi_rep\": D_swi_rep,\n",
    "        \"interaction\": D_inter,\n",
    "    }\n",
    "    return out, freqs, times, None\n",
    "\n",
    "def make_time_bins(times, bin_s=0.25):\n",
    "    t0, t1 = float(times[0]), float(times[-1])\n",
    "    edges = np.arange(t0, t1 + 1e-9, bin_s)\n",
    "    if edges[-1] < t1:\n",
    "        edges = np.append(edges, t1)\n",
    "    bins = []\n",
    "    for a, b in zip(edges[:-1], edges[1:]):\n",
    "        mask = (times >= a) & (times < b) if b < t1 else (times >= a) & (times <= b)\n",
    "        if mask.any():\n",
    "            bins.append((a, b, mask))\n",
    "    return bins\n",
    "\n",
    "def run_cluster_time_ch(X_subj_ch_time, info, adjacency, alpha=0.05, n_perm=2000, tail=0, seed=42):\n",
    "    # MNE expects (n_samples, n_times, n_space) for spatio-temporal with adjacency over space\n",
    "    X_st = np.transpose(X_subj_ch_time, (0, 2, 1))  # -> (subj, time, ch)\n",
    "\n",
    "    T_obs, clusters, pvals, H0 = mne.stats.spatio_temporal_cluster_1samp_test(\n",
    "        X_st,\n",
    "        adjacency=adjacency,\n",
    "        n_permutations=n_perm,\n",
    "        threshold=None,   # uses t-threshold internally (like your logs showed ~2.01)\n",
    "        tail=tail,\n",
    "        out_type=\"mask\",\n",
    "        seed=seed,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # Build sig mask over (time,ch)\n",
    "    sig = np.zeros(T_obs.shape, dtype=bool)  # (time,ch)\n",
    "    for cl, p in zip(clusters, pvals):\n",
    "        if p < alpha:\n",
    "            sig |= cl  # cl is boolean mask if out_type=\"mask\"\n",
    "\n",
    "    # convert to (ch,time) for topomap usage\n",
    "    sig_ch_time = sig.T  # (ch,time)\n",
    "    return T_obs, clusters, pvals, sig_ch_time\n",
    "\n",
    "# 1) Load one subject to anchor info/adjacency + axes\n",
    "anchor = subjects[0]\n",
    "epo_anchor = os.path.join(EPOCHS_DIR, f\"{anchor}-raw-ica-reject-ERP-epo.fif\")\n",
    "epochs_anchor = mne.read_epochs(epo_anchor, preload=True)\n",
    "info = epochs_anchor.copy().pick_types(eeg=True).info\n",
    "\n",
    "adjacency, ch_names_adj = mne.channels.find_ch_adjacency(info, ch_type=\"eeg\")\n",
    "print(\"[adjacency] shape:\", adjacency.shape)\n",
    "\n",
    "# 2) Build subject stacks for each effect+band\n",
    "effects = [\"att_switch_swi_rep\", \"rule_switch_int_ext\", \"interaction\"]\n",
    "\n",
    "# store: band -> effect -> list of (ch,time)\n",
    "stack = {band: {eff: [] for eff in effects} for band in bands.keys()}\n",
    "\n",
    "freqs_ref = None\n",
    "times_ref = None\n",
    "ch_ref = None\n",
    "kept = 0\n",
    "\n",
    "for subj in subjects:\n",
    "    out, freqs, times, err = build_subject_effects(subj, freqs_ref, times_ref, ch_ref)\n",
    "    if err is not None:\n",
    "        print(\"SKIP\", subj, \"->\", err)\n",
    "        continue\n",
    "\n",
    "    # lock references on first kept subject\n",
    "    if freqs_ref is None:\n",
    "        freqs_ref = freqs.copy()\n",
    "        times_ref = times.copy()\n",
    "        # channel names from your meta (must match X channel order)\n",
    "        meta0 = np.load(os.path.join(OUT_DIR, f\"{subj}_meta.npz\"), allow_pickle=True)\n",
    "        ch_ref = meta0[\"ch_names\"].tolist()\n",
    "\n",
    "    # band-average and collect\n",
    "    for band_name, (f_lo, f_hi) in bands.items():\n",
    "        for eff in effects:\n",
    "            D_ch_f_t = out[eff]  # (ch,freq,time)\n",
    "            D_ch_t = band_average(D_ch_f_t, freqs_ref, f_lo, f_hi)  # (ch,time)\n",
    "            stack[band_name][eff].append(D_ch_t.astype(np.float32))\n",
    "\n",
    "    kept += 1\n",
    "\n",
    "print(\"Kept subjects:\", kept)\n",
    "\n",
    "# 3) Cluster + plot: many topomaps per time-bin with black dots\n",
    "time_bins = make_time_bins(times_ref, BIN)\n",
    "print(\"n_time_bins:\", len(time_bins), \"bin_s:\", BIN)\n",
    "\n",
    "for band_name, (f_lo, f_hi) in bands.items():\n",
    "    all_maps = []\n",
    "    for eff in effects:\n",
    "        X_eff = np.stack(stack[band_name][eff], axis=0)  \n",
    "        all_maps.append(X_eff.mean(axis=0))           \n",
    "    all_maps = np.concatenate(all_maps, axis=1)\n",
    "    vmin, vmax = np.percentile(all_maps, [5, 95])\n",
    "\n",
    "    n_rows = len(effects)\n",
    "    n_cols = len(time_bins)\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "    fig.suptitle(\n",
    "        f\"{band_name.upper()} ({f_lo:.0f}-{f_hi:.0f} Hz) — Cluster permutation topomaps\",\n",
    "        y=0.98\n",
    "    )\n",
    "\n",
    "    # +1 column reserved for colorbar\n",
    "    gs = gridspec.GridSpec(\n",
    "        n_rows,\n",
    "        n_cols + 1,\n",
    "        width_ratios=[1] * n_cols + [0.05],\n",
    "        wspace=0.25,\n",
    "        hspace=0.3\n",
    "    )\n",
    "\n",
    "    #plot\n",
    "    for r, eff in enumerate(effects):\n",
    "        X_eff = np.stack(stack[band_name][eff], axis=0)  # (subj,ch,time)\n",
    "\n",
    "        T_obs, clusters, pvals, sig_ch_time = run_cluster_time_ch(\n",
    "            X_eff, info, adjacency,\n",
    "            alpha=ALPHA, n_perm=N_PERM, tail=TAIL, seed=SEED\n",
    "        )\n",
    "\n",
    "        mean_ch_t = X_eff.mean(axis=0)  # (ch,time)\n",
    "\n",
    "        for c, (ta, tb, tmask) in enumerate(time_bins):\n",
    "            ax = fig.add_subplot(gs[r, c])\n",
    "\n",
    "            dat = mean_ch_t[:, tmask].mean(axis=1)\n",
    "            sig_ch = sig_ch_time[:, tmask].any(axis=1)\n",
    "\n",
    "            mne.viz.plot_topomap(\n",
    "                dat,\n",
    "                info,\n",
    "                axes=ax,\n",
    "                show=False,\n",
    "                vlim=(vmin, vmax),\n",
    "                contours=0,\n",
    "                sensors=False,\n",
    "                mask=sig_ch,\n",
    "                mask_params=dict(\n",
    "                    markersize=6,\n",
    "                    markerfacecolor=\"k\",\n",
    "                    markeredgecolor=\"k\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "            ax.set_title(f\"{ta:+.2f}–{tb:+.2f}s\", fontsize=8)\n",
    "            if c == 0:\n",
    "                ax.set_ylabel(eff, fontsize=10)\n",
    "\n",
    "    #  colorbar (single, dedicated axis) \n",
    "    cax = fig.add_subplot(gs[:, -1])\n",
    "    norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    sm = mpl.cm.ScalarMappable(norm=norm, cmap=\"RdBu_r\")\n",
    "    sm.set_array([])\n",
    "\n",
    "    cbar = fig.colorbar(sm, cax=cax)\n",
    "    cbar.set_label(\"Power (baseline-corrected logratio)\", rotation=90)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f93c00-59f9-4b71-8327-05b751db9f91",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Plot the list of the siginificant channels\n",
    "#Significant channels across the time window\n",
    "sig_ch = sig_ch_time[:, tmask].any(axis=1)\n",
    "sig_names = np.array(info['ch_names'])[sig_ch]\n",
    "\n",
    "print(\n",
    "    f\"[{band_name} | {eff} | {ta:+.2f}–{tb:+.2f}s] \"\n",
    "    f\"{len(sig_names)} channels: {sig_names.tolist()}\"\n",
    ")\n",
    "\n",
    "#significant cluster\n",
    "best_idx = np.argmin(pvals)\n",
    "best_cluster = clusters[best_idx]  # (time, ch) boolean\n",
    "\n",
    "best_ch = best_cluster.any(axis=0)\n",
    "best_ch_names = np.array(info['ch_names'])[best_ch]\n",
    "\n",
    "print(\n",
    "    f\"[{band_name} | {eff}] strongest cluster p={pvals[best_idx]:.4f}\"\n",
    ")\n",
    "print(\"Channels:\", best_ch_names.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da13b4-c18b-439c-b8da-7190e205818f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Selected ROI\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.stats import permutation_cluster_1samp_test\n",
    "os.environ[\"QT_API\"] = \"pyqt5\"\n",
    "%matplotlib qt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.stats import permutation_cluster_1samp_test\n",
    "os.environ[\"QT_API\"] = \"pyqt5\"\n",
    "%matplotlib qt\n",
    "\n",
    "OUT_DIR = r\"F:/tfr_single_trial_cycle_8\"\n",
    "EPOCHS_DIR = r\"F:/epochs_ITC\"\n",
    "\n",
    "subjects = [\"sub_m_1_02\", \"sub_m_1_06\", \"sub_m_1_10\",\"sub_m_1_14\",\"sub_m_1_18\",\"sub_m_1_22\",\"sub_m_1_26\",\"sub_m_1_30\",\"sub_m_1_34\",\"sub_m_1_38\",\"sub_m_1_42\",\"sub_m_1_46\",\n",
    "            \"sub_m_2_04\",\"sub_m_2_08\",\"sub_m_2_12\",\"sub_m_2_16\",\"sub_m_2_20\",\"sub_m_2_24\",\"sub_m_2_28\",\"sub_m_2_32\",\"sub_m_2_36\",\"sub_m_2_40\",\"sub_m_2_44\",\n",
    "            \"sub_p_1_01\",\"sub_p_1_05\",\"sub_p_1_09\",\"sub_p_1_13\",\"sub_p_1_17\",\"sub_p_1_21\",\"sub_p_1_25\",\"sub_p_1_29\",\"sub_p_1_33\",\"sub_p_1_35\",\"sub_p_1_37\",\"sub_p_1_41\",\"sub_p_1_45\",\n",
    "            \"sub_p_2_03\",\"sub_p_2_07\",\"sub_p_2_11\",\"sub_p_2_15\",\"sub_p_2_19\",\"sub_p_2_27\",\"sub_p_2_31\",\"sub_p_2_39\",\"sub_p_2_43\",\"sub_p_2_47\"]\n",
    "\n",
    "conds = {\"int_rep\": \"cue/sat/int/rep\", \"int_swi\": \"cue/sat/int/swi\", \"ext_rep\": \"cue/sat/ext/rep\",\"ext_swi\": \"cue/sat/ext/swi\"}\n",
    "\n",
    "ROIS = {\"central\":  [\"C1\", \"C2\", \"Cz\", \"FC1\", \"FC2\", \"FCz\", \"FC5\"],\"parietal\": [\"CP1\", \"CP2\", \"CPz\"]}\n",
    "beta_lo, beta_hi = 13.0, 18.0\n",
    "EFFECTS_TO_TEST = [\"int_ext\", \"swi_rep\", \"interaction\"]\n",
    "\n",
    "#cluster setting\n",
    "N_PERM=2000\n",
    "ALPHA=0.05\n",
    "TAIL=0\n",
    "\n",
    "#Construct subject-level(same as above\n",
    "def build_cond_labels(epochs, conds):\n",
    "    key_list = list(conds.keys())\n",
    "    labels = np.full(len(epochs), -1, dtype=np.int16)\n",
    "\n",
    "    # epochs[cond_str].selection gives original-raw indices; map them to current epochs indices\n",
    "    base_sel = epochs.selection  # original indices for each epoch in this Epochs object\n",
    "\n",
    "    for k_i, key in enumerate(key_list):\n",
    "        cond_str = conds[key]\n",
    "        cond_sel = epochs[cond_str].selection\n",
    "        mask = np.isin(base_sel, cond_sel)\n",
    "        labels[mask] = k_i\n",
    "\n",
    "    return labels, key_list\n",
    "\n",
    "def means_by_labels_memmap(X, labels, n_classes):\n",
    "    means = []\n",
    "    for k in range(n_classes):\n",
    "        idx = np.where(labels == k)[0]\n",
    "        if idx.size == 0:\n",
    "            raise RuntimeError(f\"No trials for class {k}\")\n",
    "        # Still uses fancy indexing, but only once per class; OK.\n",
    "        # If still too slow, see the \"even faster\" streaming version below.\n",
    "        means.append(X[idx].mean(axis=0))\n",
    "    return means\n",
    "\n",
    "\n",
    "def roi_band_time(Mk, roi_idx, fidx):\n",
    "    # Mk: (ch, freq, time) -> return (time,)\n",
    "    return Mk[roi_idx][:, fidx, :].mean(axis=(0, 1))\n",
    "\n",
    "def build_subject_effects(subj, roi_channels):\n",
    "    power_path = os.path.join(OUT_DIR, f\"{subj}_power.npy\")\n",
    "    meta_path  = os.path.join(OUT_DIR, f\"{subj}_meta.npz\")\n",
    "    epo_path   = os.path.join(EPOCHS_DIR, f\"{subj}-raw-ica-reject-ERP-epo.fif\")\n",
    "\n",
    "    if not (os.path.exists(power_path) and os.path.exists(meta_path) and os.path.exists(epo_path)):\n",
    "        return None, None, \"missing file(s)\"\n",
    "\n",
    "    X = np.load(power_path, mmap_mode=\"r\")  # memmap (trial, ch, freq, time)\n",
    "    meta = np.load(meta_path, allow_pickle=True)\n",
    "    ch_names = meta[\"ch_names\"].tolist()\n",
    "    freqs = meta[\"freqs\"].astype(float)\n",
    "    times = meta[\"times\"].astype(float)\n",
    "\n",
    "    # ROI indices\n",
    "    try:\n",
    "        roi_idx = [ch_names.index(ch) for ch in roi_channels]\n",
    "    except ValueError:\n",
    "        return None, None, f\"missing ROI channels in meta (roi={roi_channels})\"\n",
    "\n",
    "    # low-beta freq indices\n",
    "    fmask = (freqs >= beta_lo) & (freqs <= beta_hi)\n",
    "    if not np.any(fmask):\n",
    "        return None, None, f\"no low-beta bins in [{beta_lo},{beta_hi}]\"\n",
    "    fidx = np.where(fmask)[0]\n",
    "\n",
    "    # epochs for condition indexing (load once)\n",
    "    epochs = mne.read_epochs(epo_path, preload=True).crop(tmin=float(times[0]), tmax=float(times[-1]))\n",
    "\n",
    "    if X.shape[0] != len(epochs):\n",
    "        return None, None, f\"trial mismatch: X={X.shape[0]} epochs={len(epochs)}\"\n",
    "\n",
    "    # build labels once\n",
    "    labels, key_list = build_cond_labels(epochs, conds)\n",
    "\n",
    "    # compute condition means once\n",
    "    M_list = means_by_labels_memmap(X, labels, n_classes=len(key_list))\n",
    "    M = {key_list[i]: M_list[i] for i in range(len(key_list))}  # each (ch,freq,time)\n",
    "\n",
    "    # effects\n",
    "    INT = 0.5 * (M[\"int_rep\"] + M[\"int_swi\"])\n",
    "    EXT = 0.5 * (M[\"ext_rep\"] + M[\"ext_swi\"])\n",
    "    D_int_ext = INT - EXT\n",
    "\n",
    "    SWI = 0.5 * (M[\"int_swi\"] + M[\"ext_swi\"])\n",
    "    REP = 0.5 * (M[\"int_rep\"] + M[\"ext_rep\"])\n",
    "    D_swi_rep = SWI - REP\n",
    "\n",
    "    D_inter = (M[\"int_swi\"] - M[\"int_rep\"]) - (M[\"ext_swi\"] - M[\"ext_rep\"])\n",
    "\n",
    "    out = {\n",
    "        \"int_ext\": roi_band_time(D_int_ext, roi_idx, fidx),\n",
    "        \"swi_rep\": roi_band_time(D_swi_rep, roi_idx, fidx),\n",
    "        \"interaction\": roi_band_time(D_inter, roi_idx, fidx),\n",
    "    }\n",
    "    return out, times, None\n",
    "\n",
    "\n",
    "def run_cluster_1samp(X_subj_time, times, title):\n",
    "    X_subj_time = np.asarray(X_subj_time, dtype=float)\n",
    "    if X_subj_time.ndim != 2:\n",
    "        raise ValueError(\"expect (subjects, time)\")\n",
    "    if X_subj_time.shape[1] != len(times):\n",
    "        raise ValueError(\"time length mismatch\")\n",
    "\n",
    "    T_obs, clusters, pvals, H0 = permutation_cluster_1samp_test(\n",
    "        X_subj_time,\n",
    "        n_permutations=N_PERM,\n",
    "        tail=TAIL,\n",
    "        threshold=None,\n",
    "        out_type=\"mask\",\n",
    "        n_jobs=1,\n",
    "        seed=0,\n",
    "    )\n",
    "\n",
    "    sig = np.where(pvals < ALPHA)[0]\n",
    "    print(f\"\\n[{title}] n_subjects={X_subj_time.shape[0]}  n_sig_clusters={len(sig)}\")\n",
    "    for i in sig:\n",
    "        mask = clusters[i]\n",
    "        t0, t1 = times[mask][0], times[mask][-1]\n",
    "        mass = float(T_obs[mask].sum())\n",
    "        print(f\"  cluster {i}: p={pvals[i]:.4f}, time=[{t0:.3f},{t1:.3f}]s, mass={mass:.3f}\")\n",
    "\n",
    "    mean = X_subj_time.mean(axis=0)\n",
    "    sem = X_subj_time.std(axis=0, ddof=1) / np.sqrt(X_subj_time.shape[0])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    ax.plot(times, mean)\n",
    "    ax.fill_between(times, mean - sem, mean + sem, alpha=0.2)\n",
    "    ax.axhline(0, color=\"k\", ls=\"--\", lw=1)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"ROI×low-beta contrast (logratio power)\")\n",
    "    for i in sig:\n",
    "        mask = clusters[i]\n",
    "        ax.axvspan(times[mask][0], times[mask][-1], alpha=0.15)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return T_obs, clusters, pvals, H0\n",
    "\n",
    "# Main: run both ROI groups\n",
    "for roi_name, roi_channels in ROIS.items():\n",
    "    print(f\"\\n================ ROI group: {roi_name} | channels={roi_channels} ================\\n\")\n",
    "\n",
    "    effects_all = {eff: [] for eff in EFFECTS_TO_TEST}\n",
    "    times_ref = None\n",
    "    kept = 0\n",
    "\n",
    "    for subj in subjects:\n",
    "        out, times, err = build_subject_effects(subj, roi_channels)\n",
    "        if err is not None:\n",
    "            print(\"SKIP\", subj, \"->\", err)\n",
    "            continue\n",
    "\n",
    "        if times_ref is None:\n",
    "            times_ref = times.copy()\n",
    "        else:\n",
    "            if len(times) != len(times_ref) or not np.allclose(times, times_ref):\n",
    "                print(\"SKIP\", subj, \"-> times mismatch\")\n",
    "                continue\n",
    "\n",
    "        for eff in EFFECTS_TO_TEST:\n",
    "            effects_all[eff].append(out[eff].astype(np.float32))\n",
    "\n",
    "        kept += 1\n",
    "\n",
    "    print(\"Kept subjects:\", kept)\n",
    "\n",
    "    for eff in EFFECTS_TO_TEST:\n",
    "        X_eff = np.stack(effects_all[eff], axis=0)  # (subjects, time)\n",
    "        title = (f\"Cluster permutation (time) — {eff} | ROI={roi_name} \"\n",
    "                 f\"| low beta={beta_lo}-{beta_hi} Hz | tail={TAIL}\")\n",
    "        run_cluster_1samp(X_eff, times_ref, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba119e78-9197-49ea-aeaa-44d70ba5b28c",
   "metadata": {},
   "source": [
    "# ERSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b161f473-74ee-47a7-b8d8-cfbb045d5043",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ERSP for theta with ROI， read out power match with epoch\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from scipy import stats\n",
    "from mne.stats import permutation_cluster_1samp_test, combine_adjacency\n",
    "\n",
    "subjects = [\n",
    "    \"sub_m_1_02\", \"sub_m_1_06\", \"sub_m_1_10\",\"sub_m_1_14\",\"sub_m_1_18\",\"sub_m_1_22\",\"sub_m_1_26\",\"sub_m_1_30\",\"sub_m_1_34\",\"sub_m_1_38\",\"sub_m_1_42\",\"sub_m_1_46\",\n",
    "    \"sub_m_2_04\",\"sub_m_2_08\",\"sub_m_2_12\",\"sub_m_2_16\",\"sub_m_2_20\",\"sub_m_2_24\",\"sub_m_2_28\",\"sub_m_2_32\",\"sub_m_2_36\",\"sub_m_2_40\",\"sub_m_2_44\",\n",
    "    \"sub_p_1_01\",\"sub_p_1_05\",\"sub_p_1_09\",\"sub_p_1_13\",\"sub_p_1_17\",\"sub_p_1_21\",\"sub_p_1_25\",\"sub_p_1_29\",\"sub_p_1_33\",\"sub_p_1_35\",\"sub_p_1_37\",\"sub_p_1_41\",\"sub_p_1_45\",\n",
    "    \"sub_p_2_03\",\"sub_p_2_07\",\"sub_p_2_11\",\"sub_p_2_15\",\"sub_p_2_19\",\"sub_p_2_27\",\"sub_p_2_31\",\"sub_p_2_39\",\"sub_p_2_43\",\"sub_p_2_47\",\n",
    "]\n",
    "\n",
    "OUT_DIR    = r\"F:/tfr_single_trial_cycle_8\"\n",
    "EPOCHS_DIR = r\"F:/epochs_ITC\" \n",
    "\n",
    "conds = {\"int_rep\": \"cue/int/rep/sat\",\"int_swi\": \"cue/int/swi/sat\",\"ext_rep\": \"cue/ext/rep/sat\",\n",
    "         \"ext_swi\": \"cue/ext/swi/sat\"}\n",
    "COND_ORDER = [\"int_rep\", \"int_swi\", \"ext_rep\", \"ext_swi\"]\n",
    "\n",
    "BASELINE = (-0.5, -0.2)\n",
    "\n",
    "# cluster permutation\n",
    "N_PERM = 2000\n",
    "P_CLUSTER_FORMING = 0.05\n",
    "P_ACCEPT = 0.05\n",
    "SEED = 42\n",
    "\n",
    "ROI_CH_NAMES: Dict[str, List[str]] = {\n",
    "    \"frontal\":  [\"Fz\", \"F1\", \"F2\", \"FCz\", \"FC1\", \"FC2\"],\n",
    "    \"parietal\": [\"Pz\", \"P1\", \"P2\", \"CPz\", \"CP1\", \"CP2\"],\n",
    "}\n",
    "\n",
    "EPOCHS_METADATA_LABEL_COLS = [\"trial_cond\", \"trial_type\", \"condition\", \"cond\", \"label\"]\n",
    "\n",
    "EPOCHS_GLOBS = [\"{subj}*epo.fif\",\"{subj}*epo.fif.gz\",\"*{subj}*epo.fif\",\"*{subj}*epo.fif.gz\"]\n",
    "\n",
    "def _as_str_array(x) -> np.ndarray:\n",
    "    x = np.asarray(x)\n",
    "    if x.dtype.kind in (\"S\", \"O\", \"U\"):\n",
    "        return x.astype(str)\n",
    "    return x\n",
    "\n",
    "def find_epochs_file(subj: str, epochs_dir: str) -> str:\n",
    "    candidates: List[str] = []\n",
    "    for pat in EPOCHS_GLOBS:\n",
    "        candidates.extend(glob.glob(os.path.join(epochs_dir, pat.format(subj=subj))))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"[{subj}] No epochs file found in {epochs_dir}\")\n",
    "    candidates.sort(key=lambda p: os.path.getmtime(p), reverse=True)\n",
    "    return candidates[0]\n",
    "\n",
    "def get_cond_labels_from_epochs(epochs: mne.Epochs) -> np.ndarray:\n",
    "    if epochs.metadata is not None:\n",
    "        for col in EPOCHS_METADATA_LABEL_COLS:\n",
    "            if col in epochs.metadata.columns:\n",
    "                return epochs.metadata[col].astype(str).to_numpy()\n",
    "    if not epochs.event_id:\n",
    "        raise KeyError(\"epochs has no metadata labels and empty event_id; cannot infer conditions.\")\n",
    "    inv = {v: k for k, v in epochs.event_id.items()}\n",
    "    codes = epochs.events[:, 2]\n",
    "    return np.array([inv[c] for c in codes], dtype=str)\n",
    "\n",
    "def channel_names_to_indices(ch_names: List[str], roi_names: Dict[str, List[str]]) -> Dict[str, List[int]]:\n",
    "    name_to_idx = {name.upper(): i for i, name in enumerate(ch_names)}\n",
    "    roi_idx: Dict[str, List[int]] = {}\n",
    "    missing = []\n",
    "    for roi, names in roi_names.items():\n",
    "        idxs = []\n",
    "        for nm in names:\n",
    "            key = nm.upper()\n",
    "            if key not in name_to_idx:\n",
    "                missing.append((roi, nm))\n",
    "            else:\n",
    "                idxs.append(name_to_idx[key])\n",
    "        roi_idx[roi] = idxs\n",
    "    if missing:\n",
    "        miss_str = \", \".join([f\"{roi}:{nm}\" for roi, nm in missing])\n",
    "        raise ValueError(f\"ROI channels missing: {miss_str}\")\n",
    "    return roi_idx\n",
    "\n",
    "def load_subject_files_with_epochs_fallback(\n",
    "    subj: str, out_dir: str, epochs_dir: str\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, List[str], np.ndarray]:\n",
    "    power_path = os.path.join(out_dir, f\"{subj}_power.npy\")\n",
    "    meta_path  = os.path.join(out_dir, f\"{subj}_meta.npz\")\n",
    "    power = np.load(power_path, allow_pickle=False)\n",
    "    meta = np.load(meta_path, allow_pickle=True)\n",
    "\n",
    "    times = np.asarray(meta[\"times\"], dtype=float)\n",
    "    freqs = np.asarray(meta[\"freqs\"], dtype=float)\n",
    "    ch_names = _as_str_array(meta[\"ch_names\"]).tolist()\n",
    "\n",
    "    cond_labels: Optional[np.ndarray] = None\n",
    "    for k in (\"trial_cond\", \"trial_type\", \"condition\", \"cond\", \"labels\", \"label\"):\n",
    "        if k in meta:\n",
    "            cond_labels = _as_str_array(meta[k]).reshape(-1)\n",
    "            break\n",
    "    if cond_labels is None:\n",
    "        epo_path = find_epochs_file(subj, epochs_dir)\n",
    "        epochs = mne.read_epochs(epo_path, preload=False, verbose=False)\n",
    "        cond_labels = get_cond_labels_from_epochs(epochs)\n",
    "\n",
    "    cond_labels = np.asarray(cond_labels, dtype=str).reshape(-1)\n",
    "\n",
    "    if power.shape[0] != len(cond_labels):\n",
    "        raise RuntimeError(\n",
    "            f\"[{subj}] trial count mismatch: power {power.shape[0]} vs labels {len(cond_labels)}\"\n",
    "        )\n",
    "    return power, times, freqs, ch_names, cond_labels\n",
    "\n",
    "def split_trials_by_condition(power: np.ndarray, cond_labels: np.ndarray, cond_map: Dict[str, str]) -> Dict[str, np.ndarray]:\n",
    "    out: Dict[str, np.ndarray] = {}\n",
    "    for ck, label in cond_map.items():\n",
    "        m = (cond_labels == label)\n",
    "        trials = power[m]\n",
    "        if trials.shape[0] == 0:\n",
    "            raise ValueError(\n",
    "                f\"No trials for {ck}='{label}'. Unique labels sample: {np.unique(cond_labels)[:30]}\"\n",
    "            )\n",
    "        out[ck] = trials\n",
    "    return out\n",
    "\n",
    "def build_data_dict(\n",
    "    subjects: List[str], out_dir: str, epochs_dir: str, roi_ch_names: Dict[str, List[str]], cond_map: Dict[str, str]\n",
    "):\n",
    "    data: Dict[str, Dict[str, Dict[str, np.ndarray]]] = {}\n",
    "    times_ref = None\n",
    "    freqs_ref = None\n",
    "    roi_idx_ref = None\n",
    "\n",
    "    for si, subj in enumerate(subjects):\n",
    "        power, times, freqs, ch_names, cond_labels = load_subject_files_with_epochs_fallback(subj, out_dir, epochs_dir)\n",
    "\n",
    "        if si == 0:\n",
    "            times_ref = times\n",
    "            freqs_ref = freqs\n",
    "            roi_idx_ref = channel_names_to_indices(ch_names, roi_ch_names)\n",
    "            data = {roi: {} for roi in roi_idx_ref.keys()}\n",
    "        else:\n",
    "            if not np.allclose(times_ref, times): raise ValueError(f\"[{subj}] times differ\")\n",
    "            if not np.allclose(freqs_ref, freqs): raise ValueError(f\"[{subj}] freqs differ\")\n",
    "\n",
    "        trials_by_cond = split_trials_by_condition(power, cond_labels, cond_map)\n",
    "        for roi, idxs in roi_idx_ref.items():\n",
    "            data[roi][subj] = {}\n",
    "            for ck in COND_ORDER:\n",
    "                data[roi][subj][ck] = trials_by_cond[ck][:, idxs, :, :]  # (trials, ch_roi, f, t)\n",
    "\n",
    "    return data, times_ref, freqs_ref, list(roi_idx_ref.keys()), subjects, roi_idx_ref\n",
    "\n",
    "# ----------- BUILD DATA (this cell output) -----------\n",
    "data, times, freqs, roi_names, subject_ids, roi_indices = build_data_dict(\n",
    "    subjects=subjects,\n",
    "    out_dir=OUT_DIR,\n",
    "    epochs_dir=EPOCHS_DIR,\n",
    "    roi_ch_names=ROI_CH_NAMES,\n",
    "    cond_map=conds,\n",
    ")\n",
    "\n",
    "print(\"OK: data built.\")\n",
    "print(\"ROIs:\", roi_names)\n",
    "print(\"ROI indices:\", roi_indices)\n",
    "print(\"Subjects:\", len(subject_ids), \"| times:\", times.shape, \"| freqs:\", freqs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02958d2f-3d2a-48db-966c-ad5d73182689",
   "metadata": {},
   "outputs": [],
   "source": [
    "ersp = 10*np.log10(x / np.maximum(x[..., bl_mask].mean(axis=-1, keepdims=True), np.finfo(float).tiny))\n",
    "print(\"ersp nan:\", np.isnan(ersp).any(), \"ersp inf:\", np.isinf(ersp).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b55a808-8856-4399-90f9-a58d7bd6ad0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ERSP, contrast and cluster permutation, extract hotspot\n",
    "from typing import Any, Dict, List\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from scipy import stats\n",
    "from mne.stats import permutation_cluster_1samp_test, combine_adjacency\n",
    "\n",
    "def subject_condition_average_value(trials_x: np.ndarray) -> np.ndarray:\n",
    "    trials_x = np.nan_to_num(trials_x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return trials_x.mean(axis=0)\n",
    "\n",
    "def compute_effect_contrasts(cell_data: np.ndarray) -> Dict[str, np.ndarray]:\n",
    "    int_rep = cell_data[:, 0]\n",
    "    int_swi = cell_data[:, 1]\n",
    "    ext_rep = cell_data[:, 2]\n",
    "    ext_swi = cell_data[:, 3]\n",
    "\n",
    "    task = 0.5 * (ext_rep + ext_swi) - 0.5 * (int_rep + int_swi)\n",
    "    rule = 0.5 * (int_swi + ext_swi) - 0.5 * (int_rep + ext_rep)\n",
    "    inter = (ext_swi - ext_rep) - (int_swi - int_rep)\n",
    "    return {\"task\": task, \"rule\": rule, \"interaction\": inter}\n",
    "\n",
    "@dataclass\n",
    "class TFClusterResult:\n",
    "    effect: str\n",
    "    roi: str\n",
    "    T_obs: np.ndarray\n",
    "    F_obs: np.ndarray\n",
    "    cluster_masks: List[np.ndarray]\n",
    "    cluster_pvals: np.ndarray\n",
    "    sig_mask: np.ndarray\n",
    "    threshold_t: float\n",
    "    times: np.ndarray\n",
    "    freqs: np.ndarray\n",
    "\n",
    "def tf_cluster_1samp_t_as_F(\n",
    "    X: np.ndarray,\n",
    "    times: np.ndarray,\n",
    "    freqs: np.ndarray,\n",
    "    effect: str,\n",
    "    roi: str,\n",
    "    n_perm: int,\n",
    "    p_cluster_forming: float,\n",
    "    p_accept: float,\n",
    "    seed: int,\n",
    ") -> TFClusterResult:\n",
    "    n_subj, n_f, n_t = X.shape\n",
    "    adjacency = combine_adjacency(n_f, n_t)\n",
    "\n",
    "    df = n_subj - 1\n",
    "    threshold_t = stats.t.ppf(1 - p_cluster_forming / 2.0, df)\n",
    "\n",
    "    T_obs, clusters, cluster_pvals, _ = permutation_cluster_1samp_test(\n",
    "        X,\n",
    "        n_permutations=n_perm,\n",
    "        threshold=threshold_t,\n",
    "        tail=0,\n",
    "        adjacency=adjacency,\n",
    "        out_type=\"mask\",\n",
    "        seed=seed,\n",
    "        # n_jobs removed (single-core)\n",
    "    )\n",
    "\n",
    "    T_obs = np.asarray(T_obs).reshape(n_f, n_t)\n",
    "    F_obs = T_obs ** 2\n",
    "    cluster_masks = [np.asarray(c).reshape(n_f, n_t) for c in clusters]\n",
    "    cluster_pvals = np.asarray(cluster_pvals)\n",
    "\n",
    "    sig_mask = np.zeros((n_f, n_t), dtype=bool)\n",
    "    for cm, p in zip(cluster_masks, cluster_pvals):\n",
    "        if p <= p_accept:\n",
    "            sig_mask |= cm\n",
    "\n",
    "    return TFClusterResult(\n",
    "        effect=effect,\n",
    "        roi=roi,\n",
    "        T_obs=T_obs,\n",
    "        F_obs=F_obs,\n",
    "        cluster_masks=cluster_masks,\n",
    "        cluster_pvals=cluster_pvals,\n",
    "        sig_mask=sig_mask,\n",
    "        threshold_t=float(threshold_t),\n",
    "        times=times,\n",
    "        freqs=freqs,\n",
    "    )\n",
    "\n",
    "@dataclass\n",
    "class Hotspot:\n",
    "    effect: str\n",
    "    roi: str\n",
    "    f0: float\n",
    "    t0: float\n",
    "    fi: int\n",
    "    ti: int\n",
    "    mask: np.ndarray\n",
    "    p_cluster: float\n",
    "\n",
    "def define_hotspot_from_sig_clusters(res: TFClusterResult, p_accept: float) -> Hotspot:\n",
    "    sig = [(cm, p) for cm, p in zip(res.cluster_masks, res.cluster_pvals) if p <= p_accept]\n",
    "    if not sig:\n",
    "        raise RuntimeError(f\"No significant clusters for {res.roi}/{res.effect}\")\n",
    "\n",
    "    best_cm, best_p = sig[0]\n",
    "    best_mass = res.F_obs[best_cm].sum()\n",
    "    for cm, p in sig[1:]:\n",
    "        mass = res.F_obs[cm].sum()\n",
    "        if (p < best_p) or (np.isclose(p, best_p) and mass > best_mass):\n",
    "            best_cm, best_p, best_mass = cm, p, mass\n",
    "\n",
    "    F_in = np.where(best_cm, res.F_obs, -np.inf)\n",
    "    fi, ti = np.unravel_index(np.nanargmax(F_in), F_in.shape)\n",
    "\n",
    "    return Hotspot(\n",
    "        effect=res.effect,\n",
    "        roi=res.roi,\n",
    "        f0=float(res.freqs[fi]),\n",
    "        t0=float(res.times[ti]),\n",
    "        fi=int(fi),\n",
    "        ti=int(ti),\n",
    "        mask=best_cm,\n",
    "        p_cluster=float(best_p),\n",
    "    )\n",
    "\n",
    "def extract_hotspot_values(subj_cell: np.ndarray, hotspot: Hotspot) -> np.ndarray:\n",
    "    vals = subj_cell[:, :, hotspot.mask]  # (n_subj, 4, n_pts)\n",
    "    return vals.mean(axis=-1)\n",
    "\n",
    "#STATS \n",
    "rng = np.random.RandomState(SEED)\n",
    "\n",
    "saved: Dict[str, Any] = {\n",
    "    \"subj_cell_value\": {},     # ROI -> (n_subj, 4, n_f, n_t)   (logratio scale)\n",
    "    \"cluster_results\": {},     # ROI -> effect -> TFClusterResult\n",
    "    \"hotspots\": {},            # ROI -> effect -> Hotspot\n",
    "    \"extracted_hotspot\": {},   # ROI -> effect -> (n_subj, 4)\n",
    "}\n",
    "\n",
    "for roi in roi_names:\n",
    "    subj_cell = []\n",
    "    for subj in subject_ids:\n",
    "        cell_maps = []\n",
    "        for ck in COND_ORDER:\n",
    "            trials_x = data[roi][subj][ck]  # (n_trials, n_ch_roi, n_f, n_t) already logratio\n",
    "            x_avg = subject_condition_average_value(trials_x)  # (n_ch_roi, n_f, n_t)\n",
    "            x_roi = x_avg.mean(axis=0)                         # (n_f, n_t)\n",
    "            cell_maps.append(x_roi)\n",
    "        subj_cell.append(np.stack(cell_maps, axis=0))\n",
    "\n",
    "    subj_cell = np.stack(subj_cell, axis=0)  # (n_subj, 4, n_f, n_t)\n",
    "    saved[\"subj_cell_value\"][roi] = subj_cell\n",
    "\n",
    "    contrasts = compute_effect_contrasts(subj_cell)\n",
    "    res_roi: Dict[str, TFClusterResult] = {}\n",
    "    hs_roi: Dict[str, Hotspot] = {}\n",
    "    ext_roi: Dict[str, np.ndarray] = {}\n",
    "\n",
    "    for effect_name, X in contrasts.items():\n",
    "        res = tf_cluster_1samp_t_as_F(\n",
    "            X=X,\n",
    "            times=times,\n",
    "            freqs=freqs,\n",
    "            effect=effect_name,\n",
    "            roi=roi,\n",
    "            n_perm=N_PERM,\n",
    "            p_cluster_forming=P_CLUSTER_FORMING,\n",
    "            p_accept=P_ACCEPT,\n",
    "            seed=int(rng.randint(0, 1_000_000)),\n",
    "        )\n",
    "        res_roi[effect_name] = res\n",
    "\n",
    "        if np.any(res.sig_mask):\n",
    "            hs = define_hotspot_from_sig_clusters(res, p_accept=P_ACCEPT)\n",
    "            hs_roi[effect_name] = hs\n",
    "            ext_roi[effect_name] = extract_hotspot_values(subj_cell, hs)\n",
    "\n",
    "    saved[\"cluster_results\"][roi] = res_roi\n",
    "    saved[\"hotspots\"][roi] = hs_roi\n",
    "    saved[\"extracted_hotspot\"][roi] = ext_roi\n",
    "\n",
    "print(\"OK: stats done. Saved keys:\", saved.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53509637-e95f-41be-a0d5-78c4c759affe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Plot\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import os\n",
    "os.environ[\"QT_API\"] = \"pyqt5\"\n",
    "%matplotlib qt\n",
    "\n",
    "def plot_f_map(res: TFClusterResult, title: str):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.imshow(\n",
    "        res.F_obs,\n",
    "        aspect=\"auto\",\n",
    "        origin=\"lower\",\n",
    "        extent=[res.times[0], res.times[-1], res.freqs[0], res.freqs[-1]],\n",
    "    )\n",
    "    plt.colorbar(label=\"F = t²\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "    plt.title(title)\n",
    "    if np.any(res.sig_mask):\n",
    "        sig = res.sig_mask.astype(float)\n",
    "        plt.contour(\n",
    "            np.linspace(res.times[0], res.times[-1], sig.shape[1]),\n",
    "            np.linspace(res.freqs[0], res.freqs[-1], sig.shape[0]),\n",
    "            sig,\n",
    "            levels=[0.5],\n",
    "            linewidths=1.0,\n",
    "        )\n",
    "    plt.tight_layout()\n",
    "\n",
    "def plot_hotspot_bar(extracted: np.ndarray, cond_names: List[str], title: str):\n",
    "    means = extracted.mean(axis=0)\n",
    "    sems = extracted.std(axis=0, ddof=1) / np.sqrt(extracted.shape[0])\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    x = np.arange(len(cond_names))\n",
    "    plt.bar(x, means, yerr=sems)\n",
    "    plt.xticks(x, cond_names, rotation=25, ha=\"right\")\n",
    "    plt.ylabel(\"ERSP (dB) @ hotspot\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "\n",
    "def posthoc_pairwise_ttests(extracted: np.ndarray, cond_names: List[str], correction: str = \"holm\"):\n",
    "    pairs, tvals, pvals = [], [], []\n",
    "    for i in range(len(cond_names)):\n",
    "        for j in range(i + 1, len(cond_names)):\n",
    "            t, p = stats.ttest_rel(extracted[:, i], extracted[:, j], nan_policy=\"omit\")\n",
    "            pairs.append((cond_names[i], cond_names[j]))\n",
    "            tvals.append(float(t))\n",
    "            pvals.append(float(p))\n",
    "    pvals = np.array(pvals)\n",
    "    if correction in (\"holm\", \"fdr_bh\"):\n",
    "        _, p_corr, _, _ = multipletests(pvals, alpha=0.05, method=correction)\n",
    "    else:\n",
    "        p_corr = pvals\n",
    "    return {pair: (t, float(pc)) for pair, t, pc in zip(pairs, tvals, p_corr)}\n",
    "\n",
    "# ---- Plot all F maps ----\n",
    "for roi in roi_names:\n",
    "    for effect_name, res in saved[\"cluster_results\"][roi].items():\n",
    "        plot_f_map(res, title=f\"{roi} | {effect_name} | F-map (cluster contour)\")\n",
    "\n",
    "# ---- Hotspot bars + posthoc ----\n",
    "for roi in roi_names:\n",
    "    for effect_name, hs in saved[\"hotspots\"][roi].items():\n",
    "        extracted = saved[\"extracted_hotspot\"][roi][effect_name]\n",
    "        plot_hotspot_bar(\n",
    "            extracted,\n",
    "            COND_ORDER,\n",
    "            title=f\"{roi} | {effect_name} hotspot @ {hs.t0*1000:.0f} ms, {hs.f0:.2f} Hz (cluster p={hs.p_cluster:.4f})\",\n",
    "        )\n",
    "        ph = posthoc_pairwise_ttests(extracted, COND_ORDER, correction=\"holm\")\n",
    "        print(f\"\\n[{roi}] posthoc ({effect_name}) Holm-corrected p:\")\n",
    "        for (a, b), (t, p) in ph.items():\n",
    "            print(f\"  {a} vs {b}: t={t:.3f}, p_corr={p:.4g}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0c47ce-1819-4b10-9891-716abeb2c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_significant_clusters(res, alpha=0.05):\n",
    "    print(f\"\\n[{res.roi} | {res.effect}] significant clusters (p ≤ {alpha}):\")\n",
    "    found = False\n",
    "    for i, (cm, p) in enumerate(zip(res.cluster_masks, res.cluster_pvals)):\n",
    "        if p <= alpha:\n",
    "            found = True\n",
    "            f_inds, t_inds = np.where(cm)\n",
    "            f_range = (res.freqs[f_inds].min(), res.freqs[f_inds].max())\n",
    "            t_range = (res.times[t_inds].min(), res.times[t_inds].max())\n",
    "            print(\n",
    "                f\"  Cluster {i}: p={p:.4g}, \"\n",
    "                f\"freq={f_range[0]:.2f}–{f_range[1]:.2f} Hz, \"\n",
    "                f\"time={t_range[0]*1000:.0f}–{t_range[1]*1000:.0f} ms\"\n",
    "            )\n",
    "    if not found:\n",
    "        print(\"  None\")\n",
    "for roi in roi_names:\n",
    "    for effect, res in saved[\"cluster_results\"][roi].items():\n",
    "        print_significant_clusters(res, alpha=P_ACCEPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd9dc9f-b0a2-40b2-89ba-316983e43cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = saved[\"cluster_results\"][\"frontal\"][\"task\"]\n",
    "\n",
    "i = 0  # 第 0 个 cluster\n",
    "cm = res.cluster_masks[i]\n",
    "\n",
    "print(\"Mask shape:\", cm.shape)\n",
    "print(\"Mask True count:\", cm.sum())\n",
    "print(\"Freq indices:\", np.unique(np.where(cm)[0])[:10])\n",
    "print(\"Time indices:\", np.unique(np.where(cm)[1])[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc23b91-518d-44c2-b9a4-972c65753a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the results of the hotspot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel\n",
    "from itertools import combinations\n",
    "\n",
    "# 0) sanity check\n",
    "if \"saved\" not in globals():\n",
    "    raise RuntimeError(\"No variable named `saved` found. Run Cell2 once to create it, or load it from disk.\")\n",
    "if \"extracted_hotspot\" not in saved:\n",
    "    raise RuntimeError(\"`saved['extracted_hotspot']` not found. Your Cell2 must store extracted hotspot values.\")\n",
    "\n",
    "# 1) configure labels (edit if your COND_ORDER differs)\n",
    "if \"COND_ORDER\" in globals():\n",
    "    cond_labels = list(COND_ORDER)\n",
    "else:\n",
    "    cond_labels = [\"int_rep\", \"int_swi\", \"ext_rep\", \"ext_swi\"]\n",
    "\n",
    "pairs = list(combinations(range(len(cond_labels)), 2))\n",
    "\n",
    "def bonferroni(p, m):\n",
    "    return min(p * m, 1.0)\n",
    "\n",
    "def star(p):\n",
    "    if p < 0.001:\n",
    "        return \"***\"\n",
    "    if p < 0.01:\n",
    "        return \"**\"\n",
    "    if p < 0.05:\n",
    "        return \"*\"\n",
    "    return \"\"\n",
    "\n",
    "def pairwise_table(vals: np.ndarray, cond_labels: list, method: str = \"bonferroni\") -> pd.DataFrame:\n",
    "    n_tests = len(pairs)\n",
    "    rows = []\n",
    "    for i, j in pairs:\n",
    "        tval, pval = ttest_rel(vals[:, i], vals[:, j], nan_policy=\"omit\")\n",
    "        if method.lower() == \"bonferroni\":\n",
    "            p_corr = bonferroni(pval, n_tests)\n",
    "        else:\n",
    "            raise ValueError(\"Only 'bonferroni' implemented in this print-only cell.\")\n",
    "        rows.append({\n",
    "            \"Contrast\": f\"{cond_labels[i]} vs. {cond_labels[j]}\",\n",
    "            \"t\": float(tval),\n",
    "            \"p_corr\": float(p_corr),\n",
    "            \"sig\": star(p_corr),\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"t\"] = df[\"t\"].map(lambda x: f\"{x:.2f}\")\n",
    "    df[\"p_corr\"] = df[\"p_corr\"].map(lambda x: f\"{x:.4f}\")\n",
    "    return df\n",
    "\n",
    "# 2) print tables for everything that exists\n",
    "all_tables = {}  # (roi, effect) -> dataframe\n",
    "\n",
    "for roi, eff_dict in saved[\"extracted_hotspot\"].items():\n",
    "    for effect, vals in eff_dict.items():\n",
    "        if vals is None:\n",
    "            continue\n",
    "        vals = np.asarray(vals)\n",
    "        if vals.ndim != 2 or vals.shape[1] != len(cond_labels):\n",
    "            raise RuntimeError(\n",
    "                f\"[{roi}/{effect}] vals has shape {vals.shape}, expected (n_subj, {len(cond_labels)}) \"\n",
    "                f\"matching cond_labels={cond_labels}\"\n",
    "            )\n",
    "        df = pairwise_table(vals, cond_labels, method=\"bonferroni\")\n",
    "        all_tables[(roi, effect)] = df\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"Hotspot pairwise comparisons (paired t-tests; Bonferroni corrected)\")\n",
    "        print(f\"ROI: {roi} | Effect: {effect} | n_subj={vals.shape[0]} | n_tests={len(pairs)}\")\n",
    "        print(df.to_string(index=False))\n",
    "\n",
    "# 3) optional: access a specific table later\n",
    "print(\"\\nDone. Tables stored in `all_tables` with keys like (roi, effect).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc6953e-eebe-44e2-bee4-71fee5bdfc2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ITPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa9e0a7-43ed-489c-97a9-ca63bdf9b809",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Compute Complex TFR\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "EPOCHS_DIR = r\"F:\\epochs_ITC\"       \n",
    "OUT_DIR    = r\"F:\\Complex_TFR\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "subjects = [\n",
    "    \"sub_m_1_02\", \"sub_m_1_06\", \"sub_m_1_10\",\"sub_m_1_14\",\"sub_m_1_18\",\"sub_m_1_22\",\"sub_m_1_26\",\"sub_m_1_30\",\"sub_m_1_34\",\"sub_m_1_38\",\"sub_m_1_42\",\"sub_m_1_46\",\n",
    "    \"sub_m_2_04\",\"sub_m_2_08\",\"sub_m_2_12\",\"sub_m_2_16\",\"sub_m_2_20\",\"sub_m_2_24\",\"sub_m_2_28\",\"sub_m_2_32\",\"sub_m_2_36\",\"sub_m_2_40\",\"sub_m_2_44\",\n",
    "    \"sub_p_1_01\",\"sub_p_1_05\",\"sub_p_1_09\",\"sub_p_1_13\",\"sub_p_1_17\",\"sub_p_1_21\",\"sub_p_1_25\",\"sub_p_1_29\",\"sub_p_1_33\",\"sub_p_1_35\",\"sub_p_1_37\",\"sub_p_1_41\",\"sub_p_1_45\",\n",
    "    \"sub_p_2_03\",\"sub_p_2_07\",\"sub_p_2_11\",\"sub_p_2_15\",\"sub_p_2_19\",\"sub_p_2_27\",\"sub_p_2_31\",\"sub_p_2_39\",\"sub_p_2_43\",\"sub_p_2_47\"]\n",
    "\n",
    "freqs = np.arange(4, 30, 1)  \n",
    "n_cycles = 3                     \n",
    "decim = 1                   \n",
    "\n",
    "#Lables + compute + data saving\n",
    "def _get_trial_labels(epochs: mne.Epochs) -> np.ndarray:\n",
    "    # 1) metadata\n",
    "    if epochs.metadata is not None:\n",
    "        for col in [\"label\", \"condition\", \"trial_type\", \"event\", \"event_name\"]:\n",
    "            if col in epochs.metadata.columns:\n",
    "                return epochs.metadata[col].astype(str).to_numpy()\n",
    "\n",
    "    # 2) event_id reverse map\n",
    "    if epochs.event_id is None or len(epochs.event_id) == 0:\n",
    "        raise RuntimeError(\"Epochs has no metadata labels and no event_id mapping. Can't recover trial labels.\")\n",
    "\n",
    "    rev = {v: k for k, v in epochs.event_id.items()}\n",
    "    codes = epochs.events[:, 2]\n",
    "    labels = np.array([rev.get(int(c), f\"code_{int(c)}\") for c in codes], dtype=object)\n",
    "    return labels\n",
    "\n",
    "def compute_and_save_complex_tfr(subj: str) -> None:\n",
    "    epo_path = os.path.join(EPOCHS_DIR, f\"{subj}-raw-ica-reject-ERP-epo.fif\")  \n",
    "    if not os.path.exists(epo_path):\n",
    "        raise FileNotFoundError(epo_path)\n",
    "\n",
    "    epochs = mne.read_epochs(epo_path, preload=True, verbose=\"error\")\n",
    "    labels = _get_trial_labels(epochs)\n",
    "\n",
    "    # Compute single-trial complex TFR\n",
    "    tfr = epochs.compute_tfr(\n",
    "        method=\"morlet\",\n",
    "        freqs=freqs,\n",
    "        n_cycles=n_cycles,\n",
    "        output=\"complex\",\n",
    "        average=False,\n",
    "        use_fft=True,\n",
    "        decim=decim,\n",
    "        return_itc=False,\n",
    "        verbose=\"error\",\n",
    "    )\n",
    "\n",
    "    # tfr.data: (n_epochs, n_channels, n_freqs, n_times), complex\n",
    "    complex_data = tfr.data.astype(np.complex64, copy=False)\n",
    "\n",
    "    complex_path = os.path.join(OUT_DIR, f\"{subj}_complex.npy\")\n",
    "    meta_path    = os.path.join(OUT_DIR, f\"{subj}_meta.npz\")\n",
    "\n",
    "    np.save(complex_path, complex_data)\n",
    "    np.savez(\n",
    "        meta_path,\n",
    "        times=tfr.times.astype(np.float32),\n",
    "        freqs=tfr.freqs.astype(np.float32),\n",
    "        ch_names=np.array(tfr.ch_names, dtype=object),\n",
    "        labels=labels.astype(object),\n",
    "    )\n",
    "\n",
    "    print(f\"[{subj}] saved complex: {complex_data.shape} -> {complex_path}\")\n",
    "\n",
    "for subj in subjects:\n",
    "    try:\n",
    "        compute_and_save_complex_tfr(subj)\n",
    "    except Exception as e:\n",
    "        print(f\"[{subj}] ERROR: {repr(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001ddbb5-c6ad-480d-9335-90ae98386085",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Subj_ITPC only\n",
    "import os\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Any\n",
    "from scipy import stats\n",
    "\n",
    "import mne\n",
    "from mne.stats import permutation_cluster_1samp_test, combine_adjacency\n",
    "\n",
    "rng = np.random.RandomState(SEED)\n",
    "\n",
    "saved_itpc: Dict[str, Any] = {\n",
    "    \"subj_cell_itpc\": {},   # roi -> (n_subj,4,n_f,n_t)\n",
    "    \"times\": None,\n",
    "    \"freqs\": None,\n",
    "    \"ch_names\": None,\n",
    "}\n",
    "\n",
    "# Template axes from first subject\n",
    "Z0, labels0, ch0, freqs, times = load_subject_complex(subjects[0], COMPLEX_DIR)\n",
    "saved_itpc[\"times\"] = times\n",
    "saved_itpc[\"freqs\"] = freqs\n",
    "saved_itpc[\"ch_names\"] = ch0\n",
    "\n",
    "for roi_name, roi_chs in ROIS.items():\n",
    "    roi_idx = pick_roi_indices(ch0, roi_chs)\n",
    "\n",
    "    subj_cell = []\n",
    "    for subj in subjects:\n",
    "        Z, labels, ch_names, freqs_s, times_s = load_subject_complex(subj, COMPLEX_DIR)\n",
    "\n",
    "        # consistency checks\n",
    "        if list(ch_names) != list(ch0):\n",
    "            raise RuntimeError(f\"[{subj}] ch_names mismatch vs first subject.\")\n",
    "        if len(freqs_s) != len(freqs) or np.any(freqs_s != freqs):\n",
    "            raise RuntimeError(f\"[{subj}] freqs mismatch.\")\n",
    "        if len(times_s) != len(times) or np.any(times_s != times):\n",
    "            raise RuntimeError(f\"[{subj}] times mismatch.\")\n",
    "\n",
    "        cell_maps = []\n",
    "        for ck in COND_ORDER:\n",
    "            lab = CONDS[ck]\n",
    "            sel = np.where(labels == lab)[0]\n",
    "            if sel.size == 0:\n",
    "                raise RuntimeError(f\"[{subj}] no trials for condition {ck} label={lab}\")\n",
    "\n",
    "            Z_trials = Z[sel][:, roi_idx, :, :]      # (n_trials, n_ch_roi, n_f, n_t)\n",
    "            itpc_ch = itpc_from_complex_trials(Z_trials)\n",
    "            itpc_roi = itpc_ch.mean(axis=0)          # (n_f, n_t)\n",
    "            cell_maps.append(itpc_roi)\n",
    "\n",
    "        subj_cell.append(np.stack(cell_maps, axis=0))  # (4,n_f,n_t)\n",
    "\n",
    "    subj_cell = np.stack(subj_cell, axis=0)            # (n_subj,4,n_f,n_t)\n",
    "    saved_itpc[\"subj_cell_itpc\"][roi_name] = subj_cell\n",
    "\n",
    "print(\"OK Step1: computed subj_cell_itpc for ROIs:\", list(saved_itpc[\"subj_cell_itpc\"].keys()))\n",
    "print(\"Example shape:\", {k: v.shape for k, v in saved_itpc[\"subj_cell_itpc\"].items()})\n",
    "\n",
    "OUT_NPZ = r\"F:\\itpc_subj_level\"\n",
    "\n",
    "np.savez_compressed(\n",
    "    OUT_NPZ,\n",
    "    subj_cell_itpc=saved_itpc[\"subj_cell_itpc\"],  # dict: roi -> (n_subj,4,n_f,n_t)\n",
    "    times=saved_itpc[\"times\"],\n",
    "    freqs=saved_itpc[\"freqs\"],\n",
    "    ch_names=np.array(saved_itpc[\"ch_names\"], dtype=object),\n",
    "    subjects=np.array(subjects, dtype=object),\n",
    "    cond_order=np.array(COND_ORDER, dtype=object),\n",
    "    rois=np.array(list(ROIS.keys()), dtype=object),\n",
    ")\n",
    "\n",
    "print(f\"Saved ITPC subject-level data to:\\n{OUT_NPZ}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579d14c3-a10b-4fe2-bd99-db038d4208b8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"Has saved_itpc?\", \"saved_itpc\" in globals())\n",
    "if \"saved_itpc\" in globals():\n",
    "    print(\"Keys:\", saved_itpc.keys())\n",
    "    print(\"ROIs:\", list(saved_itpc[\"subj_cell_itpc\"].keys()))\n",
    "    for k, v in saved_itpc[\"subj_cell_itpc\"].items():\n",
    "        print(k, v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d979a1ae-786e-468a-8aea-32f4fda187f3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "OUT_DIR = r\"F:\\itpc_subj_level\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "OUT_NPZ = os.path.join(OUT_DIR, \"itpc_subj_level.npz\")  \n",
    "\n",
    "np.savez_compressed(\n",
    "    OUT_NPZ,\n",
    "    subj_cell_itpc=saved_itpc[\"subj_cell_itpc\"],\n",
    "    times=saved_itpc[\"times\"],\n",
    "    freqs=saved_itpc[\"freqs\"],\n",
    "    ch_names=np.array(saved_itpc[\"ch_names\"], dtype=object),\n",
    "    subjects=np.array(subjects, dtype=object),\n",
    "    cond_order=np.array(COND_ORDER, dtype=object),\n",
    "    rois=np.array(list(saved_itpc[\"subj_cell_itpc\"].keys()), dtype=object),\n",
    ")\n",
    "\n",
    "print(\"Saved to:\", OUT_NPZ)\n",
    "print(\"Now dir contains:\", os.listdir(OUT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96a377b-ac75-49bf-8157-2242511c4e4b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#F-map, rmANOVA, cluster and hotspot\n",
    "npz = np.load(OUT_NPZ, allow_pickle=True)\n",
    "\n",
    "npz = np.load(OUT_NPZ, allow_pickle=True)\n",
    "subj_cell_itpc = npz[\"subj_cell_itpc\"].item()\n",
    "times = npz[\"times\"]\n",
    "freqs = npz[\"freqs\"]\n",
    "subjects = npz[\"subjects\"].tolist()\n",
    "COND_ORDER = npz[\"cond_order\"].tolist()\n",
    "\n",
    "rng = np.random.RandomState(SEED)\n",
    "\n",
    "saved_itpc.update({\n",
    "    \"Fmaps_rmANOVA\": {},     # roi -> effect -> (n_f,n_t)\n",
    "    \"cluster_results\": {},   # roi -> effect -> TFClusterResult\n",
    "    \"hotspots\": {},          # roi -> effect -> Hotspot\n",
    "    \"hotspot_vals\": {},      # roi -> effect -> (n_subj,4)\n",
    "})\n",
    "\n",
    "times = saved_itpc[\"times\"]\n",
    "freqs = saved_itpc[\"freqs\"]\n",
    "\n",
    "for roi_name, subj_cell in saved_itpc[\"subj_cell_itpc\"].items():\n",
    "\n",
    "    # (A) pointwise rmANOVA F-maps (no correction)\n",
    "    Fmaps = rm_anova_2x2_Fmaps(subj_cell)\n",
    "    saved_itpc[\"Fmaps_rmANOVA\"][roi_name] = Fmaps\n",
    "\n",
    "    # (B) cluster permutation inference on contrasts\n",
    "    contrasts = compute_effect_contrasts(subj_cell)\n",
    "\n",
    "    res_roi: Dict[str, TFClusterResult] = {}\n",
    "    hs_roi: Dict[str, Hotspot] = {}\n",
    "    vals_roi: Dict[str, np.ndarray] = {}\n",
    "\n",
    "    for effect_name, X in contrasts.items():\n",
    "        res = tf_cluster_1samp_t_as_F(\n",
    "            X=X, times=times, freqs=freqs,\n",
    "            effect=effect_name, roi=roi_name,\n",
    "            n_perm=N_PERM,\n",
    "            p_cluster_forming=P_CLUSTER_FORMING,\n",
    "            p_accept=P_ACCEPT,\n",
    "            seed=int(rng.randint(0, 1_000_000)),\n",
    "        )\n",
    "        res_roi[effect_name] = res\n",
    "\n",
    "        if np.any(res.sig_mask):\n",
    "            hs = define_hotspot_from_sig_clusters(res, p_accept=P_ACCEPT)\n",
    "            hs_roi[effect_name] = hs\n",
    "            vals_roi[effect_name] = extract_hotspot_values(subj_cell, hs)\n",
    "\n",
    "    saved_itpc[\"cluster_results\"][roi_name] = res_roi\n",
    "    saved_itpc[\"hotspots\"][roi_name] = hs_roi\n",
    "    saved_itpc[\"hotspot_vals\"][roi_name] = vals_roi\n",
    "\n",
    "print(\"OK Step2: computed Fmaps + cluster + hotspots.\")\n",
    "print(\"ROIs:\", list(saved_itpc[\"cluster_results\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca62490-94b1-4027-b702-0a7bdef3b96e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#plot\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import os\n",
    "os.environ[\"QT_API\"] = \"pyqt5\"\n",
    "%matplotlib qt\n",
    "\n",
    "COND_LABELS = COND_ORDER\n",
    "\n",
    "def print_clusters(res, max_print: int = 8, only_sig: bool = False, p_accept: float = 0.05):\n",
    "    print(f\"\\n--- ROI={res.roi} | effect={res.effect} ---\")\n",
    "    if len(res.cluster_masks) == 0:\n",
    "        print(\"No clusters found.\")\n",
    "        return\n",
    "\n",
    "    order = np.argsort(res.cluster_pvals)\n",
    "    printed = 0\n",
    "    for k in order:\n",
    "        p = float(res.cluster_pvals[k])\n",
    "        if only_sig and p > p_accept:\n",
    "            continue\n",
    "        cm = np.asarray(res.cluster_masks[k], dtype=bool)\n",
    "        n_pts = int(cm.sum())\n",
    "        if n_pts == 0:\n",
    "            continue\n",
    "        f_inds, t_inds = np.where(cm)\n",
    "        f_rng = (float(res.freqs[f_inds].min()), float(res.freqs[f_inds].max()))\n",
    "        t_rng = (float(res.times[t_inds].min()), float(res.times[t_inds].max()))\n",
    "        print(\n",
    "            f\"cluster#{k:03d}: p={p:.4g}, n_pts={n_pts}, \"\n",
    "            f\"f=[{f_rng[0]:.2f},{f_rng[1]:.2f}]Hz, t=[{t_rng[0]:.3f},{t_rng[1]:.3f}]s\"\n",
    "        )\n",
    "        printed += 1\n",
    "        if printed >= max_print:\n",
    "            break\n",
    "\n",
    "#Get (fmin,fmax), (tmin,tmax), n_pts from hotspot mask\n",
    "def hotspot_ranges(hs, res) -> Tuple[Tuple[float, float], Tuple[float, float], int]:\n",
    "    cm = np.asarray(hs.mask, dtype=bool)\n",
    "    f_inds, t_inds = np.where(cm)\n",
    "    fmin, fmax = float(res.freqs[f_inds].min()), float(res.freqs[f_inds].max())\n",
    "    tmin, tmax = float(res.times[t_inds].min()), float(res.times[t_inds].max())\n",
    "    return (fmin, fmax), (tmin, tmax), int(cm.sum())\n",
    "\n",
    "#(n_subj, 4) extracted from hotspot mask\n",
    "def plot_hotspot_bar(vals: np.ndarray, title: str, labels: List[str], info: str = \"\"):\n",
    "    means = vals.mean(axis=0)\n",
    "    sems = vals.std(axis=0, ddof=1) / np.sqrt(vals.shape[0])\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    plt.figure()\n",
    "    plt.bar(x, means, yerr=sems)\n",
    "    plt.xticks(x, labels, rotation=30, ha=\"right\")\n",
    "    plt.ylabel(\"ITPC (unitless)\")\n",
    "    plt.title(title)\n",
    "\n",
    "    if info:\n",
    "        ax = plt.gca()\n",
    "        ax.text(\n",
    "            0.01, 0.99, info,\n",
    "            transform=ax.transAxes,\n",
    "            va=\"top\", ha=\"left\"\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#Paired t-tests for all 6 pairs among 4 conditions\n",
    "def posthoc_pairwise_t(vals: np.ndarray, labels: List[str], bonferroni: bool = True):\n",
    "    pairs = [(i, j) for i in range(4) for j in range(i + 1, 4)]\n",
    "    m = len(pairs)\n",
    "    out = []\n",
    "    for i, j in pairs:\n",
    "        t, p = stats.ttest_rel(vals[:, i], vals[:, j], nan_policy=\"omit\")\n",
    "        p_adj = min(p * m, 1.0) if bonferroni else p\n",
    "        out.append((labels[i], labels[j], float(t), float(p), float(p_adj)))\n",
    "    return out\n",
    "\n",
    "#Print significant clusters + hotspot definition\n",
    "for roi_name, eff_dict in saved_itpc[\"cluster_results\"].items():\n",
    "    for effect_name, res in eff_dict.items():\n",
    "        print_clusters(res, max_print=6, only_sig=True, p_accept=P_ACCEPT)\n",
    "\n",
    "        hs = saved_itpc[\"hotspots\"].get(roi_name, {}).get(effect_name, None)\n",
    "        if hs is not None:\n",
    "            # also print hotspot TF range\n",
    "            (fmin, fmax), (tmin, tmax), npts = hotspot_ranges(hs, res)\n",
    "            print(\n",
    "                f\"  HOTSPOT: peak={hs.f0:.2f}Hz @ {hs.t0:.3f}s, \"\n",
    "                f\"cluster_p={hs.p_cluster:.4g}, pts={npts}, \"\n",
    "                f\"range f=[{fmin:.2f},{fmax:.2f}]Hz, t=[{tmin:.3f},{tmax:.3f}]s\"\n",
    "            )\n",
    "\n",
    "#Barplots + posthoc table at hotspots (with TF info on plot) \n",
    "for roi_name, eff_vals in saved_itpc[\"hotspot_vals\"].items():\n",
    "    for effect_name, vals in eff_vals.items():\n",
    "\n",
    "        hs = saved_itpc[\"hotspots\"].get(roi_name, {}).get(effect_name, None)\n",
    "        res = saved_itpc[\"cluster_results\"].get(roi_name, {}).get(effect_name, None)\n",
    "        if hs is None or res is None:\n",
    "            continue\n",
    "\n",
    "        (fmin, fmax), (tmin, tmax), npts = hotspot_ranges(hs, res)\n",
    "\n",
    "        info = (\n",
    "            f\"cluster p={hs.p_cluster:.4g}, pts={npts}\\n\"\n",
    "            f\"peak: {hs.f0:.2f} Hz @ {hs.t0*1000:.0f} ms\\n\"\n",
    "        )\n",
    "\n",
    "        title = f\"ITPC hotspot | ROI={roi_name} | effect={effect_name}\"\n",
    "        plot_hotspot_bar(vals, title, COND_LABELS, info=info)\n",
    "\n",
    "        table = posthoc_pairwise_t(vals, COND_LABELS, bonferroni=True)\n",
    "        print(f\"\\nPost-hoc paired t (Bonferroni) @ hotspot | ROI={roi_name} | effect={effect_name}\")\n",
    "        for a, b, t, p, p_adj in table:\n",
    "            print(f\"  {a:>8s} vs {b:<8s}: t={t: .3f}, p={p:.3g}, p_adj={p_adj:.3g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a400a3-e2b2-40bc-95bb-a7579d5a744e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#plot F stats map\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import os\n",
    "os.environ[\"QT_API\"] = \"pyqt5\"\n",
    "%matplotlib qt\n",
    "\n",
    "def plot_tf_Fmap_with_sig(res: TFClusterResult, title: str = None, show_sig: bool = True):\n",
    "    F = res.F_obs\n",
    "    times = res.times\n",
    "    freqs = res.freqs\n",
    "\n",
    "    plt.figure()\n",
    "    im = plt.imshow(\n",
    "        F,\n",
    "        aspect=\"auto\",\n",
    "        origin=\"lower\",\n",
    "        extent=[times[0], times[-1], freqs[0], freqs[-1]],\n",
    "    )\n",
    "    plt.colorbar(im, label=\"F (t^2)\")\n",
    "\n",
    "    if title is None:\n",
    "        title = f\"F-stat map | ROI={res.roi} | effect={res.effect}\"\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "\n",
    "    # overlay significant mask as contour\n",
    "    if show_sig and np.any(res.sig_mask):\n",
    "        sig = res.sig_mask.astype(int)\n",
    "        plt.contour(\n",
    "            times, freqs, sig,\n",
    "            levels=[0.5],\n",
    "            linewidths=2\n",
    "        )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 画每个 ROI × effect 的 F-map（跟 ERSP 一样的结构）\n",
    "for roi_name, eff_dict in saved_itpc[\"cluster_results\"].items():\n",
    "    for effect_name, res in eff_dict.items():\n",
    "        plot_tf_Fmap_with_sig(res, title=f\"ITPC F-stat map | ROI={roi_name} | effect={effect_name}\", show_sig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ed451-c961-44ee-a722-7219fa939e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print results of hotspot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel\n",
    "from itertools import combinations\n",
    "\n",
    "# 0) sanity check (ITPC)\n",
    "if \"saved_itpc\" not in globals():\n",
    "    raise RuntimeError(\n",
    "        \"No variable named `saved_itpc` found. \"\n",
    "        \"Run the ITPC Step2 (cluster+hotspot) cell to create it, or load it from disk.\"\n",
    "    )\n",
    "\n",
    "if \"hotspot_vals\" not in saved_itpc:\n",
    "    raise RuntimeError(\n",
    "        \"`saved_itpc['hotspot_vals']` not found. \"\n",
    "        \"Your ITPC Step2 must store extracted hotspot values as (n_subj,4).\"\n",
    "    )\n",
    "\n",
    "# 1) configure labels\n",
    "if \"COND_ORDER\" in globals():\n",
    "    cond_labels = list(COND_ORDER)\n",
    "else:\n",
    "    cond_labels = [\"int_rep\", \"int_swi\", \"ext_rep\", \"ext_swi\"]\n",
    "\n",
    "pairs = list(combinations(range(len(cond_labels)), 2))\n",
    "\n",
    "def bonferroni(p, m):\n",
    "    return min(p * m, 1.0)\n",
    "\n",
    "def star(p):\n",
    "    if p < 0.001:\n",
    "        return \"***\"\n",
    "    if p < 0.01:\n",
    "        return \"**\"\n",
    "    if p < 0.05:\n",
    "        return \"*\"\n",
    "    return \"\"\n",
    "\n",
    "def pairwise_table(vals: np.ndarray, cond_labels: list, method: str = \"bonferroni\") -> pd.DataFrame:\n",
    "    n_tests = len(pairs)\n",
    "    rows = []\n",
    "    for i, j in pairs:\n",
    "        tval, pval = ttest_rel(vals[:, i], vals[:, j], nan_policy=\"omit\")\n",
    "        if method.lower() == \"bonferroni\":\n",
    "            p_corr = bonferroni(pval, n_tests)\n",
    "        else:\n",
    "            raise ValueError(\"Only 'bonferroni' implemented in this print-only cell.\")\n",
    "        rows.append({\n",
    "            \"Contrast\": f\"{cond_labels[i]} vs. {cond_labels[j]}\",\n",
    "            \"t\": float(tval),\n",
    "            \"p_corr\": float(p_corr),\n",
    "            \"sig\": star(p_corr),\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"t\"] = df[\"t\"].map(lambda x: f\"{x:.2f}\")\n",
    "    df[\"p_corr\"] = df[\"p_corr\"].map(lambda x: f\"{x:.4f}\")\n",
    "    return df\n",
    "\n",
    "# 2) print tables for ITPC hotspots\n",
    "# saved_itpc[\"hotspot_vals\"][roi][effect] -> (n_subj, 4)\n",
    "all_tables_itpc = {}  # (roi, effect) -> dataframe\n",
    "\n",
    "for roi, eff_dict in saved_itpc[\"hotspot_vals\"].items():\n",
    "    if eff_dict is None:\n",
    "        continue\n",
    "    for effect, vals in eff_dict.items():\n",
    "        if vals is None:\n",
    "            continue\n",
    "        vals = np.asarray(vals)\n",
    "\n",
    "        if vals.ndim != 2 or vals.shape[1] != len(cond_labels):\n",
    "            raise RuntimeError(\n",
    "                f\"[ITPC {roi}/{effect}] vals has shape {vals.shape}, expected (n_subj, {len(cond_labels)}) \"\n",
    "                f\"matching cond_labels={cond_labels}\"\n",
    "            )\n",
    "\n",
    "        df = pairwise_table(vals, cond_labels, method=\"bonferroni\")\n",
    "        all_tables_itpc[(roi, effect)] = df\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ITPC Hotspot pairwise comparisons (paired t-tests; Bonferroni corrected)\")\n",
    "        print(f\"ROI: {roi} | Effect: {effect} | n_subj={vals.shape[0]} | n_tests={len(pairs)}\")\n",
    "        print(df.to_string(index=False))\n",
    "\n",
    "print(\"\\nDone. Tables stored in `all_tables` with keys like (roi, effect).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cbb1ed-b3aa-4542-a961-0dead65b6478",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
